{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13343, 20) (2046, 20)\n"
     ]
    }
   ],
   "source": [
    "# preparing data\n",
    "from models import *\n",
    "from methods import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from os import path\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "DATASET = 'full_data'\n",
    "\"\"\"___________________Hyper Parameters________________________\"\"\"\n",
    "MODEL_NAME = ('VAE', 'DAE', 'AE')\n",
    "CROSS_VALIDATION_SHUFFLE = True\n",
    "TRIM_DATA = (True, False)\n",
    "FILTER_CORRCOEF = (True, False)\n",
    "REMOVE_NOISE = (True, False)\n",
    "NOISE_THRESHOLD = (10, 3, 2)\n",
    "DENOISE = (False, True)\n",
    "NOISE_FACTOR = (0.05, 0.2, 0.5)\n",
    "NOISE_FRACTION = (0.1, 0.2, 0.5, 0.8)\n",
    "PERPLEXITY = 10\n",
    "NORMALIZE_DATA = (True, False)\n",
    "\n",
    "INITIALIZATION = ('xavier_normal', 'kaiming_normal')\n",
    "ACTIVATION = ('tanh', 'leaky_relu', 'sigmoid')\n",
    "SIGMA = (1e0, 1e-1, 1e-4)\n",
    "LATENT_DIM = (8, 32, 128)\n",
    "HIDDEN_DIM = (8, 64, 512)\n",
    "GD_ALGORITHMS = ('SGD', 'Adam')\n",
    "WEIGHT_DECAY = (0, 1e-6, 1e-4)\n",
    "LEARNING_RATE = (1e-4, 1e-3)\n",
    "BATCH_SIZE = (1024, 256, 128)\n",
    "EPOCHS = (2000, 4000)\n",
    "\"\"\"___________________________________________________________\"\"\"\n",
    "# collapse\n",
    "# Load Dataset\n",
    "if DATASET == 'network_data':\n",
    "    raw_data = np.loadtxt('../data/network_flow_regular_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "    anomalous_data = np.loadtxt('../data/network_flow_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "elif DATASET == 'medical_data':\n",
    "    raw_data = np.loadtxt('../data/medical_regular_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "    anomalous_data = np.loadtxt('../data/medical_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "elif DATASET == 'full_data':\n",
    "    raw_data = np.concatenate((np.loadtxt('../data/network_flow_regular_data.csv', skiprows=1, delimiter=',')[:,:-1], np.loadtxt('../data/medical_regular_data.csv', skiprows=1, delimiter=',')[:,:-1]), axis=1)\n",
    "    anomalous_data = np.concatenate((np.loadtxt('../data/network_flow_attack_data.csv', skiprows=1, delimiter=',')[:,:-1], np.loadtxt('../data/medical_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]), axis=1)\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(raw_data.shape, anomalous_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Different types of model\n",
    "for model_name in MODEL_NAME:\n",
    "    # Data Processing\n",
    "    for trim_data, normalize_data, filter_corrcoef, remove_noise, noise_threshold in itertools.product(TRIM_DATA, NORMALIZE_DATA, FILTER_CORRCOEF, REMOVE_NOISE, NOISE_THRESHOLD):\n",
    "        # initialize containers for data\n",
    "        loss_array = []\n",
    "        # process data\n",
    "        train_data, validation_data, test_data, anomalous_data = preProcessData_OneClass(raw_data, anomalous_data, trim=trim_data, trim_threshold=0.98, normalize=normalize_data,\n",
    "            filterLinearDependencies=True, filter_threshold=0.99, removeNoise=remove_noise, noise_threshold=noise_threshold)\n",
    "\n",
    "        train_data, validation_data, test_data, anomalous_data = toTorchTensor(device, train_data, validation_data, test_data, anomalous_data)\n",
    "        criterion = nn.MSELoss(reduction='sum')\n",
    "        print(train_data.shape, validation_data.shape, test_data.shape, anomalous_data.shape)\n",
    "        NUM_FEATURE = train_data.shape[1]\n",
    "        \n",
    "        for latent_dim, hidden_dim, activation, initialization, sigma in itertools.product(LATENT_DIM, HIDDEN_DIM, ACTIVATION, INITIALIZATION, SIGMA):\n",
    "            for algo, learning_rate, weight_decay, epochs, batch_size, noise_factor, noise_fraction in itertools.product(GD_ALGORITHMS, LEARNING_RATE, WEIGHT_DECAY, EPOCHS, BATCH_SIZE, NOISE_FACTOR, NOISE_FRACTION):\n",
    "                # initialize model\n",
    "                if model_name == 'AE':\n",
    "                    model = AutoEncoder(num_feature=NUM_FEATURE, latent_dim=latent_dim, hidden_dim=hidden_dim, activation=activation, initialization=initialization).to(device)\n",
    "                elif model_name == 'DAE':\n",
    "                    model = DAE(num_feature=NUM_FEATURE, latent_dim=latent_dim, hidden_dim=hidden_dim, activation=activation, initialization=initialization, noise_factor=noise_factor, noise_fraction=noise_fraction).to(device)\n",
    "                elif model_name == 'VAE':\n",
    "                    model = VAE(num_feature=NUM_FEATURE, latent_dim=latent_dim, hidden_dim=hidden_dim, activation=activation, initialization=initialization, sigma=sigma).to(device)\n",
    "                # train \n",
    "                loss_array = train(model, 'SGD', epochs, train_data, train_data, criterion, batch_size=batch_size, lr=learning_rate, weight_decay=weight_decay\n",
    "                    , grad_limit=1e3)\n",
    "                torch.save(model.state_dict(), '../model/param_AE')\n",
    "\n",
    "                # test\n",
    "                loss_test, loss_attack, kl_div_test, kl_div_attack, y_scores, y_scores_lcs, y_ground_truth, lcs_array_test, lcs_array_attack = test(model, criterion, train_data, test_data, anomalous_data) \n",
    "                # t-SNE analysis of code distribution\n",
    "                tsne = TSNE(n_components=2, perplexity=PERPLEXITY)\n",
    "                full_code = model.encode(torch.cat((test_data, anomalous_data), dim=0)).detach().numpy()\n",
    "                full_label = [0 for _ in range(len(test_data))] + [1 for _ in range(len(anomalous_data))]\n",
    "                tsne_code = tsne.fit_transform(full_code)\n",
    "                # plot\n",
    "                # parameters for visualizer to print\n",
    "                parameters = {\"trim_data\": trim_data, \"normalize_data\": normalize_data, \n",
    "                    \"filter_corrcoef\": filter_corrcoef, \"remove_noise\": remove_noise, \"noise_threshold\": noise_threshold,\n",
    "                    \n",
    "                    \"latent_dim\": latent_dim, \"hidden_dim\": hidden_dim,\n",
    "                    \"activation\": activation, \"initialization\": initialization,\n",
    "\n",
    "                    \"weight_decay\": weight_decay,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"epochs\": epochs,\n",
    "                    }\n",
    "                if model.name == 'VAE':\n",
    "                    parameters[\"sigma\"] = sigma\n",
    "                if model.name == 'DAE':\n",
    "                    parameters[\"denoise\"] = True\n",
    "                    parameters[\"noise_factor\"] = noise_factor\n",
    "                    parameters[\"noise_fraction\"] = noise_fraction\n",
    "                visualize_convergence(loss_array, model.name, save=True, **parameters)\n",
    "                visualize_loss(loss_test, loss_attack, model.name, save=True, **parameters)\n",
    "                visualize_tSNE(tsne_code, len(test_data), len(anomalous_data), PERPLEXITY, model.name, save=True, **parameters)\n",
    "                visualize_kl(kl_div_test, kl_div_attack, model.name, save=True, **parameters)\n",
    "                scores = {\"y_scores\": y_scores, \"y_scores_lcs\": y_scores_lcs, \"kl_scores\": np.concatenate((kl_div_test, kl_div_attack), axis=None)}\n",
    "                #visualize_ROC(y_ground_truth, model.name, True, scores ,**parameters)\n",
    "                plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network data\n",
    "raw_data, anomalous_data = np.loadtxt('../data/network_flow_regular_data.csv', skiprows=1, delimiter=',')[:,:-1], np.loadtxt('../data/network_flow_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "_, _, _, anomalous_data = preProcessData_OneClass(raw_data, anomalous_data, trim=trim_data, trim_threshold=0.98, normalize=normalize_data,\n",
    "            filterLinearDependencies=True, filter_threshold=0.98, removeNoise=remove_noise, noise_threshold=noise_threshold)\n",
    "# import network optimal model\n",
    "model = None\n",
    "model.load_state_dict('../model/param_DOCAE_network_optimal')\n",
    "# indices that are detected\n",
    "idc1 = torch.sum((model.encode(anomalous_data) - model.center)**2, dim=1) > model.R**2\n",
    "\n",
    "#_______________________________________________________________________________\n",
    "# load medical data\n",
    "raw_data, anomalous_data = np.loadtxt('../data/medical_regular_data.csv', skiprows=1, delimiter=',')[:,:-1], np.loadtxt('../data/medical_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "_, _, _, anomalous_data = preProcessData_OneClass(raw_data, anomalous_data, trim=trim_data, trim_threshold=0.98, normalize=normalize_data,\n",
    "            filterLinearDependencies=True, filter_threshold=0.98, removeNoise=remove_noise, noise_threshold=noise_threshold)\n",
    "# import medical optimal model\n",
    "model = None\n",
    "model.load_state_dict('../model/param_DOCAE_medical_optimal')\n",
    "# indices that are detected\n",
    "idc2 = torch.sum((model.encode(anomalous_data) - model.center)**2, dim=1) > model.R**2\n",
    "\n",
    "print('Accuracy = ', torch.logical_or(idc1, idc2).sum() / len(idc1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db51f3103e33fda5231e127d6bff8ab7a63db870768c02250aa2c81f3d18b2ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
