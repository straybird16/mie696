{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "macOS-13.0-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "# preparing data\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "from os import path\n",
    "import torch.nn as nn\n",
    "\n",
    "NETWORK_DATA = True\n",
    "\n",
    "\"\"\"___________________Hyper Parameters________________________\"\"\"\n",
    "CROSS_VALIDATION_SHUFFLE = True\n",
    "TRIM_DATA = True\n",
    "FILTER_CORRCOEF = True\n",
    "DENOISE = False\n",
    "NORMALIZE_DATA = False\n",
    "LATENT_DIM = 16\n",
    "HIDDEN_DIM = 4\n",
    "WEIGHT_DECAY = 0\n",
    "LEARNING_RATE = 1e-5\n",
    "ACTIVATION = 'leaky_relu'\n",
    "OUTPUT_DIM = 1\n",
    "PREDICTING_INDEX = 0\n",
    "\"\"\"___________________________________________________________\"\"\"\n",
    "# collapse\n",
    "if NETWORK_DATA:\n",
    "    raw_data = np.loadtxt('../data/network_flow_regular_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "    anomalous_data = np.loadtxt('../data/network_flow_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "else:\n",
    "    raw_data = np.loadtxt('../data/medical_regular_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "    anomalous_data = np.loadtxt('../data/medical_attack_data.csv', skiprows=1, delimiter=',')[:,:-1]\n",
    "# collapse here\n",
    "\n",
    "if True:\n",
    "    len_raw_data = len(raw_data)\n",
    "    PROPORTION_TRAIN = 0.6\n",
    "    PROPORTION_VALIDATION = 0.2\n",
    "    PROPORTION_TEST = 0.2\n",
    "    if CROSS_VALIDATION_SHUFFLE:\n",
    "        random_idc = np.random.choice(len_raw_data, len_raw_data, replace=False)\n",
    "        raw_data = raw_data[random_idc,:]\n",
    "    train_data = torch.tensor(raw_data[0:math.floor(len_raw_data * PROPORTION_TRAIN)])\n",
    "    validation_data = torch.tensor(raw_data[math.floor(len_raw_data * PROPORTION_TRAIN):math.floor(len_raw_data * (PROPORTION_TRAIN + PROPORTION_VALIDATION))])\n",
    "    test_data = torch.tensor(raw_data[math.floor(len_raw_data * (PROPORTION_TRAIN + PROPORTION_VALIDATION)):])\n",
    "\n",
    "    train_data = train_data.to(torch.float32)\n",
    "    validation_data = validation_data.to(torch.float32)\n",
    "    test_data = test_data.to(torch.float32)\n",
    "    anomalous_data = torch.tensor(anomalous_data).to(torch.float32)\n",
    "\n",
    "    if TRIM_DATA:\n",
    "        train_data = torch.cat((train_data[::, 2:-5], train_data[::, -3:]), 1)\n",
    "        validation_data = torch.cat((validation_data[::, 2:-5], validation_data[::, -3:]), 1)\n",
    "        test_data = torch.cat((test_data[::, 2:-5], test_data[::, -3:]), 1)\n",
    "        anomalous_data = torch.cat((anomalous_data[::, 2:-5], anomalous_data[::, -3:]), 1)\n",
    "    #print(torch.corrcoef(torch.t(train_data)).numpy())\n",
    "\n",
    "    # this ensures that the current MacOS version is at least 12.3+\n",
    "    print(torch.backends.mps.is_available())\n",
    "    # this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "    print(torch.backends.mps.is_built())\n",
    "    import platform\n",
    "    print(platform.platform())\n",
    "    if FILTER_CORRCOEF:\n",
    "        train_data = torch.cat((train_data[::, 0:1], train_data[::, 2:-2]), 1)\n",
    "        validation_data = torch.cat((validation_data[::, 0:1], validation_data[::, 2:-2]), 1)\n",
    "        test_data = torch.cat((test_data[::, 0:1], test_data[::, 2:-2]), 1)\n",
    "        anomalous_data = torch.cat((anomalous_data[::, 0:1], anomalous_data[::, 2:-2]), 1)\n",
    "    if NORMALIZE_DATA:\n",
    "        eps = 1e-5\n",
    "        train_mu = torch.mean(train_data, 0, True)\n",
    "        train_std = torch.std(train_data, dim=0, unbiased=True, keepdim=True)\n",
    "        print(\"Train data std: \", train_std)\n",
    "        train_data = (train_data - train_mu) / (train_std + eps)\n",
    "        validation_data = (validation_data - torch.mean(validation_data, 0, True)) / (train_std + eps)\n",
    "        test_data = (test_data - train_mu) / (train_std + eps)\n",
    "        anomalous_data = (anomalous_data - train_mu) / (train_std + eps)\n",
    "\n",
    "# use gpu if available\n",
    "#device = torch.device(\"mps\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = train_data.to(device)\n",
    "validation_data = validation_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "anomalous_data = anomalous_data.to(device)\n",
    "train_y, validation_y, test_y, anomalous_y = train_data[:,PREDICTING_INDEX], validation_data[:,PREDICTING_INDEX], test_data[:,PREDICTING_INDEX], anomalous_data[:,PREDICTING_INDEX]\n",
    "train_X, validation_X, test_X, anomalous_X = np.delete(train_data, PREDICTING_INDEX, axis=1), np.delete(validation_data, PREDICTING_INDEX, axis=1), np.delete(test_data, PREDICTING_INDEX, axis=1), np.delete(anomalous_data, PREDICTING_INDEX, axis=1)\n",
    "\n",
    "NUM_FEATURE = len(train_data[0]) - OUTPUT_DIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE class\n",
    "class AutoEncoder(nn.Module):\n",
    "    def _init_weights(self, module):\n",
    "        #torch.nn.init.kaiming_normal_(module.weight.data, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        torch.nn.init.xavier_normal_(module.weight, gain=torch.nn.init.calculate_gain(nonlinearity='linear'))\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def __init__(self, num_feature=16, latend_dim=4, hidden_dim=8, activation='leaky_relu', **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.num_feature = num_feature\n",
    "        self.latent_dim = latend_dim\n",
    "        hd = hidden_dim\n",
    "        self.KLD = 0\n",
    "        self.output_dim = OUTPUT_DIM\n",
    "        self.l1 = nn.Linear(num_feature, hd)\n",
    "        self.l2 = nn.Linear(hd, hd)\n",
    "        self.l3 = nn.Linear(hd, hd)\n",
    "        self.generate_mean = nn.Linear(hd, latend_dim)\n",
    "        self.generate_var = nn.Linear(hd, latend_dim)\n",
    "        self.l5 = nn.Linear(latend_dim, hd)\n",
    "        self.l6 = nn.Linear(hd, hd)\n",
    "        self.l7 = nn.Linear(hd, hd)\n",
    "        self.l8 = nn.Linear(hd, self.output_dim)\n",
    "\n",
    "        if activation == 'leaky_relu':\n",
    "            self.encoding_layer = nn.Sequential(\n",
    "                self.l1,\n",
    "                nn.LeakyReLU(0.1),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l2,\n",
    "                nn.LeakyReLU(0.1),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l3,\n",
    "                nn.LeakyReLU(0.1),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "            )  \n",
    "            self.decoding_layer = nn.Sequential(\n",
    "                self.l5,\n",
    "                nn.LeakyReLU(0.1),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l6,\n",
    "                nn.LeakyReLU(0.1),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l7,\n",
    "                nn.LeakyReLU(0.1),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l8,\n",
    "            )\n",
    "        elif activation == 'tanh':\n",
    "            self.encoding_layer = nn.Sequential(\n",
    "                self.l1,\n",
    "                nn.Tanh(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l2,\n",
    "                nn.Tanh(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l3,\n",
    "                nn.Tanh(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "            )  \n",
    "            self.decoding_layer = nn.Sequential(\n",
    "                self.l5,\n",
    "                nn.Tanh(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l6,\n",
    "                nn.Tanh(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l7,\n",
    "                nn.Tanh(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l8\n",
    "            )\n",
    "        elif activation == 'sigmoid':\n",
    "            self.encoding_layer = nn.Sequential(\n",
    "                self.l1,\n",
    "                nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l2,\n",
    "                nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l3,\n",
    "                nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "            )  \n",
    "            self.decoding_layer = nn.Sequential(\n",
    "                self.l5,\n",
    "                nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l6,\n",
    "                nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l7,\n",
    "                nn.Sigmoid(),\n",
    "                #nn.BatchNorm1d(hd),\n",
    "                self.l8,\n",
    "            )\n",
    "\n",
    "        self._init_weights(self.l1)\n",
    "        self._init_weights(self.l2)\n",
    "        self._init_weights(self.l3)\n",
    "        self._init_weights(self.generate_mean)\n",
    "        self._init_weights(self.generate_var)\n",
    "        self._init_weights(self.l5)\n",
    "        self._init_weights(self.l6)\n",
    "        self._init_weights(self.l7)\n",
    "        self._init_weights(self.l8)\n",
    "    \n",
    "    def reparameterize(self, mu, var):\n",
    "        std = torch.sqrt(var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        self.KLD = -0.5 * torch.sum(1 + torch.log(var) - mu**2 - var) / self.latent_dim\n",
    "        #print(\"eps = {}, var = {}, std = {}, KLD = {}\".format(eps, var, std, self.KLD))\n",
    "        #torch.ones(mu.size())\n",
    "        #self.KLD = 0.5 * (torch.exp(var) + mu**2 - var - 1)\n",
    "        return sample\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoding_layer(x)\n",
    "        mu, var = self.generate_mean(x), self.generate_var(x)**2\n",
    "        return self.reparameterize(mu, var)\n",
    "    def decode(self, x):\n",
    "        return self.decoding_layer(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l8(self.l2(self.l1(x)))\n",
    "        return self.decode(self.encode(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "BATCH_SIZE = 128\n",
    "# collapse\n",
    "if True:\n",
    "    model = AutoEncoder(num_feature=NUM_FEATURE, latend_dim=LATENT_DIM, hidden_dim=HIDDEN_DIM, activation=ACTIVATION).to(device)\n",
    "\n",
    "    # mean-squared error loss\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/2000, loss = 54555951458.082695, KLD = 0.0\n",
      "epoch : 2/2000, loss = 54551110979.765648, KLD = 0.0\n",
      "epoch : 3/2000, loss = 54546279114.049721, KLD = 0.0\n",
      "epoch : 4/2000, loss = 54541436572.638100, KLD = 0.0\n",
      "epoch : 5/2000, loss = 54536600220.510178, KLD = 0.0\n",
      "epoch : 6/2000, loss = 54531773234.176643, KLD = 0.0\n",
      "epoch : 7/2000, loss = 54526931576.948410, KLD = 0.0\n",
      "epoch : 8/2000, loss = 54522111631.334419, KLD = 0.0\n",
      "epoch : 9/2000, loss = 54517271414.997627, KLD = 0.0\n",
      "epoch : 10/2000, loss = 54512445280.099937, KLD = 0.0\n",
      "epoch : 11/2000, loss = 54507617016.612617, KLD = 0.0\n",
      "epoch : 12/2000, loss = 54502774868.171394, KLD = 0.0\n",
      "epoch : 13/2000, loss = 54497937042.404495, KLD = 0.0\n",
      "epoch : 14/2000, loss = 54493094009.779884, KLD = 0.0\n",
      "epoch : 15/2000, loss = 54488260670.424988, KLD = 0.0\n",
      "epoch : 16/2000, loss = 54483413216.883446, KLD = 0.0\n",
      "epoch : 17/2000, loss = 54478579681.043350, KLD = 0.0\n",
      "epoch : 18/2000, loss = 54473738580.523170, KLD = 0.0\n",
      "epoch : 19/2000, loss = 54468887459.257965, KLD = 0.0\n",
      "epoch : 20/2000, loss = 54464023828.435226, KLD = 0.0\n",
      "epoch : 21/2000, loss = 54459168777.466087, KLD = 0.0\n",
      "epoch : 22/2000, loss = 54454310877.461586, KLD = 0.0\n",
      "epoch : 23/2000, loss = 54449447574.114182, KLD = 0.0\n",
      "epoch : 24/2000, loss = 54444583419.330917, KLD = 0.0\n",
      "epoch : 25/2000, loss = 54439704233.430107, KLD = 0.0\n",
      "epoch : 26/2000, loss = 54434819414.953651, KLD = 0.0\n",
      "epoch : 27/2000, loss = 54429940229.052841, KLD = 0.0\n",
      "epoch : 28/2000, loss = 54425046601.490067, KLD = 0.0\n",
      "epoch : 29/2000, loss = 54420146260.683075, KLD = 0.0\n",
      "epoch : 30/2000, loss = 54415239697.844849, KLD = 0.0\n",
      "epoch : 31/2000, loss = 54410340503.201500, KLD = 0.0\n",
      "epoch : 32/2000, loss = 54405409805.431602, KLD = 0.0\n",
      "epoch : 33/2000, loss = 54400490045.337662, KLD = 0.0\n",
      "epoch : 34/2000, loss = 54395561869.127792, KLD = 0.0\n",
      "epoch : 35/2000, loss = 54390610245.684448, KLD = 0.0\n",
      "epoch : 36/2000, loss = 54385672343.457336, KLD = 0.0\n",
      "epoch : 37/2000, loss = 54380701988.425232, KLD = 0.0\n",
      "epoch : 38/2000, loss = 54375744175.698189, KLD = 0.0\n",
      "epoch : 39/2000, loss = 54370759640.984383, KLD = 0.0\n",
      "epoch : 40/2000, loss = 54365784603.055092, KLD = 0.0\n",
      "epoch : 41/2000, loss = 54360781958.955650, KLD = 0.0\n",
      "epoch : 42/2000, loss = 54355779151.118553, KLD = 0.0\n",
      "epoch : 43/2000, loss = 54350769302.561897, KLD = 0.0\n",
      "epoch : 44/2000, loss = 54345733550.706810, KLD = 0.0\n",
      "epoch : 45/2000, loss = 54340701204.595131, KLD = 0.0\n",
      "epoch : 46/2000, loss = 54335668269.027855, KLD = 0.0\n",
      "epoch : 47/2000, loss = 54330596658.624359, KLD = 0.0\n",
      "epoch : 48/2000, loss = 54325517418.045723, KLD = 0.0\n",
      "epoch : 49/2000, loss = 54320442565.636475, KLD = 0.0\n",
      "epoch : 50/2000, loss = 54315351896.168892, KLD = 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[39m# compute reconstructions\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     20\u001b[0m \u001b[39m#print(outputs.shape, batch_y.shape)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# compute training reconstruction loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m train_loss \u001b[39m=\u001b[39m criterion(outputs, batch_y\u001b[39m.\u001b[39mview(\u001b[39mlen\u001b[39m(outputs), \u001b[39m1\u001b[39m)) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "epochs = 2000\n",
    "sigma = 1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_array = []\n",
    "#model.load_state_dict(torch.load('../model/param_AE'))\n",
    "model.train()\n",
    "l = len(train_data)\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    kl = 0\n",
    "    permutation = np.random.permutation(l)\n",
    "    for i in range(0, l, BATCH_SIZE):\n",
    "        batch_idc = permutation[i:i+BATCH_SIZE]\n",
    "        batch = train_X[batch_idc,]\n",
    "        batch_y = train_y[batch_idc,]\n",
    "        optimizer.zero_grad()\n",
    "        # compute reconstructions\n",
    "        outputs = model(batch)\n",
    "        #print(outputs.shape, batch_y.shape)\n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_y.view(len(outputs), 1)) \n",
    "        #+ sigma * model.KLD\n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "        #kl += model.KLD\n",
    "        \n",
    "        train_loss /= len(batch)\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1e1)\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss /= l\n",
    "    kl /= l\n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}, KLD = {}\".format(epoch + 1, epochs, loss, kl))\n",
    "    loss_array.append(loss)\n",
    "\n",
    "torch.save(model.state_dict(), '../model/param_AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:tensor([  3.9290,   2.4395,   2.9182,   2.3965, 682.0000])\n",
      "output:tensor([223321.8125])\n",
      "Batch Average Reconstruciton Loss:850316544.0\n",
      "input:tensor([  6.7113,   4.7900,   4.7676,   4.7230, 682.0000])\n",
      "output:tensor([223189.1250])\n",
      "Batch Average Reconstruciton Loss:5682012672.0\n",
      "input:tensor([  3.5383,   1.8735,   2.8511,   1.8065, 682.0000])\n",
      "output:tensor([223347.5156])\n",
      "Batch Average Reconstruciton Loss:3250195456.0\n",
      "input:tensor([  4.2147,   2.8240,   3.0349,   2.8060, 682.0000])\n",
      "output:tensor([223303.1875])\n",
      "Batch Average Reconstruciton Loss:145583824.0\n",
      "input:tensor([  5.2080,   2.7665,   4.1484,   2.7325, 682.0000])\n",
      "output:tensor([223283.1406])\n",
      "Batch Average Reconstruciton Loss:1076308480.0\n",
      "input:tensor([  3.8130,   2.4060,   2.8079,   2.3470, 682.0000])\n",
      "output:tensor([223325.8281])\n",
      "Batch Average Reconstruciton Loss:1356977280.0\n",
      "input:tensor([  4.0013,   2.4005,   3.0274,   2.3255, 682.0000])\n",
      "output:tensor([223322.0781])\n",
      "Batch Average Reconstruciton Loss:604910208.0\n",
      "input:tensor([  4.9070,   3.6165,   3.4725,   3.5375, 682.0000])\n",
      "output:tensor([223264.3750])\n",
      "Batch Average Reconstruciton Loss:445394656.0\n",
      "input:tensor([  3.8610,   2.3430,   2.9147,   2.3110, 682.0000])\n",
      "output:tensor([223325.7344])\n",
      "Batch Average Reconstruciton Loss:1129112192.0\n",
      "input:tensor([  3.9843,   2.5750,   2.9203,   2.5090, 682.0000])\n",
      "output:tensor([223316.9688])\n",
      "Batch Average Reconstruciton Loss:658334592.0\n",
      "input:tensor([  3.8533,   2.4055,   2.8654,   2.3245, 682.0000])\n",
      "output:tensor([223325.3438])\n",
      "Batch Average Reconstruciton Loss:1163741568.0\n",
      "input:tensor([  4.7167,   3.0235,   2.5729,   2.9455, 682.0000])\n",
      "output:tensor([223297.1875])\n",
      "Batch Average Reconstruciton Loss:168459312.0\n",
      "input:tensor([  3.7447,   2.0840,   2.9112,   2.0660, 682.0000])\n",
      "output:tensor([223335.9219])\n",
      "Batch Average Reconstruciton Loss:1728403968.0\n",
      "input:tensor([  4.2450,   2.0770,   3.5378,   2.0350, 682.0000])\n",
      "output:tensor([223324.7500])\n",
      "Batch Average Reconstruciton Loss:107376224.0\n",
      "input:tensor([ 21.0537,   2.9315,  25.7809,   2.8965, 682.0000])\n",
      "output:tensor([222877.0625])\n",
      "Batch Average Reconstruciton Loss:30891247616.0\n",
      "input:tensor([  3.7513,   2.1680,   2.8751,   2.1270, 682.0000])\n",
      "output:tensor([223333.8125])\n",
      "Batch Average Reconstruciton Loss:1689636480.0\n",
      "input:tensor([  5.0953,   3.3375,   3.5489,   3.2485, 682.0000])\n",
      "output:tensor([223271.7500])\n",
      "Batch Average Reconstruciton Loss:817030784.0\n",
      "input:tensor([ 16.4230,   2.3460,  20.0147,   2.3280, 682.0000])\n",
      "output:tensor([223008.5312])\n",
      "Batch Average Reconstruciton Loss:26440558592.0\n",
      "input:tensor([  4.0307,   2.5655,   2.5120,   2.4595, 682.0000])\n",
      "output:tensor([223322.1719])\n",
      "Batch Average Reconstruciton Loss:519421856.0\n",
      "input:tensor([  4.1263,   2.1970,   3.2948,   2.1620, 682.0000])\n",
      "output:tensor([223324.1719])\n",
      "Batch Average Reconstruciton Loss:291823008.0\n",
      "input:tensor([  4.8967,   4.5730,   3.7336,   4.5350, 682.0000])\n",
      "output:tensor([223226.4688])\n",
      "Batch Average Reconstruciton Loss:425987680.0\n",
      "input:tensor([  4.2033,   1.8300,   3.6895,   1.8120, 682.0000])\n",
      "output:tensor([223331.7656])\n",
      "Batch Average Reconstruciton Loss:160560176.0\n",
      "input:tensor([  4.0023,   2.4990,   2.9591,   2.4550, 682.0000])\n",
      "output:tensor([223318.5156])\n",
      "Batch Average Reconstruciton Loss:602039040.0\n",
      "input:tensor([  3.8353,   2.2615,   2.8899,   2.2575, 682.0000])\n",
      "output:tensor([223328.4844])\n",
      "Batch Average Reconstruciton Loss:1247468160.0\n",
      "input:tensor([  4.3960,   2.5725,   3.1693,   2.4205, 682.0000])\n",
      "output:tensor([223312.1562])\n",
      "Batch Average Reconstruciton Loss:5512370.5\n",
      "input:tensor([  3.6567,   2.0210,   2.8533,   2.0030, 682.0000])\n",
      "output:tensor([223339.7188])\n",
      "Batch Average Reconstruciton Loss:2298749952.0\n",
      "input:tensor([ 14.5530,  10.8855,   7.7002,  10.8795, 682.0000])\n",
      "output:tensor([222855.1562])\n",
      "Batch Average Reconstruciton Loss:23929044992.0\n",
      "input:tensor([  4.0267,   2.6645,   2.9252,   2.5875, 682.0000])\n",
      "output:tensor([223313.5312])\n",
      "Batch Average Reconstruciton Loss:531047552.0\n",
      "input:tensor([  4.5267,   2.4385,   3.4904,   2.2925, 682.0000])\n",
      "output:tensor([223311.9688])\n",
      "Batch Average Reconstruciton Loss:17355296.0\n",
      "input:tensor([  4.6957,   3.6150,   2.0371,   3.4340, 682.0000])\n",
      "output:tensor([223284.6250])\n",
      "Batch Average Reconstruciton Loss:144615664.0\n",
      "input:tensor([  3.7783,   2.1875,   2.8882,   2.1465, 682.0000])\n",
      "output:tensor([223332.6875])\n",
      "Batch Average Reconstruciton Loss:1537997568.0\n",
      "input:tensor([  3.6283,   1.9635,   2.8864,   1.8955, 682.0000])\n",
      "output:tensor([223343.])\n",
      "Batch Average Reconstruciton Loss:2506103808.0\n",
      "input:tensor([  5.0260,   2.6910,   4.0034,   2.6310, 682.0000])\n",
      "output:tensor([223289.9844])\n",
      "Batch Average Reconstruciton Loss:671638272.0\n",
      "input:tensor([  5.6110,   5.4290,   4.4027,   5.3480, 682.0000])\n",
      "output:tensor([223182.2500])\n",
      "Batch Average Reconstruciton Loss:2151684096.0\n",
      "input:tensor([  5.0987,   3.1220,   2.9232,   3.1160, 682.0000])\n",
      "output:tensor([223284.0469])\n",
      "Batch Average Reconstruciton Loss:825013440.0\n",
      "input:tensor([ 12.7110,   9.8105,   5.7654,   9.7525, 682.0000])\n",
      "output:tensor([222935.1719])\n",
      "Batch Average Reconstruciton Loss:20993740800.0\n",
      "input:tensor([  3.7823,   2.2325,   2.8806,   2.2155, 682.0000])\n",
      "output:tensor([223330.5312])\n",
      "Batch Average Reconstruciton Loss:1516438016.0\n",
      "input:tensor([  4.9467,   3.4615,   3.5308,   3.3855, 682.0000])\n",
      "output:tensor([223268.7812])\n",
      "Batch Average Reconstruciton Loss:516642944.0\n",
      "input:tensor([  3.8173,   2.3975,   2.6713,   2.2925, 682.0000])\n",
      "output:tensor([223328.7188])\n",
      "Batch Average Reconstruciton Loss:1335046016.0\n",
      "input:tensor([  4.1843,   2.2650,   3.3008,   2.2470, 682.0000])\n",
      "output:tensor([223320.6094])\n",
      "Batch Average Reconstruciton Loss:189183264.0\n",
      "input:tensor([  3.7923,   2.7565,   2.6833,   2.7385, 682.0000])\n",
      "output:tensor([223313.8438])\n",
      "Batch Average Reconstruciton Loss:1464298752.0\n",
      "input:tensor([  3.8777,   1.7915,   3.3286,   1.7305, 682.0000])\n",
      "output:tensor([223341.5625])\n",
      "Batch Average Reconstruciton Loss:1055108736.0\n",
      "input:tensor([  3.7980,   3.0225,   2.5695,   2.8485, 682.0000])\n",
      "output:tensor([223309.4219])\n",
      "Batch Average Reconstruciton Loss:1434938240.0\n",
      "input:tensor([  7.0340,   2.5190,   6.7817,   2.4410, 682.0000])\n",
      "output:tensor([223245.4688])\n",
      "Batch Average Reconstruciton Loss:6759547904.0\n",
      "input:tensor([  3.3687,   2.3355,   2.4080,   2.3185, 682.0000])\n",
      "output:tensor([223336.3125])\n",
      "Batch Average Reconstruciton Loss:5061281792.0\n",
      "input:tensor([  4.4337,   3.1820,   3.1516,   3.1410, 682.0000])\n",
      "output:tensor([223287.4062])\n",
      "Batch Average Reconstruciton Loss:207565.671875\n",
      "input:tensor([  4.7300,   2.6775,   3.4716,   2.5915, 682.0000])\n",
      "output:tensor([223299.9531])\n",
      "Batch Average Reconstruciton Loss:184279360.0\n",
      "input:tensor([  4.0083,   2.6300,   2.7734,   2.5090, 682.0000])\n",
      "output:tensor([223317.6719])\n",
      "Batch Average Reconstruciton Loss:584011392.0\n",
      "input:tensor([  4.2740,   2.4735,   3.2729,   2.4395, 682.0000])\n",
      "output:tensor([223312.9062])\n",
      "Batch Average Reconstruciton Loss:77230592.0\n",
      "input:tensor([  4.1437,   2.7415,   2.1003,   2.6385, 682.0000])\n",
      "output:tensor([223319.0469])\n",
      "Batch Average Reconstruciton Loss:258629216.0\n",
      "input:tensor([  3.5907,   1.8955,   2.8813,   1.8615, 682.0000])\n",
      "output:tensor([223345.])\n",
      "Batch Average Reconstruciton Loss:2801267456.0\n",
      "input:tensor([  4.7827,   3.1815,   3.4509,   3.1465, 682.0000])\n",
      "output:tensor([223280.3281])\n",
      "Batch Average Reconstruciton Loss:251676912.0\n",
      "input:tensor([  3.5590,   2.3435,   2.4593,   2.2135, 682.0000])\n",
      "output:tensor([223336.2812])\n",
      "Batch Average Reconstruciton Loss:3068464128.0\n",
      "input:tensor([ 36.7327,   2.4060,  48.6421,   2.3460, 682.0000])\n",
      "output:tensor([222484.8281])\n",
      "Batch Average Reconstruciton Loss:38211973120.0\n",
      "input:tensor([  3.5800,   2.4230,   2.5782,   2.3180, 682.0000])\n",
      "output:tensor([223331.2969])\n",
      "Batch Average Reconstruciton Loss:2890535680.0\n",
      "input:tensor([  3.1537,   1.7980,   2.4498,   1.7640, 682.0000])\n",
      "output:tensor([223357.7656])\n",
      "Batch Average Reconstruciton Loss:8316935680.0\n",
      "input:tensor([  4.4043,   2.2175,   3.6165,   2.1785, 682.0000])\n",
      "output:tensor([223317.1094])\n",
      "Batch Average Reconstruciton Loss:3670637.0\n",
      "input:tensor([  7.2330,   7.7390,   6.3030,   7.7220, 682.0000])\n",
      "output:tensor([223060.5312])\n",
      "Batch Average Reconstruciton Loss:7380791296.0\n",
      "input:tensor([  3.6943,   2.1270,   2.8451,   2.1090, 682.0000])\n",
      "output:tensor([223335.6406])\n",
      "Batch Average Reconstruciton Loss:2041536000.0\n",
      "input:tensor([  3.8327,   2.2880,   2.8803,   2.2710, 682.0000])\n",
      "output:tensor([223328.0156])\n",
      "Batch Average Reconstruciton Loss:1260248832.0\n",
      "input:tensor([  4.1770,   2.7660,   3.0238,   2.6840, 682.0000])\n",
      "output:tensor([223307.3906])\n",
      "Batch Average Reconstruciton Loss:201174768.0\n",
      "input:tensor([  5.4553,   3.1600,   4.1796,   3.1170, 682.0000])\n",
      "output:tensor([223266.3594])\n",
      "Batch Average Reconstruciton Loss:1716143232.0\n",
      "input:tensor([ 42.5637,  60.1065,  54.9076,  60.0295, 682.0000])\n",
      "output:tensor([220295.5469])\n",
      "Batch Average Reconstruciton Loss:38804881408.0\n",
      "input:tensor([  4.2240,   2.5405,   3.1865,   2.5035, 682.0000])\n",
      "output:tensor([223312.0625])\n",
      "Batch Average Reconstruciton Loss:133077856.0\n",
      "input:tensor([ 31.5223,  23.4030,  22.2896,  23.3860, 682.0000])\n",
      "output:tensor([222071.7500])\n",
      "Batch Average Reconstruciton Loss:36329025536.0\n",
      "input:tensor([  3.6853,   2.0455,   2.8801,   2.0105, 682.0000])\n",
      "output:tensor([223338.6875])\n",
      "Batch Average Reconstruciton Loss:2100967552.0\n",
      "input:tensor([  3.8170,   2.8550,   2.4702,   2.6780, 682.0000])\n",
      "output:tensor([223316.3438])\n",
      "Batch Average Reconstruciton Loss:1337632384.0\n",
      "input:tensor([  3.3940,   2.1905,   2.4797,   2.1485, 682.0000])\n",
      "output:tensor([223341.0781])\n",
      "Batch Average Reconstruciton Loss:4752712704.0\n",
      "input:tensor([  4.6863,   3.0790,   3.4082,   3.0190, 682.0000])\n",
      "output:tensor([223286.1094])\n",
      "Batch Average Reconstruciton Loss:134724992.0\n",
      "input:tensor([  4.3163,   3.0440,   3.0675,   3.0270, 682.0000])\n",
      "output:tensor([223293.8438])\n",
      "Batch Average Reconstruciton Loss:42656000.0\n",
      "input:tensor([  3.4837,   2.2905,   2.5313,   2.2295, 682.0000])\n",
      "output:tensor([223336.4688])\n",
      "Batch Average Reconstruciton Loss:3772481536.0\n",
      "input:tensor([  3.7713,   2.2590,   2.8571,   2.1800, 682.0000])\n",
      "output:tensor([223331.5312])\n",
      "Batch Average Reconstruciton Loss:1576524288.0\n",
      "input:tensor([  3.8123,   1.8285,   3.2771,   1.6385, 682.0000])\n",
      "output:tensor([223344.7188])\n",
      "Batch Average Reconstruciton Loss:1358901504.0\n",
      "input:tensor([  4.4180,   2.5935,   3.3622,   2.5595, 682.0000])\n",
      "output:tensor([223306.1406])\n",
      "Batch Average Reconstruciton Loss:1512554.125\n",
      "input:tensor([  3.9880,   3.0085,   1.6226,   3.0025, 682.0000])\n",
      "output:tensor([223313.8438])\n",
      "Batch Average Reconstruciton Loss:646794560.0\n",
      "input:tensor([ 12.7503,   2.1455,  15.1726,   2.0415, 682.0000])\n",
      "output:tensor([223108.7812])\n",
      "Batch Average Reconstruciton Loss:21114060800.0\n",
      "input:tensor([  3.5897,   2.3435,   2.6088,   2.3385, 682.0000])\n",
      "output:tensor([223331.2188])\n",
      "Batch Average Reconstruciton Loss:2810885120.0\n",
      "input:tensor([  3.7400,   2.1405,   2.8671,   2.1365, 682.0000])\n",
      "output:tensor([223334.0781])\n",
      "Batch Average Reconstruciton Loss:1756190080.0\n",
      "input:tensor([  4.8150,   2.4950,   3.8999,   2.4190, 682.0000])\n",
      "output:tensor([223300.7500])\n",
      "Batch Average Reconstruciton Loss:298520640.0\n",
      "input:tensor([  6.4320,   3.4070,   5.1230,   3.3710, 682.0000])\n",
      "output:tensor([223236.8750])\n",
      "Batch Average Reconstruciton Loss:4762086912.0\n",
      "input:tensor([  3.7510,   2.1090,   2.9091,   2.0740, 682.0000])\n",
      "output:tensor([223335.4062])\n",
      "Batch Average Reconstruciton Loss:1691478912.0\n",
      "input:tensor([  5.8347,   2.9610,   4.5497,   2.8550, 682.0000])\n",
      "output:tensor([223267.0469])\n",
      "Batch Average Reconstruciton Loss:2835461120.0\n",
      "input:tensor([  3.5563,   2.4035,   2.3848,   2.2865, 682.0000])\n",
      "output:tensor([223334.6250])\n",
      "Batch Average Reconstruciton Loss:3091846400.0\n",
      "input:tensor([  4.3060,   2.0640,   3.6190,   2.0230, 682.0000])\n",
      "output:tensor([223323.6562])\n",
      "Batch Average Reconstruciton Loss:49735552.0\n",
      "input:tensor([  3.7560,   2.1580,   2.8784,   2.1180, 682.0000])\n",
      "output:tensor([223334.0625])\n",
      "Batch Average Reconstruciton Loss:1662758656.0\n",
      "input:tensor([  7.0140,   6.6175,   1.3537,   6.5215, 682.0000])\n",
      "output:tensor([223157.9531])\n",
      "Batch Average Reconstruciton Loss:6679294976.0\n",
      "input:tensor([  3.4883,   1.7335,   2.8788,   1.6895, 682.0000])\n",
      "output:tensor([223352.1719])\n",
      "Batch Average Reconstruciton Loss:3724029696.0\n",
      "input:tensor([  3.8837,   2.3450,   2.9016,   2.3280, 682.0000])\n",
      "output:tensor([223325.2031])\n",
      "Batch Average Reconstruciton Loss:1030653760.0\n",
      "input:tensor([  3.6093,   2.5085,   2.5807,   2.4665, 682.0000])\n",
      "output:tensor([223326.3281])\n",
      "Batch Average Reconstruciton Loss:2653967360.0\n",
      "input:tensor([  7.2523,   3.7630,   5.8447,   3.7210, 682.0000])\n",
      "output:tensor([223207.8594])\n",
      "Batch Average Reconstruciton Loss:7469083648.0\n",
      "input:tensor([  6.6057,   4.9660,   4.6679,   4.9220, 682.0000])\n",
      "output:tensor([223184.4375])\n",
      "Batch Average Reconstruciton Loss:5330524160.0\n",
      "input:tensor([  4.6590,   2.5510,   3.6574,   2.4910, 682.0000])\n",
      "output:tensor([223302.5938])\n",
      "Batch Average Reconstruciton Loss:107777488.0\n",
      "input:tensor([  4.0037,   2.5675,   2.9330,   2.5295, 682.0000])\n",
      "output:tensor([223316.1719])\n",
      "Batch Average Reconstruciton Loss:598136448.0\n",
      "input:tensor([  4.1940,   1.8205,   3.7039,   1.7585, 682.0000])\n",
      "output:tensor([223333.1719])\n",
      "Batch Average Reconstruciton Loss:174103488.0\n",
      "input:tensor([  4.5907,   2.9360,   3.3638,   2.9020, 682.0000])\n",
      "output:tensor([223292.0625])\n",
      "Batch Average Reconstruciton Loss:51855300.0\n",
      "input:tensor([  3.5533,   2.3895,   2.5662,   2.3715, 682.0000])\n",
      "output:tensor([223330.7500])\n",
      "Batch Average Reconstruciton Loss:3118468608.0\n",
      "input:tensor([  3.3843,   2.1235,   2.5028,   2.0895, 682.0000])\n",
      "output:tensor([223343.1250])\n",
      "Batch Average Reconstruciton Loss:4868114432.0\n",
      "input:tensor([  4.3123,   2.5480,   3.2812,   2.5130, 682.0000])\n",
      "output:tensor([223309.7656])\n",
      "Batch Average Reconstruciton Loss:45269136.0\n",
      "input:tensor([  3.6100,   2.5090,   2.5815,   2.4820, 682.0000])\n",
      "output:tensor([223325.9375])\n",
      "Batch Average Reconstruciton Loss:2648755712.0\n",
      "input:tensor([  4.3623,   2.4970,   3.3678,   2.4390, 682.0000])\n",
      "output:tensor([223310.7344])\n",
      "Batch Average Reconstruciton Loss:16730273.0\n",
      "input:tensor([  4.0067,   2.6325,   2.9151,   2.5725, 682.0000])\n",
      "output:tensor([223314.5625])\n",
      "Batch Average Reconstruciton Loss:589151232.0\n",
      "input:tensor([  4.1153,   2.7455,   2.9816,   2.7115, 682.0000])\n",
      "output:tensor([223308.])\n",
      "Batch Average Reconstruciton Loss:314778560.0\n",
      "input:tensor([  3.1760,   1.8190,   2.4598,   1.7590, 682.0000])\n",
      "output:tensor([223357.3438])\n",
      "Batch Average Reconstruciton Loss:7918447104.0\n",
      "input:tensor([  4.4763,   3.8315,   3.2269,   3.7035, 682.0000])\n",
      "output:tensor([223265.1250])\n",
      "Batch Average Reconstruciton Loss:2739438.75\n",
      "input:tensor([  4.5237,   3.7525,   3.2378,   3.7465, 682.0000])\n",
      "output:tensor([223264.2500])\n",
      "Batch Average Reconstruciton Loss:15786716.0\n",
      "input:tensor([  4.5987,   3.9010,   3.3151,   3.8600, 682.0000])\n",
      "output:tensor([223258.2188])\n",
      "Batch Average Reconstruciton Loss:56900148.0\n",
      "input:tensor([  5.5177,   3.3120,   4.1582,   3.2330, 682.0000])\n",
      "output:tensor([223261.4219])\n",
      "Batch Average Reconstruciton Loss:1890112256.0\n",
      "input:tensor([  7.6200,   5.1280,   3.6892,   5.0930, 682.0000])\n",
      "output:tensor([223178.1406])\n",
      "Batch Average Reconstruciton Loss:8647910400.0\n",
      "input:tensor([  3.6933,   2.5920,   2.6302,   2.5570, 682.0000])\n",
      "output:tensor([223321.7656])\n",
      "Batch Average Reconstruciton Loss:2049394176.0\n",
      "input:tensor([  4.3810,   2.6095,   3.3071,   2.5745, 682.0000])\n",
      "output:tensor([223306.5781])\n",
      "Batch Average Reconstruciton Loss:9768262.0\n",
      "input:tensor([ 36.2937,  27.2680,  25.6607,  27.1910, 682.0000])\n",
      "output:tensor([221848.3906])\n",
      "Batch Average Reconstruciton Loss:37836238848.0\n",
      "input:tensor([  3.9887,   2.5495,   2.9423,   2.4705, 682.0000])\n",
      "output:tensor([223317.9219])\n",
      "Batch Average Reconstruciton Loss:644503744.0\n",
      "input:tensor([  3.5957,   2.4420,   2.5851,   2.3830, 682.0000])\n",
      "output:tensor([223329.2812])\n",
      "Batch Average Reconstruciton Loss:2762418944.0\n",
      "input:tensor([  5.5953,   4.8935,   1.2435,   4.8755, 682.0000])\n",
      "output:tensor([223233.7969])\n",
      "Batch Average Reconstruciton Loss:2110740608.0\n",
      "input:tensor([  3.9827,   2.5720,   2.9059,   2.5550, 682.0000])\n",
      "output:tensor([223316.])\n",
      "Batch Average Reconstruciton Loss:663732160.0\n",
      "input:tensor([  5.1693,   3.2640,   2.9098,   3.1600, 682.0000])\n",
      "output:tensor([223280.8281])\n",
      "Batch Average Reconstruciton Loss:984693632.0\n",
      "input:tensor([  4.5310,   2.5635,   3.5052,   2.5025, 682.0000])\n",
      "output:tensor([223305.1719])\n",
      "Batch Average Reconstruciton Loss:19089662.0\n",
      "input:tensor([  4.0813,   2.1975,   3.2565,   2.1635, 682.0000])\n",
      "output:tensor([223324.9844])\n",
      "Batch Average Reconstruciton Loss:389391904.0\n",
      "input:tensor([  5.7673,   3.0855,   4.5695,   3.0505, 682.0000])\n",
      "output:tensor([223261.3125])\n",
      "Batch Average Reconstruciton Loss:2627414528.0\n",
      "input:tensor([  4.5243,   2.3775,   3.6512,   2.3025, 682.0000])\n",
      "output:tensor([223310.6562])\n",
      "Batch Average Reconstruciton Loss:16415918.0\n",
      "input:tensor([  3.9920,   2.5385,   2.9365,   2.4635, 682.0000])\n",
      "output:tensor([223318.2188])\n",
      "Batch Average Reconstruciton Loss:633971008.0\n",
      "input:tensor([  4.9733,   2.4835,   4.0811,   2.4655, 682.0000])\n",
      "output:tensor([223296.0469])\n",
      "Batch Average Reconstruciton Loss:567966464.0\n",
      "input:tensor([  2.9933,   2.0750,   2.1507,   2.0070, 682.0000])\n",
      "output:tensor([223353.6406])\n",
      "Batch Average Reconstruciton Loss:11674663936.0\n",
      "input:tensor([ 17.7093,   2.3565,  21.8229,   2.3205, 682.0000])\n",
      "output:tensor([222975.5781])\n",
      "Batch Average Reconstruciton Loss:27875500032.0\n",
      "input:tensor([  4.0287,   3.1015,   2.8448,   3.0685, 682.0000])\n",
      "output:tensor([223297.6562])\n",
      "Batch Average Reconstruciton Loss:526121728.0\n",
      "input:tensor([  3.9453,   2.4975,   2.9039,   2.4635, 682.0000])\n",
      "output:tensor([223319.5156])\n",
      "Batch Average Reconstruciton Loss:790536704.0\n",
      "input:tensor([  4.0953,   2.6470,   2.9856,   2.6410, 682.0000])\n",
      "output:tensor([223310.9844])\n",
      "Batch Average Reconstruciton Loss:357815648.0\n",
      "input:tensor([  3.8460,   1.8000,   3.2817,   1.7590, 682.0000])\n",
      "output:tensor([223341.5938])\n",
      "Batch Average Reconstruciton Loss:1196357888.0\n",
      "input:tensor([  4.4057,   2.1745,   3.6714,   2.0705, 682.0000])\n",
      "output:tensor([223319.6719])\n",
      "Batch Average Reconstruciton Loss:3405236.0\n",
      "input:tensor([  3.5547,   1.8885,   2.8489,   1.8115, 682.0000])\n",
      "output:tensor([223347.0625])\n",
      "Batch Average Reconstruciton Loss:3105045760.0\n",
      "input:tensor([  3.5897,   2.9060,   2.5524,   2.8880, 682.0000])\n",
      "output:tensor([223312.0625])\n",
      "Batch Average Reconstruciton Loss:2812916736.0\n",
      "input:tensor([  3.6180,   2.5815,   2.5711,   2.5365, 682.0000])\n",
      "output:tensor([223323.8281])\n",
      "Batch Average Reconstruciton Loss:2586858752.0\n",
      "input:tensor([  3.6587,   2.5435,   2.6111,   2.5095, 682.0000])\n",
      "output:tensor([223324.0469])\n",
      "Batch Average Reconstruciton Loss:2286078464.0\n",
      "input:tensor([  4.7173,   2.6210,   3.6833,   2.5820, 682.0000])\n",
      "output:tensor([223298.6562])\n",
      "Batch Average Reconstruciton Loss:169277184.0\n",
      "input:tensor([ 35.4170,  26.2440,  25.0466,  26.2010, 682.0000])\n",
      "output:tensor([221900.0312])\n",
      "Batch Average Reconstruciton Loss:37593731072.0\n",
      "input:tensor([  3.5980,   2.5145,   2.3791,   2.4055, 682.0000])\n",
      "output:tensor([223330.0938])\n",
      "Batch Average Reconstruciton Loss:2743549696.0\n",
      "input:tensor([  4.9937,   4.0030,   3.5429,   3.9350, 682.0000])\n",
      "output:tensor([223248.6094])\n",
      "Batch Average Reconstruciton Loss:604993216.0\n",
      "input:tensor([  3.6700,   2.5515,   2.6207,   2.5085, 682.0000])\n",
      "output:tensor([223323.7656])\n",
      "Batch Average Reconstruciton Loss:2206766592.0\n",
      "input:tensor([  3.8623,   2.3065,   2.9252,   2.2395, 682.0000])\n",
      "output:tensor([223327.8125])\n",
      "Batch Average Reconstruciton Loss:1123066752.0\n",
      "input:tensor([  3.9877,   2.5065,   2.9508,   2.4005, 682.0000])\n",
      "output:tensor([223320.0312])\n",
      "Batch Average Reconstruciton Loss:647548224.0\n",
      "input:tensor([  3.8947,   2.9020,   2.7540,   2.8430, 682.0000])\n",
      "output:tensor([223307.8281])\n",
      "Batch Average Reconstruciton Loss:985907968.0\n",
      "input:tensor([  3.8077,   1.7255,   3.2787,   1.7065, 682.0000])\n",
      "output:tensor([223344.1406])\n",
      "Batch Average Reconstruciton Loss:1382564992.0\n",
      "input:tensor([  4.8043,   3.0645,   2.6208,   3.0615, 682.0000])\n",
      "output:tensor([223292.3750])\n",
      "Batch Average Reconstruciton Loss:282655968.0\n",
      "input:tensor([  3.2693,   2.6555,   2.3202,   2.6385, 682.0000])\n",
      "output:tensor([223326.8906])\n",
      "Batch Average Reconstruciton Loss:6415867392.0\n",
      "input:tensor([  5.0547,   4.0910,   2.1974,   3.9950, 682.0000])\n",
      "output:tensor([223259.9688])\n",
      "Batch Average Reconstruciton Loss:729322368.0\n",
      "input:tensor([  3.8670,   3.1655,   2.7566,   3.1585, 682.0000])\n",
      "output:tensor([223297.3750])\n",
      "Batch Average Reconstruciton Loss:1104407424.0\n",
      "input:tensor([  4.9240,   2.5260,   4.0385,   2.4200, 682.0000])\n",
      "output:tensor([223297.7500])\n",
      "Batch Average Reconstruciton Loss:476799968.0\n",
      "input:tensor([  4.8337,   2.9910,   3.5826,   2.9850, 682.0000])\n",
      "output:tensor([223284.4531])\n",
      "Batch Average Reconstruciton Loss:326071616.0\n",
      "input:tensor([  4.4573,   2.1135,   3.7686,   2.0795, 682.0000])\n",
      "output:tensor([223318.5156])\n",
      "Batch Average Reconstruciton Loss:582956.125\n",
      "input:tensor([  3.1517,   1.7555,   2.4557,   1.7205, 682.0000])\n",
      "output:tensor([223359.2500])\n",
      "Batch Average Reconstruciton Loss:8353000448.0\n",
      "input:tensor([  4.4973,   3.3105,   3.1792,   3.2765, 682.0000])\n",
      "output:tensor([223281.6562])\n",
      "Batch Average Reconstruciton Loss:7325988.0\n",
      "input:tensor([  4.5460,   3.2140,   3.2385,   3.1450, 682.0000])\n",
      "output:tensor([223284.8438])\n",
      "Batch Average Reconstruciton Loss:25713456.0\n",
      "input:tensor([  3.3293,   2.0360,   2.4838,   2.0310, 682.0000])\n",
      "output:tensor([223346.3125])\n",
      "Batch Average Reconstruciton Loss:5566903808.0\n",
      "input:tensor([  3.5630,   1.9020,   2.8635,   1.8620, 682.0000])\n",
      "output:tensor([223345.4219])\n",
      "Batch Average Reconstruciton Loss:3032878592.0\n",
      "input:tensor([  3.9560,   2.4830,   2.9293,   2.4160, 682.0000])\n",
      "output:tensor([223320.4688])\n",
      "Batch Average Reconstruciton Loss:752818112.0\n",
      "input:tensor([  9.1373,   3.7020,   8.3095,   3.6680, 682.0000])\n",
      "output:tensor([223163.3906])\n",
      "Batch Average Reconstruciton Loss:13132562432.0\n",
      "input:tensor([  3.8080,   2.2575,   2.9044,   2.2175, 682.0000])\n",
      "output:tensor([223329.6719])\n",
      "Batch Average Reconstruciton Loss:1381930624.0\n",
      "input:tensor([  5.0943,   4.6080,   3.7846,   4.5080, 682.0000])\n",
      "output:tensor([223224.1562])\n",
      "Batch Average Reconstruciton Loss:812144896.0\n",
      "input:tensor([  4.3703,   2.0975,   3.6674,   2.0375, 682.0000])\n",
      "output:tensor([223321.7500])\n",
      "Batch Average Reconstruciton Loss:13419401.0\n",
      "input:tensor([  4.2630,   2.9490,   3.0530,   2.9090, 682.0000])\n",
      "output:tensor([223298.5625])\n",
      "Batch Average Reconstruciton Loss:88387024.0\n",
      "input:tensor([  3.8117,   1.7760,   3.2633,   1.7160, 682.0000])\n",
      "output:tensor([223343.4844])\n",
      "Batch Average Reconstruciton Loss:1362386176.0\n",
      "input:tensor([  3.7697,   2.7825,   2.6647,   2.7475, 682.0000])\n",
      "output:tensor([223313.7812])\n",
      "Batch Average Reconstruciton Loss:1587163392.0\n",
      "input:tensor([  4.5673,   2.8925,   3.3560,   2.8585, 682.0000])\n",
      "output:tensor([223293.9531])\n",
      "Batch Average Reconstruciton Loss:37197228.0\n",
      "input:tensor([  3.6780,   2.5310,   2.6327,   2.4920, 682.0000])\n",
      "output:tensor([223324.1719])\n",
      "Batch Average Reconstruciton Loss:2151830528.0\n",
      "input:tensor([  3.6637,   2.5195,   2.6262,   2.4585, 682.0000])\n",
      "output:tensor([223325.3750])\n",
      "Batch Average Reconstruciton Loss:2250707712.0\n",
      "input:tensor([  5.2577,   3.1705,   3.1033,   3.1065, 682.0000])\n",
      "output:tensor([223280.1562])\n",
      "Batch Average Reconstruciton Loss:1197378432.0\n",
      "input:tensor([  5.3163,   4.8705,   3.9952,   4.7895, 682.0000])\n",
      "output:tensor([223209.6719])\n",
      "Batch Average Reconstruciton Loss:1340634240.0\n",
      "input:tensor([  3.9047,   1.6765,   3.4613,   1.6425, 682.0000])\n",
      "output:tensor([223343.2812])\n",
      "Batch Average Reconstruciton Loss:943209664.0\n",
      "input:tensor([  3.5560,   2.3845,   2.5581,   2.3785, 682.0000])\n",
      "output:tensor([223330.6875])\n",
      "Batch Average Reconstruciton Loss:3095176704.0\n",
      "input:tensor([  4.3067,   2.9530,   3.0796,   2.9110, 682.0000])\n",
      "output:tensor([223297.7188])\n",
      "Batch Average Reconstruciton Loss:49607812.0\n",
      "input:tensor([  3.9480,   1.9240,   3.2933,   1.8900, 682.0000])\n",
      "output:tensor([223335.7812])\n",
      "Batch Average Reconstruciton Loss:780097088.0\n",
      "input:tensor([  8.9987,   5.6950,   6.6104,   5.6520, 682.0000])\n",
      "output:tensor([223112.1406])\n",
      "Batch Average Reconstruciton Loss:12740345856.0\n",
      "input:tensor([  4.7147,   3.0455,   2.5544,   2.9475, 682.0000])\n",
      "output:tensor([223297.1094])\n",
      "Batch Average Reconstruciton Loss:166154912.0\n",
      "input:tensor([  3.4743,   1.7490,   2.8699,   1.7320, 682.0000])\n",
      "output:tensor([223351.1719])\n",
      "Batch Average Reconstruciton Loss:3865211904.0\n",
      "input:tensor([  4.7033,   3.5105,   1.7752,   3.4365, 682.0000])\n",
      "output:tensor([223288.3750])\n",
      "Batch Average Reconstruciton Loss:153125152.0\n",
      "input:tensor([  4.0437,   2.6515,   2.9330,   2.6345, 682.0000])\n",
      "output:tensor([223312.2344])\n",
      "Batch Average Reconstruciton Loss:484429792.0\n",
      "input:tensor([  3.7317,   2.3435,   2.7472,   2.3095, 682.0000])\n",
      "output:tensor([223328.9688])\n",
      "Batch Average Reconstruciton Loss:1806592640.0\n",
      "input:tensor([  3.8907,   2.3365,   2.9178,   2.3025, 682.0000])\n",
      "output:tensor([223325.6875])\n",
      "Batch Average Reconstruciton Loss:1001299200.0\n",
      "input:tensor([  4.1427,   2.2515,   3.2636,   2.1915, 682.0000])\n",
      "output:tensor([223322.9844])\n",
      "Batch Average Reconstruciton Loss:260371008.0\n",
      "input:tensor([  3.6157,   2.0035,   2.8290,   1.9685, 682.0000])\n",
      "output:tensor([223341.4844])\n",
      "Batch Average Reconstruciton Loss:2603092992.0\n",
      "input:tensor([  4.4157,   2.3160,   3.5583,   2.2820, 682.0000])\n",
      "output:tensor([223314.])\n",
      "Batch Average Reconstruciton Loss:1798281.0\n",
      "input:tensor([  4.8623,   2.3435,   4.0695,   2.3135, 682.0000])\n",
      "output:tensor([223302.6562])\n",
      "Batch Average Reconstruciton Loss:371936544.0\n",
      "input:tensor([  4.8193,   3.1635,   3.4678,   3.1245, 682.0000])\n",
      "output:tensor([223280.5312])\n",
      "Batch Average Reconstruciton Loss:304241888.0\n",
      "input:tensor([  4.1267,   1.7265,   3.7071,   1.7095, 682.0000])\n",
      "output:tensor([223336.0625])\n",
      "Batch Average Reconstruciton Loss:290768576.0\n",
      "input:tensor([  4.3107,   2.4585,   3.3017,   2.4405, 682.0000])\n",
      "output:tensor([223312.3438])\n",
      "Batch Average Reconstruciton Loss:46439540.0\n",
      "input:tensor([  3.7180,   2.6485,   2.6470,   2.5835, 682.0000])\n",
      "output:tensor([223320.0781])\n",
      "Batch Average Reconstruciton Loss:1891373312.0\n",
      "input:tensor([  4.6450,   2.1490,   3.9631,   2.1310, 682.0000])\n",
      "output:tensor([223312.7500])\n",
      "Batch Average Reconstruciton Loss:95057624.0\n",
      "input:tensor([  4.6630,   3.0305,   2.4324,   3.0245, 682.0000])\n",
      "output:tensor([223297.1875])\n",
      "Batch Average Reconstruciton Loss:111475320.0\n",
      "input:tensor([  3.3150,   2.0695,   2.4595,   2.0095, 682.0000])\n",
      "output:tensor([223346.9062])\n",
      "Batch Average Reconstruciton Loss:5760672256.0\n",
      "input:tensor([  3.7510,   2.6180,   1.6660,   2.5840, 682.0000])\n",
      "output:tensor([223330.5469])\n",
      "Batch Average Reconstruciton Loss:1691878656.0\n",
      "input:tensor([  3.9160,   2.1345,   3.0973,   2.1005, 682.0000])\n",
      "output:tensor([223330.7188])\n",
      "Batch Average Reconstruciton Loss:899356992.0\n",
      "input:tensor([  3.2050,   1.8800,   2.4465,   1.8380, 682.0000])\n",
      "output:tensor([223354.5156])\n",
      "Batch Average Reconstruciton Loss:7423801344.0\n",
      "input:tensor([  4.7773,   3.3055,   3.4161,   3.2085, 682.0000])\n",
      "output:tensor([223277.9062])\n",
      "Batch Average Reconstruciton Loss:244325232.0\n",
      "input:tensor([  4.1157,   3.2425,   1.5674,   3.2365, 682.0000])\n",
      "output:tensor([223304.7031])\n",
      "Batch Average Reconstruciton Loss:314186144.0\n",
      "input:tensor([  5.6327,   4.9225,   4.1251,   4.9045, 682.0000])\n",
      "output:tensor([223201.5000])\n",
      "Batch Average Reconstruciton Loss:2217044224.0\n",
      "input:tensor([  4.0343,   2.0725,   3.3041,   2.0555, 682.0000])\n",
      "output:tensor([223329.0312])\n",
      "Batch Average Reconstruciton Loss:508952192.0\n",
      "input:tensor([  3.8170,   2.7600,   2.7074,   2.7260, 682.0000])\n",
      "output:tensor([223313.5938])\n",
      "Batch Average Reconstruciton Loss:1337833472.0\n",
      "input:tensor([ 28.7487,  20.6770,  20.3848,  20.6090, 682.0000])\n",
      "output:tensor([222220.2500])\n",
      "Batch Average Reconstruciton Loss:35236638720.0\n",
      "input:tensor([  4.0077,   2.0150,   3.2734,   1.9980, 682.0000])\n",
      "output:tensor([223331.7031])\n",
      "Batch Average Reconstruciton Loss:585364032.0\n",
      "input:tensor([  6.5193,   7.3260,   6.0740,   7.3080, 682.0000])\n",
      "output:tensor([223085.3438])\n",
      "Batch Average Reconstruciton Loss:5029978624.0\n",
      "input:tensor([  6.3783,   3.1200,   5.2892,   3.0820, 682.0000])\n",
      "output:tensor([223245.9688])\n",
      "Batch Average Reconstruciton Loss:4585858560.0\n",
      "input:tensor([  4.8723,   3.7335,   3.4414,   3.6635, 682.0000])\n",
      "output:tensor([223260.6875])\n",
      "Batch Average Reconstruciton Loss:386581952.0\n",
      "input:tensor([  3.6110,   2.4755,   2.5796,   2.4575, 682.0000])\n",
      "output:tensor([223326.9062])\n",
      "Batch Average Reconstruciton Loss:2640838912.0\n",
      "input:tensor([  5.2107,   5.8490,   4.7402,   5.6610, 682.0000])\n",
      "output:tensor([223170.5625])\n",
      "Batch Average Reconstruciton Loss:1075286528.0\n",
      "input:tensor([  3.9200,   2.9385,   2.7700,   2.8575, 682.0000])\n",
      "output:tensor([223306.6406])\n",
      "Batch Average Reconstruciton Loss:885321920.0\n",
      "input:tensor([  4.3903,   2.6040,   3.3104,   2.5690, 682.0000])\n",
      "output:tensor([223306.6562])\n",
      "Batch Average Reconstruciton Loss:6992554.0\n",
      "input:tensor([  2.8073,   1.7870,   2.0777,   1.7260, 682.0000])\n",
      "output:tensor([223366.4844])\n",
      "Batch Average Reconstruciton Loss:16898314240.0\n",
      "input:tensor([  4.2800,   2.4505,   3.2929,   2.4095, 682.0000])\n",
      "output:tensor([223313.6250])\n",
      "Batch Average Reconstruciton Loss:71611792.0\n",
      "input:tensor([  4.6030,   2.1485,   3.9097,   2.1125, 682.0000])\n",
      "output:tensor([223314.2500])\n",
      "Batch Average Reconstruciton Loss:60875104.0\n",
      "input:tensor([  4.0053,   3.1240,   2.8296,   3.0590, 682.0000])\n",
      "output:tensor([223298.0469])\n",
      "Batch Average Reconstruciton Loss:593992128.0\n",
      "input:tensor([  3.8047,   1.7810,   3.2800,   1.6770, 682.0000])\n",
      "output:tensor([223344.3125])\n",
      "Batch Average Reconstruciton Loss:1397839232.0\n",
      "input:tensor([  3.7653,   2.1440,   2.9085,   2.1100, 682.0000])\n",
      "output:tensor([223334.])\n",
      "Batch Average Reconstruciton Loss:1609774848.0\n",
      "input:tensor([  3.2673,   1.9445,   2.4736,   1.9025, 682.0000])\n",
      "output:tensor([223351.2656])\n",
      "Batch Average Reconstruciton Loss:6441785344.0\n",
      "input:tensor([  3.9003,   2.3415,   2.9200,   2.3345, 682.0000])\n",
      "output:tensor([223324.7031])\n",
      "Batch Average Reconstruciton Loss:961762560.0\n",
      "input:tensor([  4.2767,   3.3055,   3.0226,   3.3005, 682.0000])\n",
      "output:tensor([223285.1250])\n",
      "Batch Average Reconstruciton Loss:75184072.0\n",
      "input:tensor([  3.6463,   2.5160,   2.6122,   2.4460, 682.0000])\n",
      "output:tensor([223326.0469])\n",
      "Batch Average Reconstruciton Loss:2374413312.0\n",
      "input:tensor([  3.3903,   2.1780,   2.4967,   2.1140, 682.0000])\n",
      "output:tensor([223341.9219])\n",
      "Batch Average Reconstruciton Loss:4796265984.0\n",
      "input:tensor([  3.7610,   2.1225,   2.7517,   2.0515, 682.0000])\n",
      "output:tensor([223337.4219])\n",
      "Batch Average Reconstruciton Loss:1633984768.0\n",
      "input:tensor([  4.2837,   2.8710,   3.0746,   2.8650, 682.0000])\n",
      "output:tensor([223300.0312])\n",
      "Batch Average Reconstruciton Loss:68508208.0\n",
      "input:tensor([  4.1173,   1.7870,   3.6944,   1.7470, 682.0000])\n",
      "output:tensor([223334.7188])\n",
      "Batch Average Reconstruciton Loss:309699488.0\n",
      "input:tensor([  6.3943,   2.5065,   5.9104,   2.4665, 682.0000])\n",
      "output:tensor([223261.0938])\n",
      "Batch Average Reconstruciton Loss:4640891904.0\n",
      "input:tensor([  3.6200,   2.4960,   2.5901,   2.4620, 682.0000])\n",
      "output:tensor([223326.3750])\n",
      "Batch Average Reconstruciton Loss:2571161856.0\n",
      "input:tensor([  3.3860,   2.0730,   2.5334,   2.0350, 682.0000])\n",
      "output:tensor([223344.6875])\n",
      "Batch Average Reconstruciton Loss:4847823360.0\n",
      "input:tensor([  4.1930,   2.3140,   3.2875,   2.3070, 682.0000])\n",
      "output:tensor([223318.6562])\n",
      "Batch Average Reconstruciton Loss:175995872.0\n",
      "input:tensor([  4.2900,   2.4675,   3.2909,   2.4085, 682.0000])\n",
      "output:tensor([223313.3906])\n",
      "Batch Average Reconstruciton Loss:62751896.0\n",
      "input:tensor([  3.9990,   2.5555,   2.9231,   2.5375, 682.0000])\n",
      "output:tensor([223316.2500])\n",
      "Batch Average Reconstruciton Loss:612352128.0\n",
      "input:tensor([  4.1640,   2.2635,   3.2917,   2.2565, 682.0000])\n",
      "output:tensor([223320.7031])\n",
      "Batch Average Reconstruciton Loss:222346768.0\n",
      "input:tensor([  4.6773,   3.4380,   3.3070,   3.4040, 682.0000])\n",
      "output:tensor([223273.8281])\n",
      "Batch Average Reconstruciton Loss:125145120.0\n",
      "input:tensor([ 31.5437,  24.9815,  22.2005,  24.9455, 682.0000])\n",
      "output:tensor([222016.5781])\n",
      "Batch Average Reconstruciton Loss:36316381184.0\n",
      "input:tensor([  3.7230,   2.5795,   2.6624,   2.5405, 682.0000])\n",
      "output:tensor([223321.6562])\n",
      "Batch Average Reconstruciton Loss:1860226560.0\n",
      "input:tensor([ 34.0537,   1.7640,  45.7842,   1.7290, 682.0000])\n",
      "output:tensor([222566.2188])\n",
      "Batch Average Reconstruciton Loss:37417570304.0\n",
      "input:tensor([  6.3607,   6.1125,   4.9644,   6.0435, 682.0000])\n",
      "output:tensor([223143.5469])\n",
      "Batch Average Reconstruciton Loss:4513897472.0\n",
      "input:tensor([  3.7787,   2.1880,   2.8888,   2.1530, 682.0000])\n",
      "output:tensor([223332.5156])\n",
      "Batch Average Reconstruciton Loss:1536129280.0\n",
      "input:tensor([  3.6157,   2.4665,   2.5885,   2.4485, 682.0000])\n",
      "output:tensor([223327.0781])\n",
      "Batch Average Reconstruciton Loss:2604563200.0\n",
      "input:tensor([  5.4423,   4.2615,   3.8491,   4.1955, 682.0000])\n",
      "output:tensor([223231.2812])\n",
      "Batch Average Reconstruciton Loss:1677416960.0\n",
      "input:tensor([  4.0090,   2.5835,   2.9266,   2.5485, 682.0000])\n",
      "output:tensor([223315.5312])\n",
      "Batch Average Reconstruciton Loss:582134720.0\n",
      "input:tensor([  3.9583,   2.4405,   2.9536,   2.4065, 682.0000])\n",
      "output:tensor([223320.8750])\n",
      "Batch Average Reconstruciton Loss:744750912.0\n",
      "input:tensor([  4.1223,   2.6885,   2.9956,   2.6715, 682.0000])\n",
      "output:tensor([223309.4062])\n",
      "Batch Average Reconstruciton Loss:300349472.0\n",
      "input:tensor([  5.3630,   3.6340,   3.8648,   3.4990, 682.0000])\n",
      "output:tensor([223256.0938])\n",
      "Batch Average Reconstruciton Loss:1465748352.0\n",
      "input:tensor([ 23.1633,  17.2490,  16.3765,  17.2130, 682.0000])\n",
      "output:tensor([222444.1875])\n",
      "Batch Average Reconstruciton Loss:32262692864.0\n",
      "input:tensor([  3.7897,   1.7200,   3.2837,   1.7030, 682.0000])\n",
      "output:tensor([223344.4219])\n",
      "Batch Average Reconstruciton Loss:1476064000.0\n",
      "input:tensor([  3.8347,   2.3190,   2.8924,   2.2850, 682.0000])\n",
      "output:tensor([223327.1875])\n",
      "Batch Average Reconstruciton Loss:1250740736.0\n",
      "input:tensor([ 16.8513,   4.0900,  18.0637,   4.0840, 682.0000])\n",
      "output:tensor([222962.3281])\n",
      "Batch Average Reconstruciton Loss:26926948352.0\n",
      "input:tensor([  3.7547,   2.3730,   2.7766,   2.3300, 682.0000])\n",
      "output:tensor([223327.5781])\n",
      "Batch Average Reconstruciton Loss:1670963584.0\n",
      "input:tensor([  4.2647,   2.3705,   3.3097,   2.2915, 682.0000])\n",
      "output:tensor([223317.4375])\n",
      "Batch Average Reconstruciton Loss:86333136.0\n",
      "input:tensor([  4.2653,   2.3670,   3.3257,   2.3610, 682.0000])\n",
      "output:tensor([223315.5469])\n",
      "Batch Average Reconstruciton Loss:85700440.0\n",
      "input:tensor([  3.6820,   2.5770,   2.6175,   2.5590, 682.0000])\n",
      "output:tensor([223322.1250])\n",
      "Batch Average Reconstruciton Loss:2124921856.0\n",
      "input:tensor([  4.4507,   2.7570,   3.3124,   2.6900, 682.0000])\n",
      "output:tensor([223301.3125])\n",
      "Batch Average Reconstruciton Loss:170827.21875\n",
      "input:tensor([  6.2700,   3.3910,   4.9378,   3.3730, 682.0000])\n",
      "output:tensor([223240.7188])\n",
      "Batch Average Reconstruciton Loss:4228474112.0\n",
      "input:tensor([  4.4043,   2.6605,   2.5576,   2.5865, 682.0000])\n",
      "output:tensor([223313.5312])\n",
      "Batch Average Reconstruciton Loss:3684360.25\n",
      "input:tensor([ 13.1170,   1.7400,  16.2590,   1.6360, 682.0000])\n",
      "output:tensor([223107.7188])\n",
      "Batch Average Reconstruciton Loss:21750562816.0\n",
      "input:tensor([  3.8313,   1.8670,   3.0631,   1.6890, 682.0000])\n",
      "output:tensor([223345.1406])\n",
      "Batch Average Reconstruciton Loss:1265428352.0\n",
      "input:tensor([  3.7787,   2.1940,   2.8836,   2.1520, 682.0000])\n",
      "output:tensor([223332.5469])\n",
      "Batch Average Reconstruciton Loss:1536126720.0\n",
      "input:tensor([ 35.2233,  27.0500,  22.1875,  27.0440, 682.0000])\n",
      "output:tensor([221903.0156])\n",
      "Batch Average Reconstruciton Loss:37535195136.0\n",
      "input:tensor([  4.5743,   3.9165,   1.7631,   3.8185, 682.0000])\n",
      "output:tensor([223276.])\n",
      "Batch Average Reconstruciton Loss:41139396.0\n",
      "input:tensor([  3.5823,   1.8765,   2.8940,   1.8595, 682.0000])\n",
      "output:tensor([223345.2031])\n",
      "Batch Average Reconstruciton Loss:2869615872.0\n",
      "input:tensor([  3.5650,   1.8305,   2.8789,   1.8235, 682.0000])\n",
      "output:tensor([223346.9531])\n",
      "Batch Average Reconstruciton Loss:3015552512.0\n",
      "input:tensor([  3.6057,   2.4080,   2.6025,   2.3640, 682.0000])\n",
      "output:tensor([223329.7812])\n",
      "Batch Average Reconstruciton Loss:2682537472.0\n",
      "input:tensor([  4.6210,   3.0185,   3.3628,   2.9805, 682.0000])\n",
      "output:tensor([223288.9062])\n",
      "Batch Average Reconstruciton Loss:74251072.0\n",
      "input:tensor([  9.7360,  11.5645,   9.7060,  11.5345, 682.0000])\n",
      "output:tensor([222861.1562])\n",
      "Batch Average Reconstruciton Loss:14634020864.0\n",
      "input:tensor([  3.8547,   2.3380,   2.7983,   2.3340, 682.0000])\n",
      "output:tensor([223326.5469])\n",
      "Batch Average Reconstruciton Loss:1157595392.0\n",
      "input:tensor([  3.6340,   2.5680,   2.4702,   2.4260, 682.0000])\n",
      "output:tensor([223327.6562])\n",
      "Batch Average Reconstruciton Loss:2465057280.0\n",
      "input:tensor([  3.9587,   2.5130,   2.9030,   2.4950, 682.0000])\n",
      "output:tensor([223318.4062])\n",
      "Batch Average Reconstruciton Loss:743685312.0\n",
      "input:tensor([  3.9440,   2.4780,   2.9212,   2.4150, 682.0000])\n",
      "output:tensor([223320.7656])\n",
      "Batch Average Reconstruciton Loss:795253248.0\n",
      "input:tensor([  8.9140,   5.1480,   6.7973,   5.1410, 682.0000])\n",
      "output:tensor([223129.6719])\n",
      "Batch Average Reconstruciton Loss:12509006848.0\n",
      "input:tensor([  3.7637,   2.3470,   2.7828,   2.3290, 682.0000])\n",
      "output:tensor([223327.7188])\n",
      "Batch Average Reconstruciton Loss:1619682688.0\n",
      "input:tensor([  4.5463,   3.3380,   3.2145,   3.3040, 682.0000])\n",
      "output:tensor([223279.7812])\n",
      "Batch Average Reconstruciton Loss:25824500.0\n",
      "input:tensor([ 36.9140,   3.0460,  47.9158,   2.9370, 682.0000])\n",
      "output:tensor([222469.0625])\n",
      "Batch Average Reconstruciton Loss:38257819648.0\n",
      "input:tensor([  4.9690,   2.5040,   4.0691,   2.4680, 682.0000])\n",
      "output:tensor([223295.9688])\n",
      "Batch Average Reconstruciton Loss:559699456.0\n",
      "input:tensor([ 17.0663,  13.6900,   8.0393,  13.5810, 682.0000])\n",
      "output:tensor([222727.2344])\n",
      "Batch Average Reconstruciton Loss:27093565440.0\n",
      "input:tensor([ 47.1467,  67.1920,  61.7394,  67.1750, 682.0000])\n",
      "output:tensor([219919.0781])\n",
      "Batch Average Reconstruciton Loss:39552491520.0\n",
      "input:tensor([  3.9900,   2.5370,   2.9329,   2.5030, 682.0000])\n",
      "output:tensor([223317.3125])\n",
      "Batch Average Reconstruciton Loss:640327232.0\n",
      "input:tensor([ 30.2903,  22.7520,  21.4136,  22.7170, 682.0000])\n",
      "output:tensor([222117.9219])\n",
      "Batch Average Reconstruciton Loss:35860209664.0\n",
      "input:tensor([  5.6717,   4.1095,   4.0202,   4.0425, 682.0000])\n",
      "output:tensor([223232.4688])\n",
      "Batch Average Reconstruciton Loss:2335640832.0\n",
      "input:tensor([  4.0320,   2.5525,   2.9620,   2.4925, 682.0000])\n",
      "output:tensor([223316.6406])\n",
      "Batch Average Reconstruciton Loss:515987552.0\n",
      "input:tensor([  4.0243,   2.5135,   2.9746,   2.4745, 682.0000])\n",
      "output:tensor([223317.4531])\n",
      "Batch Average Reconstruciton Loss:537430464.0\n",
      "input:tensor([  4.1713,   2.8025,   3.0073,   2.7675, 682.0000])\n",
      "output:tensor([223305.1094])\n",
      "Batch Average Reconstruciton Loss:210507904.0\n",
      "input:tensor([  4.9823,   2.9865,   3.7452,   2.9515, 682.0000])\n",
      "output:tensor([223282.0312])\n",
      "Batch Average Reconstruciton Loss:584625536.0\n",
      "input:tensor([ 78.0642,  75.4647, 121.8426,  93.9421, 802.0000])\n",
      "output:tensor([257508.6094])\n",
      "Batch Average Reconstruciton Loss:60568956928.0\n",
      "input:tensor([  4.4370,   2.5320,   3.4314,   2.5150, 682.0000])\n",
      "output:tensor([223306.9844])\n",
      "Batch Average Reconstruciton Loss:71832.375\n",
      "input:tensor([  4.0650,   2.1370,   3.2996,   2.0340, 682.0000])\n",
      "output:tensor([223328.6094])\n",
      "Batch Average Reconstruciton Loss:428713216.0\n",
      "input:tensor([  4.4263,   2.6785,   3.3345,   2.6615, 682.0000])\n",
      "output:tensor([223302.8750])\n",
      "Batch Average Reconstruciton Loss:656302.5\n",
      "input:tensor([  5.7233,   4.6120,   4.0667,   4.5440, 682.0000])\n",
      "output:tensor([223213.5000])\n",
      "Batch Average Reconstruciton Loss:2488762624.0\n",
      "input:tensor([  3.8017,   2.3285,   2.8716,   2.1375, 682.0000])\n",
      "output:tensor([223331.3594])\n",
      "Batch Average Reconstruciton Loss:1414259456.0\n",
      "input:tensor([  5.8523,   2.0350,   5.6816,   2.0020, 682.0000])\n",
      "output:tensor([223285.9531])\n",
      "Batch Average Reconstruciton Loss:2892390912.0\n",
      "input:tensor([  3.5733,   2.5515,   2.5368,   2.4915, 682.0000])\n",
      "output:tensor([223326.1250])\n",
      "Batch Average Reconstruciton Loss:2946956288.0\n",
      "input:tensor([  5.4503,   2.0260,   5.1529,   1.9900, 682.0000])\n",
      "output:tensor([223296.2969])\n",
      "Batch Average Reconstruciton Loss:1704806016.0\n",
      "input:tensor([  3.6020,   2.4300,   2.5953,   2.3550, 682.0000])\n",
      "output:tensor([223329.9062])\n",
      "Batch Average Reconstruciton Loss:2711607040.0\n",
      "input:tensor([  3.8847,   2.8785,   2.7460,   2.8075, 682.0000])\n",
      "output:tensor([223309.1562])\n",
      "Batch Average Reconstruciton Loss:1027448896.0\n",
      "input:tensor([  4.6530,   2.5300,   3.6828,   2.4710, 682.0000])\n",
      "output:tensor([223303.1094])\n",
      "Batch Average Reconstruciton Loss:102153656.0\n",
      "input:tensor([  3.4763,   1.7930,   2.8324,   1.7230, 682.0000])\n",
      "output:tensor([223351.3125])\n",
      "Batch Average Reconstruciton Loss:3844829184.0\n",
      "input:tensor([  4.0140,   2.5920,   2.9442,   2.5250, 682.0000])\n",
      "output:tensor([223315.7969])\n",
      "Batch Average Reconstruciton Loss:567354432.0\n",
      "input:tensor([  5.6483,   4.4535,   1.7193,   4.4465, 682.0000])\n",
      "output:tensor([223243.6094])\n",
      "Batch Average Reconstruciton Loss:2267341568.0\n",
      "input:tensor([  3.9373,   2.4615,   2.9219,   2.3955, 682.0000])\n",
      "output:tensor([223321.4688])\n",
      "Batch Average Reconstruciton Loss:819421056.0\n",
      "input:tensor([  4.4790,   2.6800,   3.3772,   2.6200, 682.0000])\n",
      "output:tensor([223302.8906])\n",
      "Batch Average Reconstruciton Loss:3330225.75\n",
      "input:tensor([  5.7257,   2.5550,   4.9918,   2.4520, 682.0000])\n",
      "output:tensor([223277.8906])\n",
      "Batch Average Reconstruciton Loss:2502289664.0\n",
      "input:tensor([  3.7250,   2.1385,   2.8839,   2.0345, 682.0000])\n",
      "output:tensor([223336.6250])\n",
      "Batch Average Reconstruciton Loss:1846625024.0\n",
      "input:tensor([  3.9977,   3.0395,   1.6196,   2.9315, 682.0000])\n",
      "output:tensor([223315.2188])\n",
      "Batch Average Reconstruciton Loss:616518016.0\n",
      "input:tensor([  3.7327,   1.8455,   3.1153,   1.8265, 682.0000])\n",
      "output:tensor([223342.4062])\n",
      "Batch Average Reconstruciton Loss:1799421952.0\n",
      "input:tensor([  2.7300,   1.6685,   2.0408,   1.6115, 682.0000])\n",
      "output:tensor([223371.8438])\n",
      "Batch Average Reconstruciton Loss:19599482880.0\n",
      "input:tensor([ 29.7177,   1.7065,  39.6824,   1.7015, 682.0000])\n",
      "output:tensor([222678.9844])\n",
      "Batch Average Reconstruciton Loss:35833724928.0\n",
      "input:tensor([  3.8803,   2.3765,   2.9047,   2.2685, 682.0000])\n",
      "output:tensor([223326.3594])\n",
      "Batch Average Reconstruciton Loss:1044688448.0\n",
      "input:tensor([  3.7067,   3.1510,   2.6690,   3.0840, 682.0000])\n",
      "output:tensor([223302.0625])\n",
      "Batch Average Reconstruciton Loss:1964611456.0\n",
      "input:tensor([  4.4657,   2.7640,   3.3106,   2.7300, 682.0000])\n",
      "output:tensor([223300.0938])\n",
      "Batch Average Reconstruciton Loss:1348138.75\n",
      "input:tensor([  3.7593,   1.6870,   3.3018,   1.5830, 682.0000])\n",
      "output:tensor([223347.9375])\n",
      "Batch Average Reconstruciton Loss:1642604928.0\n",
      "input:tensor([  3.2653,   1.9900,   2.4668,   1.8780, 682.0000])\n",
      "output:tensor([223351.4844])\n",
      "Batch Average Reconstruciton Loss:6471480832.0\n",
      "input:tensor([  3.7353,   2.6605,   2.6526,   2.6165, 682.0000])\n",
      "output:tensor([223318.8594])\n",
      "Batch Average Reconstruciton Loss:1785327872.0\n",
      "input:tensor([  3.7610,   2.1115,   2.9007,   2.0935, 682.0000])\n",
      "output:tensor([223334.8906])\n",
      "Batch Average Reconstruciton Loss:1634189440.0\n",
      "input:tensor([  3.8310,   2.7685,   2.7175,   2.6985, 682.0000])\n",
      "output:tensor([223313.9375])\n",
      "Batch Average Reconstruciton Loss:1269216384.0\n",
      "input:tensor([  4.2100,   2.3470,   3.2843,   2.2350, 682.0000])\n",
      "output:tensor([223319.9375])\n",
      "Batch Average Reconstruciton Loss:151513024.0\n",
      "input:tensor([  5.4527,   3.1695,   4.1534,   3.1525, 682.0000])\n",
      "output:tensor([223265.6719])\n",
      "Batch Average Reconstruciton Loss:1708720384.0\n",
      "input:tensor([  4.0890,   2.6835,   2.9741,   2.6175, 682.0000])\n",
      "output:tensor([223311.3750])\n",
      "Batch Average Reconstruciton Loss:372128224.0\n",
      "input:tensor([  3.2603,   1.8635,   2.5103,   1.7625, 682.0000])\n",
      "output:tensor([223355.3438])\n",
      "Batch Average Reconstruciton Loss:6546049024.0\n",
      "input:tensor([  4.6360,   2.9985,   3.3872,   2.9235, 682.0000])\n",
      "output:tensor([223290.1406])\n",
      "Batch Average Reconstruciton Loss:86715960.0\n",
      "input:tensor([  3.8113,   2.2875,   2.8816,   2.2455, 682.0000])\n",
      "output:tensor([223328.8750])\n",
      "Batch Average Reconstruciton Loss:1365090048.0\n",
      "input:tensor([  3.4943,   2.7740,   2.4741,   2.7400, 682.0000])\n",
      "output:tensor([223319.0312])\n",
      "Batch Average Reconstruciton Loss:3668600064.0\n",
      "input:tensor([  3.4970,   1.7540,   2.8636,   1.7210, 682.0000])\n",
      "output:tensor([223351.2188])\n",
      "Batch Average Reconstruciton Loss:3638596608.0\n",
      "input:tensor([  4.0463,   2.1045,   3.2729,   2.0355, 682.0000])\n",
      "output:tensor([223329.3906])\n",
      "Batch Average Reconstruciton Loss:476575520.0\n",
      "input:tensor([  4.0800,   2.5540,   3.0114,   2.5170, 682.0000])\n",
      "output:tensor([223314.9844])\n",
      "Batch Average Reconstruciton Loss:392912288.0\n",
      "input:tensor([  3.9910,   1.7585,   3.4903,   1.7405, 682.0000])\n",
      "output:tensor([223338.7031])\n",
      "Batch Average Reconstruciton Loss:636063360.0\n",
      "input:tensor([  3.9060,   2.1325,   3.0635,   2.1145, 682.0000])\n",
      "output:tensor([223330.8281])\n",
      "Batch Average Reconstruciton Loss:938636288.0\n",
      "input:tensor([  3.2150,   1.8835,   2.4623,   1.8485, 682.0000])\n",
      "output:tensor([223353.9375])\n",
      "Batch Average Reconstruciton Loss:7259050496.0\n",
      "input:tensor([  3.6283,   1.9450,   2.9039,   1.8780, 682.0000])\n",
      "output:tensor([223343.4375])\n",
      "Batch Average Reconstruciton Loss:2506060032.0\n",
      "input:tensor([  4.2550,   2.8910,   2.0598,   2.8310, 682.0000])\n",
      "output:tensor([223311.8594])\n",
      "Batch Average Reconstruciton Loss:96533392.0\n",
      "input:tensor([  3.2147,   2.3820,   2.2740,   2.3410, 682.0000])\n",
      "output:tensor([223338.3281])\n",
      "Batch Average Reconstruciton Loss:7267165696.0\n",
      "input:tensor([  5.7437,   2.6645,   4.9277,   2.5865, 682.0000])\n",
      "output:tensor([223273.8438])\n",
      "Batch Average Reconstruciton Loss:2556499968.0\n",
      "input:tensor([  4.4217,   2.8690,   3.2070,   2.8120, 682.0000])\n",
      "output:tensor([223298.5312])\n",
      "Batch Average Reconstruciton Loss:1105586.5\n",
      "input:tensor([  3.4237,   2.2655,   2.4710,   2.2315, 682.0000])\n",
      "output:tensor([223337.9688])\n",
      "Batch Average Reconstruciton Loss:4410292224.0\n",
      "input:tensor([  3.6773,   2.5895,   2.6278,   2.5225, 682.0000])\n",
      "output:tensor([223322.8594])\n",
      "Batch Average Reconstruciton Loss:2156500992.0\n",
      "input:tensor([  4.5323,   3.4115,   3.2009,   3.3765, 682.0000])\n",
      "output:tensor([223277.4688])\n",
      "Batch Average Reconstruciton Loss:19408154.0\n",
      "input:tensor([  7.1100,   2.1350,   7.2801,   2.1010, 682.0000])\n",
      "output:tensor([223251.9219])\n",
      "Batch Average Reconstruciton Loss:7010699776.0\n",
      "input:tensor([  3.2893,   1.9795,   2.4737,   1.9745, 682.0000])\n",
      "output:tensor([223348.8438])\n",
      "Batch Average Reconstruciton Loss:6120270336.0\n",
      "input:tensor([  4.3227,   2.5490,   3.2831,   2.5140, 682.0000])\n",
      "output:tensor([223309.6406])\n",
      "Batch Average Reconstruciton Loss:38172124.0\n",
      "input:tensor([  4.0160,   2.5300,   2.9553,   2.4890, 682.0000])\n",
      "output:tensor([223317.2031])\n",
      "Batch Average Reconstruciton Loss:561443392.0\n",
      "input:tensor([  3.5547,   2.3930,   2.5613,   2.3590, 682.0000])\n",
      "output:tensor([223331.0469])\n",
      "Batch Average Reconstruciton Loss:3106830848.0\n",
      "input:tensor([  4.2963,   2.9310,   2.1156,   2.8310, 682.0000])\n",
      "output:tensor([223310.4219])\n",
      "Batch Average Reconstruciton Loss:57525824.0\n",
      "input:tensor([  4.1393,   2.1850,   3.2953,   2.1450, 682.0000])\n",
      "output:tensor([223324.5625])\n",
      "Batch Average Reconstruciton Loss:266585216.0\n",
      "input:tensor([  3.1107,   1.7275,   2.4267,   1.7205, 682.0000])\n",
      "output:tensor([223360.3125])\n",
      "Batch Average Reconstruciton Loss:9128404992.0\n",
      "input:tensor([  3.6613,   2.0060,   2.8740,   1.9890, 682.0000])\n",
      "output:tensor([223339.9688])\n",
      "Batch Average Reconstruciton Loss:2265763072.0\n",
      "input:tensor([  4.2217,   2.3885,   3.2709,   2.3245, 682.0000])\n",
      "output:tensor([223317.2812])\n",
      "Batch Average Reconstruciton Loss:135972368.0\n",
      "input:tensor([  5.7190,   2.1870,   5.3428,   2.1360, 682.0000])\n",
      "output:tensor([223286.0312])\n",
      "Batch Average Reconstruciton Loss:2482932480.0\n",
      "input:tensor([  3.4960,   1.8380,   2.8370,   1.7930, 682.0000])\n",
      "output:tensor([223348.8125])\n",
      "Batch Average Reconstruciton Loss:3648665856.0\n",
      "input:tensor([  4.7520,   3.5380,   2.1904,   3.4380, 682.0000])\n",
      "output:tensor([223283.0938])\n",
      "Batch Average Reconstruciton Loss:211094560.0\n",
      "input:tensor([  4.3363,   3.0710,   3.0864,   2.9910, 682.0000])\n",
      "output:tensor([223294.0625])\n",
      "Batch Average Reconstruciton Loss:29931158.0\n",
      "input:tensor([ 26.2323,   1.8645,  34.5498,   1.8285, 682.0000])\n",
      "output:tensor([222766.1875])\n",
      "Batch Average Reconstruciton Loss:34206572544.0\n",
      "input:tensor([  6.3030,   3.6530,   4.8073,   3.6100, 682.0000])\n",
      "output:tensor([223233.0312])\n",
      "Batch Average Reconstruciton Loss:4335963136.0\n",
      "input:tensor([  4.1433,   2.9585,   2.9440,   2.8815, 682.0000])\n",
      "output:tensor([223301.6094])\n",
      "Batch Average Reconstruciton Loss:259834752.0\n",
      "input:tensor([  3.5087,   2.2965,   2.5521,   2.2555, 682.0000])\n",
      "output:tensor([223335.2812])\n",
      "Batch Average Reconstruciton Loss:3527495168.0\n",
      "input:tensor([  4.2117,   2.8410,   2.1453,   2.8360, 682.0000])\n",
      "output:tensor([223311.8125])\n",
      "Batch Average Reconstruciton Loss:149430768.0\n",
      "input:tensor([  3.9250,   2.3205,   2.9869,   2.2605, 682.0000])\n",
      "output:tensor([223325.7969])\n",
      "Batch Average Reconstruciton Loss:865136512.0\n",
      "input:tensor([  4.4147,   2.7440,   3.2902,   2.6110, 682.0000])\n",
      "output:tensor([223304.0469])\n",
      "Batch Average Reconstruciton Loss:1965472.625\n",
      "input:tensor([  3.9117,   2.4625,   2.8879,   2.3655, 682.0000])\n",
      "output:tensor([223322.8906])\n",
      "Batch Average Reconstruciton Loss:916703360.0\n",
      "input:tensor([  4.5583,   3.3830,   3.2217,   3.3410, 682.0000])\n",
      "output:tensor([223278.1562])\n",
      "Batch Average Reconstruciton Loss:31980792.0\n",
      "input:tensor([  3.6323,   2.0695,   2.8275,   1.9715, 682.0000])\n",
      "output:tensor([223340.5469])\n",
      "Batch Average Reconstruciton Loss:2476301824.0\n",
      "input:tensor([  4.2197,   2.4040,   3.2715,   2.3090, 682.0000])\n",
      "output:tensor([223317.5156])\n",
      "Batch Average Reconstruciton Loss:138591392.0\n",
      "input:tensor([ 24.0073,   3.0655,  29.6882,   2.9565, 682.0000])\n",
      "output:tensor([222800.8750])\n",
      "Batch Average Reconstruciton Loss:32934944768.0\n",
      "input:tensor([ 22.9297,   3.2275,  28.0094,   3.1915, 682.0000])\n",
      "output:tensor([222822.7031])\n",
      "Batch Average Reconstruciton Loss:32241686528.0\n",
      "input:tensor([  4.8567,   1.8495,   4.5755,   1.7815, 682.0000])\n",
      "output:tensor([223315.9062])\n",
      "Batch Average Reconstruciton Loss:363318144.0\n",
      "input:tensor([  4.3767,   3.1100,   3.1178,   3.0070, 682.0000])\n",
      "output:tensor([223292.5000])\n",
      "Batch Average Reconstruciton Loss:11319860.0\n",
      "input:tensor([ 12.0533,   2.8775,  13.1037,   2.7935, 682.0000])\n",
      "output:tensor([223111.7188])\n",
      "Batch Average Reconstruciton Loss:19827658752.0\n",
      "input:tensor([  3.9060,   2.3285,   2.9402,   2.3105, 682.0000])\n",
      "output:tensor([223325.1875])\n",
      "Batch Average Reconstruciton Loss:938981952.0\n",
      "input:tensor([  3.6390,   2.5085,   2.6151,   2.4705, 682.0000])\n",
      "output:tensor([223325.5781])\n",
      "Batch Average Reconstruciton Loss:2428165632.0\n",
      "input:tensor([  2.7490,   2.1670,   1.9421,   2.1500, 682.0000])\n",
      "output:tensor([223353.8906])\n",
      "Batch Average Reconstruciton Loss:18907379712.0\n",
      "input:tensor([  3.5020,   2.3020,   2.5478,   2.2680, 682.0000])\n",
      "output:tensor([223335.0156])\n",
      "Batch Average Reconstruciton Loss:3591842816.0\n",
      "input:tensor([  3.1533,   1.7535,   2.4846,   1.7365, 682.0000])\n",
      "output:tensor([223358.5469])\n",
      "Batch Average Reconstruciton Loss:8322812928.0\n",
      "input:tensor([  3.7560,   1.6270,   3.1414,   1.5700, 682.0000])\n",
      "output:tensor([223350.6562])\n",
      "Batch Average Reconstruciton Loss:1661405568.0\n",
      "input:tensor([  3.4680,   2.2610,   2.5305,   2.2440, 682.0000])\n",
      "output:tensor([223336.6094])\n",
      "Batch Average Reconstruciton Loss:3932216832.0\n",
      "input:tensor([  4.0957,   3.1910,   2.8942,   3.1310, 682.0000])\n",
      "output:tensor([223293.9062])\n",
      "Batch Average Reconstruciton Loss:357705120.0\n",
      "input:tensor([  4.4260,   2.5555,   2.7045,   2.5375, 682.0000])\n",
      "output:tensor([223314.0469])\n",
      "Batch Average Reconstruciton Loss:665779.5\n",
      "input:tensor([  4.5487,   3.5820,   3.2179,   3.5140, 682.0000])\n",
      "output:tensor([223271.8594])\n",
      "Batch Average Reconstruciton Loss:26893138.0\n",
      "input:tensor([  3.9493,   2.5000,   2.7463,   2.3920, 682.0000])\n",
      "output:tensor([223322.9219])\n",
      "Batch Average Reconstruciton Loss:776128256.0\n",
      "input:tensor([  3.4940,   2.2885,   2.5399,   2.2555, 682.0000])\n",
      "output:tensor([223335.6406])\n",
      "Batch Average Reconstruciton Loss:3669858816.0\n",
      "input:tensor([  3.9963,   2.0700,   3.2513,   2.0100, 682.0000])\n",
      "output:tensor([223331.1562])\n",
      "Batch Average Reconstruciton Loss:619852800.0\n",
      "input:tensor([  3.2267,   1.8410,   2.4842,   1.8060, 682.0000])\n",
      "output:tensor([223355.0938])\n",
      "Batch Average Reconstruciton Loss:7069935104.0\n",
      "input:tensor([  4.7783,   3.7180,   3.3785,   3.6430, 682.0000])\n",
      "output:tensor([223263.0156])\n",
      "Batch Average Reconstruciton Loss:245204768.0\n",
      "input:tensor([  3.9763,   2.5300,   2.9311,   2.4860, 682.0000])\n",
      "output:tensor([223317.9688])\n",
      "Batch Average Reconstruciton Loss:684242624.0\n",
      "input:tensor([  3.6600,   2.0080,   2.8924,   1.9400, 682.0000])\n",
      "output:tensor([223340.9844])\n",
      "Batch Average Reconstruciton Loss:2275005184.0\n",
      "input:tensor([  4.4270,   3.1945,   3.1360,   3.1885, 682.0000])\n",
      "output:tensor([223286.2969])\n",
      "Batch Average Reconstruciton Loss:629964.625\n",
      "input:tensor([  3.4437,   2.2045,   2.5234,   2.1875, 682.0000])\n",
      "output:tensor([223338.9531])\n",
      "Batch Average Reconstruciton Loss:4189461248.0\n",
      "input:tensor([ 15.2390,   2.4710,  18.1037,   2.3650, 682.0000])\n",
      "output:tensor([223039.3438])\n",
      "Batch Average Reconstruciton Loss:24946100224.0\n",
      "input:tensor([ 10.6203,  10.2885,   8.3737,  10.2705, 682.0000])\n",
      "output:tensor([222911.3281])\n",
      "Batch Average Reconstruciton Loss:16771630080.0\n",
      "input:tensor([  3.5597,   1.8830,   2.8552,   1.8450, 682.0000])\n",
      "output:tensor([223346.1719])\n",
      "Batch Average Reconstruciton Loss:3061611264.0\n",
      "input:tensor([  3.6110,   1.8745,   2.9161,   1.8395, 682.0000])\n",
      "output:tensor([223345.2188])\n",
      "Batch Average Reconstruciton Loss:2638957056.0\n",
      "input:tensor([  3.4450,   2.1770,   2.5359,   2.1400, 682.0000])\n",
      "output:tensor([223340.2812])\n",
      "Batch Average Reconstruciton Loss:4174932736.0\n",
      "input:tensor([  4.1210,   2.3960,   3.1438,   2.3620, 682.0000])\n",
      "output:tensor([223318.6875])\n",
      "Batch Average Reconstruciton Loss:302736064.0\n",
      "input:tensor([  4.3577,   3.0185,   3.1077,   2.9775, 682.0000])\n",
      "output:tensor([223294.5312])\n",
      "Batch Average Reconstruciton Loss:18926578.0\n",
      "input:tensor([  3.7227,   2.1435,   2.8741,   2.1095, 682.0000])\n",
      "output:tensor([223334.8125])\n",
      "Batch Average Reconstruciton Loss:1861162112.0\n",
      "input:tensor([  3.6663,   1.8655,   2.9811,   1.8595, 682.0000])\n",
      "output:tensor([223343.5000])\n",
      "Batch Average Reconstruciton Loss:2230342400.0\n",
      "input:tensor([  4.5890,   4.0480,   3.3512,   3.9440, 682.0000])\n",
      "output:tensor([223254.2500])\n",
      "Batch Average Reconstruciton Loss:50200768.0\n",
      "input:tensor([ 10.3277,   3.4490,   9.8419,   3.4440, 682.0000])\n",
      "output:tensor([223142.6094])\n",
      "Batch Average Reconstruciton Loss:16151769088.0\n",
      "input:tensor([  3.8020,   2.8150,   2.6923,   2.7110, 682.0000])\n",
      "output:tensor([223313.7188])\n",
      "Batch Average Reconstruciton Loss:1413856384.0\n",
      "input:tensor([  5.1713,   2.4005,   4.4440,   2.3235, 682.0000])\n",
      "output:tensor([223294.5000])\n",
      "Batch Average Reconstruciton Loss:990203584.0\n",
      "input:tensor([  4.2490,   2.4375,   3.2811,   2.4035, 682.0000])\n",
      "output:tensor([223314.3750])\n",
      "Batch Average Reconstruciton Loss:103075792.0\n",
      "input:tensor([  4.0687,   2.6335,   2.9624,   2.6265, 682.0000])\n",
      "output:tensor([223312.0156])\n",
      "Batch Average Reconstruciton Loss:420372384.0\n",
      "input:tensor([  3.9250,   2.3965,   2.9321,   2.3295, 682.0000])\n",
      "output:tensor([223323.8438])\n",
      "Batch Average Reconstruciton Loss:865251392.0\n",
      "input:tensor([  4.3760,   2.6635,   3.2868,   2.5675, 682.0000])\n",
      "output:tensor([223306.4531])\n",
      "Batch Average Reconstruciton Loss:11455158.0\n",
      "input:tensor([  3.9630,   2.6115,   2.8841,   2.5495, 682.0000])\n",
      "output:tensor([223316.1875])\n",
      "Batch Average Reconstruciton Loss:728935872.0\n",
      "input:tensor([  3.6817,   2.5565,   2.6283,   2.5225, 682.0000])\n",
      "output:tensor([223323.1562])\n",
      "Batch Average Reconstruciton Loss:2127040000.0\n",
      "input:tensor([  3.7490,   2.1875,   2.8542,   2.1455, 682.0000])\n",
      "output:tensor([223333.4062])\n",
      "Batch Average Reconstruciton Loss:1703261952.0\n",
      "input:tensor([  3.5977,   1.8930,   2.8925,   1.8530, 682.0000])\n",
      "output:tensor([223345.0625])\n",
      "Batch Average Reconstruciton Loss:2744600832.0\n",
      "input:tensor([  3.9713,   2.4730,   2.9368,   2.4560, 682.0000])\n",
      "output:tensor([223319.3281])\n",
      "Batch Average Reconstruciton Loss:700696448.0\n",
      "input:tensor([ 34.7753,   1.7380,  46.8245,   1.7030, 682.0000])\n",
      "output:tensor([222548.3281])\n",
      "Batch Average Reconstruciton Loss:37644664832.0\n",
      "input:tensor([  3.9770,   2.5100,   2.9271,   2.4770, 682.0000])\n",
      "output:tensor([223318.4375])\n",
      "Batch Average Reconstruciton Loss:682022592.0\n",
      "input:tensor([  3.3877,   2.2045,   2.4821,   2.1635, 682.0000])\n",
      "output:tensor([223340.5938])\n",
      "Batch Average Reconstruciton Loss:4828360704.0\n",
      "input:tensor([  5.4630,   2.4250,   4.7629,   2.4080, 682.0000])\n",
      "output:tensor([223285.6250])\n",
      "Batch Average Reconstruciton Loss:1738942080.0\n",
      "input:tensor([  9.4190,   7.1520,   6.6574,   7.1110, 682.0000])\n",
      "output:tensor([223055.0781])\n",
      "Batch Average Reconstruciton Loss:13861784576.0\n",
      "input:tensor([  3.4810,   2.2400,   2.5404,   2.2060, 682.0000])\n",
      "output:tensor([223337.5312])\n",
      "Batch Average Reconstruciton Loss:3799300864.0\n",
      "input:tensor([  7.7943,   3.6755,   6.5623,   3.6575, 682.0000])\n",
      "output:tensor([223196.9531])\n",
      "Batch Average Reconstruciton Loss:9201596416.0\n",
      "input:tensor([  6.1380,   6.7580,   2.0599,   6.7230, 682.0000])\n",
      "output:tensor([223153.1406])\n",
      "Batch Average Reconstruciton Loss:3786819584.0\n",
      "input:tensor([  4.1060,   2.2340,   3.0624,   2.1180, 682.0000])\n",
      "output:tensor([223327.5469])\n",
      "Batch Average Reconstruciton Loss:333809472.0\n",
      "input:tensor([  4.2543,   2.4285,   3.2758,   2.3935, 682.0000])\n",
      "output:tensor([223314.7188])\n",
      "Batch Average Reconstruciton Loss:97205424.0\n",
      "input:tensor([  4.7283,   3.6095,   1.9928,   3.5915, 682.0000])\n",
      "output:tensor([223280.8438])\n",
      "Batch Average Reconstruciton Loss:181760112.0\n",
      "input:tensor([  4.8663,   2.3040,   4.1212,   2.2400, 682.0000])\n",
      "output:tensor([223304.3125])\n",
      "Batch Average Reconstruciton Loss:378470272.0\n",
      "input:tensor([ 31.5873,  23.4855,  22.3347,  23.3825, 682.0000])\n",
      "output:tensor([222069.7812])\n",
      "Batch Average Reconstruciton Loss:36353056768.0\n",
      "input:tensor([  4.9940,   3.4895,   3.5642,   3.4505, 682.0000])\n",
      "output:tensor([223266.])\n",
      "Batch Average Reconstruciton Loss:606538368.0\n",
      "input:tensor([  3.7840,   2.7605,   2.6803,   2.7245, 682.0000])\n",
      "output:tensor([223314.2500])\n",
      "Batch Average Reconstruciton Loss:1508681600.0\n",
      "input:tensor([ 28.1103,  21.2775,  17.0709,  21.2715, 682.0000])\n",
      "output:tensor([222239.5938])\n",
      "Batch Average Reconstruciton Loss:34950152192.0\n",
      "input:tensor([  3.0200,   2.1510,   2.0112,   2.0940, 682.0000])\n",
      "output:tensor([223351.8750])\n",
      "Batch Average Reconstruciton Loss:11051291648.0\n",
      "input:tensor([  3.9357,   2.4630,   2.9051,   2.4290, 682.0000])\n",
      "output:tensor([223320.8125])\n",
      "Batch Average Reconstruciton Loss:825596032.0\n",
      "input:tensor([  4.1620,   3.3045,   2.9467,   3.2275, 682.0000])\n",
      "output:tensor([223289.0156])\n",
      "Batch Average Reconstruciton Loss:226742896.0\n",
      "input:tensor([  3.8817,   2.2670,   2.9583,   2.2220, 682.0000])\n",
      "output:tensor([223328.1094])\n",
      "Batch Average Reconstruciton Loss:1038894784.0\n",
      "input:tensor([  4.1183,   3.2295,   2.7423,   3.1985, 682.0000])\n",
      "output:tensor([223293.1875])\n",
      "Batch Average Reconstruciton Loss:309084960.0\n",
      "input:tensor([ 18.5207,   2.2695,  23.1119,   2.2355, 682.0000])\n",
      "output:tensor([222956.2031])\n",
      "Batch Average Reconstruciton Loss:28694396928.0\n",
      "input:tensor([  5.3430,   3.5465,   3.8606,   3.5085, 682.0000])\n",
      "output:tensor([223257.0469])\n",
      "Batch Average Reconstruciton Loss:1413312384.0\n",
      "input:tensor([  3.4277,   2.2040,   2.5175,   2.1700, 682.0000])\n",
      "output:tensor([223339.6250])\n",
      "Batch Average Reconstruciton Loss:4365294592.0\n",
      "input:tensor([ 33.5130,   3.8245,  42.0582,   3.7075, 682.0000])\n",
      "output:tensor([222540.3750])\n",
      "Batch Average Reconstruciton Loss:37225988096.0\n",
      "input:tensor([  4.9160,   3.6530,   3.4737,   3.6180, 682.0000])\n",
      "output:tensor([223261.8438])\n",
      "Batch Average Reconstruciton Loss:461040064.0\n",
      "input:tensor([  6.3940,   6.4670,   5.2367,   6.4250, 682.0000])\n",
      "output:tensor([223126.9375])\n",
      "Batch Average Reconstruciton Loss:4621543936.0\n",
      "input:tensor([  3.6967,   2.0750,   2.8862,   2.0170, 682.0000])\n",
      "output:tensor([223338.0312])\n",
      "Batch Average Reconstruciton Loss:2026077312.0\n",
      "input:tensor([ 18.5847,   1.8920,  23.7434,   1.8530, 682.0000])\n",
      "output:tensor([222962.3438])\n",
      "Batch Average Reconstruciton Loss:28759189504.0\n",
      "input:tensor([  3.9463,   2.4700,   2.9207,   2.4290, 682.0000])\n",
      "output:tensor([223320.4688])\n",
      "Batch Average Reconstruciton Loss:786944512.0\n",
      "input:tensor([  3.5263,   1.8430,   2.8547,   1.7840, 682.0000])\n",
      "output:tensor([223348.4844])\n",
      "Batch Average Reconstruciton Loss:3359769088.0\n",
      "input:tensor([  3.4880,   1.8005,   2.8402,   1.7335, 682.0000])\n",
      "output:tensor([223350.7656])\n",
      "Batch Average Reconstruciton Loss:3727497472.0\n",
      "input:tensor([  4.9073,   3.7690,   3.4680,   3.6620, 682.0000])\n",
      "output:tensor([223259.6562])\n",
      "Batch Average Reconstruciton Loss:445786496.0\n",
      "input:tensor([  4.8370,   2.8125,   3.6958,   2.7945, 682.0000])\n",
      "output:tensor([223289.9062])\n",
      "Batch Average Reconstruciton Loss:331382208.0\n",
      "input:tensor([  4.2417,   2.3900,   3.3043,   2.3170, 682.0000])\n",
      "output:tensor([223316.8750])\n",
      "Batch Average Reconstruciton Loss:111368448.0\n",
      "input:tensor([  3.9120,   2.3900,   2.9138,   2.3850, 682.0000])\n",
      "output:tensor([223322.8594])\n",
      "Batch Average Reconstruciton Loss:915434048.0\n",
      "input:tensor([  3.5443,   1.8785,   2.8384,   1.8385, 682.0000])\n",
      "output:tensor([223346.7188])\n",
      "Batch Average Reconstruciton Loss:3196350976.0\n",
      "input:tensor([  4.8397,   3.0705,   3.5661,   3.0025, 682.0000])\n",
      "output:tensor([223283.3125])\n",
      "Batch Average Reconstruciton Loss:335267552.0\n",
      "input:tensor([  3.8360,   2.8285,   2.7155,   2.7275, 682.0000])\n",
      "output:tensor([223312.5312])\n",
      "Batch Average Reconstruciton Loss:1245417216.0\n",
      "input:tensor([  4.1700,   1.8190,   3.6797,   1.7820, 682.0000])\n",
      "output:tensor([223333.0938])\n",
      "Batch Average Reconstruciton Loss:211903520.0\n",
      "input:tensor([  4.2923,   2.3330,   3.3953,   2.3270, 682.0000])\n",
      "output:tensor([223315.7344])\n",
      "Batch Average Reconstruciton Loss:60750576.0\n",
      "input:tensor([  3.8647,   2.2890,   2.9394,   2.2130, 682.0000])\n",
      "output:tensor([223328.5000])\n",
      "Batch Average Reconstruciton Loss:1112589440.0\n",
      "input:tensor([  5.0223,   2.7585,   3.7385,   2.5795, 682.0000])\n",
      "output:tensor([223293.4375])\n",
      "Batch Average Reconstruciton Loss:664373184.0\n",
      "input:tensor([ 18.4360,   1.7110,  23.7680,   1.6760, 682.0000])\n",
      "output:tensor([222970.0156])\n",
      "Batch Average Reconstruciton Loss:28615788544.0\n",
      "input:tensor([  4.6033,   2.4555,   3.6702,   2.4495, 682.0000])\n",
      "output:tensor([223305.0938])\n",
      "Batch Average Reconstruciton Loss:60981944.0\n",
      "input:tensor([  3.9187,   2.4630,   2.8886,   2.4210, 682.0000])\n",
      "output:tensor([223321.3906])\n",
      "Batch Average Reconstruciton Loss:889566976.0\n",
      "input:tensor([  4.1930,   2.7695,   3.0355,   2.7655, 682.0000])\n",
      "output:tensor([223305.])\n",
      "Batch Average Reconstruciton Loss:176358400.0\n",
      "input:tensor([  3.8110,   2.3655,   2.8682,   2.1985, 682.0000])\n",
      "output:tensor([223329.3594])\n",
      "Batch Average Reconstruciton Loss:1366754304.0\n",
      "input:tensor([  3.0237,   1.6365,   2.2499,   1.5265, 682.0000])\n",
      "output:tensor([223368.9531])\n",
      "Batch Average Reconstruciton Loss:10964194304.0\n",
      "input:tensor([  3.6347,   2.5265,   2.6038,   2.4595, 682.0000])\n",
      "output:tensor([223325.7969])\n",
      "Batch Average Reconstruciton Loss:2460279296.0\n",
      "input:tensor([  3.7043,   2.1580,   2.8591,   2.0350, 682.0000])\n",
      "output:tensor([223336.8906])\n",
      "Batch Average Reconstruciton Loss:1976434560.0\n",
      "input:tensor([  3.9783,   2.5090,   2.9298,   2.4740, 682.0000])\n",
      "output:tensor([223318.4844])\n",
      "Batch Average Reconstruciton Loss:677691840.0\n",
      "input:tensor([  3.8267,   2.2060,   2.9524,   2.0960, 682.0000])\n",
      "output:tensor([223332.5469])\n",
      "Batch Average Reconstruciton Loss:1288842496.0\n",
      "input:tensor([  3.6150,   2.5085,   2.5936,   2.4035, 682.0000])\n",
      "output:tensor([223327.7344])\n",
      "Batch Average Reconstruciton Loss:2609602304.0\n",
      "input:tensor([  3.7243,   2.6440,   2.6521,   2.5770, 682.0000])\n",
      "output:tensor([223320.1406])\n",
      "Batch Average Reconstruciton Loss:1852085248.0\n",
      "input:tensor([  4.0153,   1.5175,   3.7692,   1.4785, 682.0000])\n",
      "output:tensor([223344.6094])\n",
      "Batch Average Reconstruciton Loss:562087808.0\n",
      "input:tensor([  3.5763,   2.4060,   2.5729,   2.3650, 682.0000])\n",
      "output:tensor([223330.4062])\n",
      "Batch Average Reconstruciton Loss:2921250560.0\n",
      "input:tensor([  3.5987,   2.3965,   2.6086,   2.3305, 682.0000])\n",
      "output:tensor([223330.7656])\n",
      "Batch Average Reconstruciton Loss:2738139392.0\n",
      "input:tensor([  4.4527,   2.4670,   3.4753,   2.4600, 682.0000])\n",
      "output:tensor([223308.4062])\n",
      "Batch Average Reconstruciton Loss:270822.65625\n",
      "input:tensor([  3.9360,   1.9530,   3.2572,   1.8820, 682.0000])\n",
      "output:tensor([223336.2031])\n",
      "Batch Average Reconstruciton Loss:823506176.0\n",
      "input:tensor([  8.4080,   9.3515,   7.7270,   9.3165, 682.0000])\n",
      "output:tensor([222975.6406])\n",
      "Batch Average Reconstruciton Loss:11023454208.0\n",
      "input:tensor([  7.8243,   3.9340,   6.4047,   3.8940, 682.0000])\n",
      "output:tensor([223189.6250])\n",
      "Batch Average Reconstruciton Loss:9294044160.0\n",
      "input:tensor([  3.7033,   2.1105,   2.8747,   2.0695, 682.0000])\n",
      "output:tensor([223336.3906])\n",
      "Batch Average Reconstruciton Loss:1982975232.0\n",
      "input:tensor([  4.6390,   2.4285,   3.7207,   2.3935, 682.0000])\n",
      "output:tensor([223305.8594])\n",
      "Batch Average Reconstruciton Loss:89621424.0\n",
      "input:tensor([  5.3633,   2.5470,   4.5299,   2.5410, 682.0000])\n",
      "output:tensor([223284.5156])\n",
      "Batch Average Reconstruciton Loss:1468768512.0\n",
      "input:tensor([  4.1043,   2.1905,   3.2854,   2.1315, 682.0000])\n",
      "output:tensor([223325.3281])\n",
      "Batch Average Reconstruciton Loss:337481600.0\n",
      "input:tensor([ 12.1740,   4.9175,  11.1037,   4.8125, 682.0000])\n",
      "output:tensor([223059.5312])\n",
      "Batch Average Reconstruciton Loss:20043347968.0\n",
      "input:tensor([  3.8843,   2.3620,   2.9012,   2.3270, 682.0000])\n",
      "output:tensor([223325.0625])\n",
      "Batch Average Reconstruciton Loss:1027839616.0\n",
      "input:tensor([  4.8930,   3.4190,   3.5048,   3.2960, 682.0000])\n",
      "output:tensor([223272.3125])\n",
      "Batch Average Reconstruciton Loss:421616928.0\n",
      "input:tensor([  4.0923,   2.7300,   2.9577,   2.6960, 682.0000])\n",
      "output:tensor([223309.0781])\n",
      "Batch Average Reconstruciton Loss:364654240.0\n",
      "input:tensor([  4.1327,   3.3485,   2.9349,   3.3305, 682.0000])\n",
      "output:tensor([223286.4062])\n",
      "Batch Average Reconstruciton Loss:280649408.0\n",
      "input:tensor([  4.0183,   3.0730,   2.8377,   3.0310, 682.0000])\n",
      "output:tensor([223299.0781])\n",
      "Batch Average Reconstruciton Loss:555541248.0\n",
      "input:tensor([  3.6960,   2.6105,   2.6316,   2.5725, 682.0000])\n",
      "output:tensor([223321.1250])\n",
      "Batch Average Reconstruciton Loss:2031924608.0\n",
      "input:tensor([  4.3247,   2.5440,   3.3138,   2.4170, 682.0000])\n",
      "output:tensor([223311.7500])\n",
      "Batch Average Reconstruciton Loss:36847936.0\n",
      "input:tensor([  4.2563,   2.8580,   3.0617,   2.7840, 682.0000])\n",
      "output:tensor([223302.6406])\n",
      "Batch Average Reconstruciton Loss:95284136.0\n",
      "input:tensor([  3.4003,   2.3140,   2.1305,   2.1950, 682.0000])\n",
      "output:tensor([223342.2812])\n",
      "Batch Average Reconstruciton Loss:4677700608.0\n",
      "input:tensor([  3.6177,   2.4015,   2.6273,   2.3245, 682.0000])\n",
      "output:tensor([223330.4688])\n",
      "Batch Average Reconstruciton Loss:2588726784.0\n",
      "input:tensor([  4.6487,   2.7595,   3.5639,   2.5475, 682.0000])\n",
      "output:tensor([223300.0469])\n",
      "Batch Average Reconstruciton Loss:98109952.0\n",
      "input:tensor([  3.6880,   2.0465,   2.8695,   2.0115, 682.0000])\n",
      "output:tensor([223338.7344])\n",
      "Batch Average Reconstruciton Loss:2083125120.0\n",
      "input:tensor([  4.0057,   3.0145,   2.8276,   2.9795, 682.0000])\n",
      "output:tensor([223301.2344])\n",
      "Batch Average Reconstruciton Loss:592813696.0\n",
      "input:tensor([  4.2520,   2.8670,   3.0608,   2.7930, 682.0000])\n",
      "output:tensor([223302.3750])\n",
      "Batch Average Reconstruciton Loss:99992504.0\n",
      "input:tensor([  3.4823,   1.7530,   2.9059,   1.7120, 682.0000])\n",
      "output:tensor([223351.1562])\n",
      "Batch Average Reconstruciton Loss:3784076032.0\n",
      "input:tensor([  3.8810,   1.8420,   3.2654,   1.7980, 682.0000])\n",
      "output:tensor([223339.9688])\n",
      "Batch Average Reconstruciton Loss:1040967744.0\n",
      "input:tensor([  3.3410,   2.0690,   2.4808,   2.0280, 682.0000])\n",
      "output:tensor([223345.9375])\n",
      "Batch Average Reconstruciton Loss:5412701184.0\n",
      "input:tensor([  3.7157,   2.0755,   2.8916,   2.0415, 682.0000])\n",
      "output:tensor([223337.1562])\n",
      "Batch Average Reconstruciton Loss:1904523264.0\n",
      "input:tensor([  4.5870,   2.4700,   3.5450,   2.2890, 682.0000])\n",
      "output:tensor([223310.5000])\n",
      "Batch Average Reconstruciton Loss:49667256.0\n",
      "input:tensor([  4.7473,   3.3625,   3.3721,   3.3035, 682.0000])\n",
      "output:tensor([223275.7031])\n",
      "Batch Average Reconstruciton Loss:204967984.0\n",
      "input:tensor([  4.7967,   2.7280,   3.6928,   2.7230, 682.0000])\n",
      "output:tensor([223293.0312])\n",
      "Batch Average Reconstruciton Loss:271690304.0\n",
      "input:tensor([  3.3070,   2.0110,   2.4955,   1.9500, 682.0000])\n",
      "output:tensor([223348.7188])\n",
      "Batch Average Reconstruciton Loss:5870820864.0\n",
      "input:tensor([  3.8250,   1.8175,   3.1110,   1.6895, 682.0000])\n",
      "output:tensor([223345.2188])\n",
      "Batch Average Reconstruciton Loss:1296056192.0\n",
      "input:tensor([  4.1213,   2.7275,   2.9839,   2.6675, 682.0000])\n",
      "output:tensor([223309.2031])\n",
      "Batch Average Reconstruciton Loss:302405024.0\n",
      "input:tensor([  4.4437,   3.1170,   3.1730,   3.0790, 682.0000])\n",
      "output:tensor([223289.2969])\n",
      "Batch Average Reconstruciton Loss:2529.775634765625\n",
      "input:tensor([  3.7843,   2.6735,   2.6904,   2.5985, 682.0000])\n",
      "output:tensor([223318.2500])\n",
      "Batch Average Reconstruciton Loss:1506584832.0\n",
      "input:tensor([  3.5610,   2.3730,   2.5731,   2.3340, 682.0000])\n",
      "output:tensor([223331.7031])\n",
      "Batch Average Reconstruciton Loss:3051600896.0\n",
      "input:tensor([  3.9490,   2.4440,   2.9354,   2.4100, 682.0000])\n",
      "output:tensor([223321.0469])\n",
      "Batch Average Reconstruciton Loss:777403328.0\n",
      "input:tensor([  5.6473,   2.7080,   4.7621,   2.6400, 682.0000])\n",
      "output:tensor([223274.8594])\n",
      "Batch Average Reconstruciton Loss:2267365376.0\n",
      "input:tensor([  7.3080,   6.5345,   5.4231,   6.5175, 682.0000])\n",
      "output:tensor([223112.1875])\n",
      "Batch Average Reconstruciton Loss:7633549824.0\n",
      "input:tensor([  4.8243,   2.8595,   3.6492,   2.8255, 682.0000])\n",
      "output:tensor([223289.2344])\n",
      "Batch Average Reconstruciton Loss:312060512.0\n",
      "input:tensor([  4.7340,   3.6180,   2.0436,   3.5760, 682.0000])\n",
      "output:tensor([223280.5469])\n",
      "Batch Average Reconstruciton Loss:188582848.0\n",
      "input:tensor([  4.6107,   3.3990,   3.2590,   3.3650, 682.0000])\n",
      "output:tensor([223276.4375])\n",
      "Batch Average Reconstruciton Loss:65990236.0\n",
      "input:tensor([ 10.6333,   3.0985,  11.0144,   3.0265, 682.0000])\n",
      "output:tensor([223141.0312])\n",
      "Batch Average Reconstruciton Loss:16860771328.0\n",
      "input:tensor([  6.3333,   5.5365,   4.6413,   5.4955, 682.0000])\n",
      "output:tensor([223167.1719])\n",
      "Batch Average Reconstruciton Loss:4426929152.0\n",
      "input:tensor([  4.4327,   3.2005,   3.1437,   3.1825, 682.0000])\n",
      "output:tensor([223286.2500])\n",
      "Batch Average Reconstruciton Loss:256795.5625\n",
      "input:tensor([  6.0037,   2.3135,   5.6030,   2.2795, 682.0000])\n",
      "output:tensor([223275.2812])\n",
      "Batch Average Reconstruciton Loss:3369022464.0\n",
      "input:tensor([  3.5480,   2.4710,   2.5494,   2.3530, 682.0000])\n",
      "output:tensor([223330.5781])\n",
      "Batch Average Reconstruciton Loss:3165572608.0\n",
      "input:tensor([  4.1257,   2.7690,   2.9732,   2.7360, 682.0000])\n",
      "output:tensor([223307.1406])\n",
      "Batch Average Reconstruciton Loss:293740512.0\n",
      "input:tensor([  4.4397,   2.2355,   3.6665,   2.1755, 682.0000])\n",
      "output:tensor([223316.0938])\n",
      "Batch Average Reconstruciton Loss:15352.7587890625\n",
      "input:tensor([  4.0233,   3.0715,   1.5981,   3.0535, 682.0000])\n",
      "output:tensor([223311.7656])\n",
      "Batch Average Reconstruciton Loss:540573376.0\n",
      "input:tensor([  4.2180,   1.8965,   3.6844,   1.8525, 682.0000])\n",
      "output:tensor([223329.9531])\n",
      "Batch Average Reconstruciton Loss:140494720.0\n",
      "input:tensor([  3.8727,   2.3580,   2.9102,   2.3190, 682.0000])\n",
      "output:tensor([223325.3125])\n",
      "Batch Average Reconstruciton Loss:1077722752.0\n",
      "input:tensor([  5.7883,   2.5640,   5.0456,   2.5300, 682.0000])\n",
      "output:tensor([223274.6094])\n",
      "Batch Average Reconstruciton Loss:2693154304.0\n",
      "input:tensor([  4.1443,   2.3415,   3.0671,   2.1205, 682.0000])\n",
      "output:tensor([223325.9062])\n",
      "Batch Average Reconstruciton Loss:257188368.0\n",
      "input:tensor([  5.9433,   4.9860,   4.2610,   4.9070, 682.0000])\n",
      "output:tensor([223196.])\n",
      "Batch Average Reconstruciton Loss:3168113920.0\n",
      "input:tensor([  8.4207,   3.0870,   8.0120,   3.0200, 682.0000])\n",
      "output:tensor([223197.])\n",
      "Batch Average Reconstruciton Loss:11107473408.0\n",
      "input:tensor([  4.2377,   2.4050,   3.1739,   2.2050, 682.0000])\n",
      "output:tensor([223320.9844])\n",
      "Batch Average Reconstruciton Loss:115993240.0\n",
      "input:tensor([  4.2017,   3.3090,   1.3430,   3.3020, 682.0000])\n",
      "output:tensor([223303.8594])\n",
      "Batch Average Reconstruciton Loss:163664448.0\n",
      "input:tensor([  3.8120,   2.2760,   2.8876,   2.2310, 682.0000])\n",
      "output:tensor([223329.2969])\n",
      "Batch Average Reconstruciton Loss:1361735680.0\n",
      "input:tensor([  5.4553,   2.1690,   5.0367,   2.1350, 682.0000])\n",
      "output:tensor([223292.3281])\n",
      "Batch Average Reconstruciton Loss:1718295552.0\n",
      "input:tensor([  4.3567,   2.0860,   3.6422,   2.0680, 682.0000])\n",
      "output:tensor([223321.5000])\n",
      "Batch Average Reconstruciton Loss:19145000.0\n",
      "input:tensor([  3.2757,   1.9965,   2.4664,   1.9185, 682.0000])\n",
      "output:tensor([223350.2812])\n",
      "Batch Average Reconstruciton Loss:6318456320.0\n",
      "input:tensor([  3.8927,   2.3740,   2.9040,   2.3690, 682.0000])\n",
      "output:tensor([223323.7344])\n",
      "Batch Average Reconstruciton Loss:993148928.0\n",
      "input:tensor([  3.4827,   1.9660,   2.7640,   1.7780, 682.0000])\n",
      "output:tensor([223348.7656])\n",
      "Batch Average Reconstruciton Loss:3781048832.0\n",
      "input:tensor([  4.6980,   2.6490,   3.6521,   2.5720, 682.0000])\n",
      "output:tensor([223299.1562])\n",
      "Batch Average Reconstruciton Loss:147504816.0\n",
      "input:tensor([  5.5263,   3.4510,   4.0926,   3.4160, 682.0000])\n",
      "output:tensor([223255.9375])\n",
      "Batch Average Reconstruciton Loss:1914232064.0\n",
      "input:tensor([  4.7267,   3.1500,   3.4158,   3.1110, 682.0000])\n",
      "output:tensor([223282.5469])\n",
      "Batch Average Reconstruciton Loss:179815952.0\n",
      "input:tensor([  4.6817,   2.4420,   3.7667,   2.4080, 682.0000])\n",
      "output:tensor([223304.4219])\n",
      "Batch Average Reconstruciton Loss:130289024.0\n",
      "input:tensor([  4.0257,   2.8715,   2.4390,   2.8385, 682.0000])\n",
      "output:tensor([223310.2500])\n",
      "Batch Average Reconstruciton Loss:534014336.0\n",
      "input:tensor([  3.8177,   2.7975,   2.7025,   2.7565, 682.0000])\n",
      "output:tensor([223312.4844])\n",
      "Batch Average Reconstruciton Loss:1334624640.0\n",
      "input:tensor([  4.3943,   3.1630,   3.1172,   3.1240, 682.0000])\n",
      "output:tensor([223288.8125])\n",
      "Batch Average Reconstruciton Loss:6032857.0\n",
      "input:tensor([  3.9383,   2.4905,   2.9144,   2.3865, 682.0000])\n",
      "output:tensor([223321.4688])\n",
      "Batch Average Reconstruciton Loss:815761088.0\n",
      "input:tensor([  5.2817,   2.3850,   4.5694,   2.3490, 682.0000])\n",
      "output:tensor([223291.5156])\n",
      "Batch Average Reconstruciton Loss:1258228480.0\n",
      "input:tensor([  4.4270,   2.2235,   3.6316,   2.1785, 682.0000])\n",
      "output:tensor([223316.6719])\n",
      "Batch Average Reconstruciton Loss:582669.8125\n",
      "input:tensor([  3.1920,   1.7970,   2.4794,   1.7560, 682.0000])\n",
      "output:tensor([223357.2500])\n",
      "Batch Average Reconstruciton Loss:7642212864.0\n",
      "input:tensor([  4.0033,   2.6885,   2.8848,   2.6545, 682.0000])\n",
      "output:tensor([223312.2812])\n",
      "Batch Average Reconstruciton Loss:599354560.0\n",
      "input:tensor([  4.6560,   3.4550,   3.2917,   3.3430, 682.0000])\n",
      "output:tensor([223275.5625])\n",
      "Batch Average Reconstruciton Loss:104398584.0\n",
      "input:tensor([  3.6953,   2.0960,   2.8726,   2.0340, 682.0000])\n",
      "output:tensor([223337.5469])\n",
      "Batch Average Reconstruciton Loss:2034862720.0\n",
      "input:tensor([  4.2453,   2.4180,   3.2706,   2.4120, 682.0000])\n",
      "output:tensor([223314.5000])\n",
      "Batch Average Reconstruciton Loss:107194960.0\n",
      "input:tensor([  4.6663,   3.0325,   3.3989,   2.9985, 682.0000])\n",
      "output:tensor([223287.4375])\n",
      "Batch Average Reconstruciton Loss:114499360.0\n",
      "input:tensor([  6.1243,   2.7930,   5.2569,   2.7540, 682.0000])\n",
      "output:tensor([223260.7031])\n",
      "Batch Average Reconstruciton Loss:3755692288.0\n",
      "input:tensor([  6.3873,   2.2975,   6.1015,   2.2795, 682.0000])\n",
      "output:tensor([223266.0312])\n",
      "Batch Average Reconstruciton Loss:4618429952.0\n",
      "input:tensor([  4.1150,   2.2080,   3.2741,   2.1730, 682.0000])\n",
      "output:tensor([223324.0938])\n",
      "Batch Average Reconstruciton Loss:314881696.0\n",
      "input:tensor([  3.6420,   2.0160,   2.8500,   1.9720, 682.0000])\n",
      "output:tensor([223340.7656])\n",
      "Batch Average Reconstruciton Loss:2404650240.0\n",
      "input:tensor([  4.0863,   2.1840,   3.2573,   2.1170, 682.0000])\n",
      "output:tensor([223326.2344])\n",
      "Batch Average Reconstruciton Loss:377671232.0\n",
      "input:tensor([  3.7350,   2.6820,   2.6569,   2.5710, 682.0000])\n",
      "output:tensor([223319.7344])\n",
      "Batch Average Reconstruciton Loss:1787282688.0\n",
      "input:tensor([  71.9835,   92.6950,  119.0081,  131.0163, 1058.0000])\n",
      "output:tensor([340377.0938])\n",
      "Batch Average Reconstruciton Loss:103977934848.0\n",
      "input:tensor([ 69.0095,  76.8740, 111.2582, 100.2531, 802.0000])\n",
      "output:tensor([257544.8906])\n",
      "Batch Average Reconstruciton Loss:59852591104.0\n",
      "input:tensor([  9.5443,  11.4720,   9.4975,  11.4030, 682.0000])\n",
      "output:tensor([222869.7344])\n",
      "Batch Average Reconstruciton Loss:14145232896.0\n",
      "input:tensor([  3.5827,   1.9505,   2.8403,   1.8855, 682.0000])\n",
      "output:tensor([223344.3594])\n",
      "Batch Average Reconstruciton Loss:2867028480.0\n",
      "input:tensor([  3.4897,   2.2810,   2.5390,   2.2200, 682.0000])\n",
      "output:tensor([223336.6719])\n",
      "Batch Average Reconstruciton Loss:3712626688.0\n",
      "input:tensor([  3.4073,   2.2575,   2.4673,   2.2395, 682.0000])\n",
      "output:tensor([223338.0625])\n",
      "Batch Average Reconstruciton Loss:4596696064.0\n",
      "input:tensor([  3.7660,   2.2735,   2.8619,   2.1525, 682.0000])\n",
      "output:tensor([223332.0312])\n",
      "Batch Average Reconstruciton Loss:1606163456.0\n",
      "input:tensor([  4.0873,   2.1770,   3.2596,   2.1420, 682.0000])\n",
      "output:tensor([223325.6562])\n",
      "Batch Average Reconstruciton Loss:375403936.0\n",
      "input:tensor([  3.7937,   2.5055,   2.7620,   2.4705, 682.0000])\n",
      "output:tensor([223322.3750])\n",
      "Batch Average Reconstruciton Loss:1456614912.0\n",
      "input:tensor([  3.5367,   2.3370,   2.5704,   2.2930, 682.0000])\n",
      "output:tensor([223333.4062])\n",
      "Batch Average Reconstruciton Loss:3266876160.0\n",
      "input:tensor([  3.6373,   2.0535,   2.6844,   1.9485, 682.0000])\n",
      "output:tensor([223342.7812])\n",
      "Batch Average Reconstruciton Loss:2438801152.0\n",
      "input:tensor([ 28.0297,   2.3930,  36.3655,   2.3320, 682.0000])\n",
      "output:tensor([222709.3750])\n",
      "Batch Average Reconstruciton Loss:35088175104.0\n",
      "input:tensor([  4.1213,   2.7215,   2.9866,   2.7045, 682.0000])\n",
      "output:tensor([223308.3125])\n",
      "Batch Average Reconstruciton Loss:302436000.0\n",
      "input:tensor([  3.7053,   2.6295,   2.6362,   2.5325, 682.0000])\n",
      "output:tensor([223321.7656])\n",
      "Batch Average Reconstruciton Loss:1971380864.0\n",
      "input:tensor([ 37.3087,   2.9910,  48.5778,   2.8800, 682.0000])\n",
      "output:tensor([222459.7656])\n",
      "Batch Average Reconstruciton Loss:38365356032.0\n",
      "input:tensor([  7.6910,   6.0825,   5.4499,   6.0065, 682.0000])\n",
      "output:tensor([223125.4531])\n",
      "Batch Average Reconstruciton Loss:8862989312.0\n",
      "input:tensor([  5.9947,   4.5335,   4.2346,   4.5285, 682.0000])\n",
      "output:tensor([223210.0156])\n",
      "Batch Average Reconstruciton Loss:3332754688.0\n",
      "input:tensor([  8.4180,   5.1765,   6.2609,   5.1195, 682.0000])\n",
      "output:tensor([223140.9062])\n",
      "Batch Average Reconstruciton Loss:11087648768.0\n",
      "input:tensor([ 17.8737,   1.9040,  22.7821,   1.7150, 682.0000])\n",
      "output:tensor([222983.5312])\n",
      "Batch Average Reconstruciton Loss:28050399232.0\n",
      "input:tensor([  4.6840,   2.5870,   3.6718,   2.5510, 682.0000])\n",
      "output:tensor([223300.2812])\n",
      "Batch Average Reconstruciton Loss:132601704.0\n",
      "input:tensor([  4.0520,   2.1555,   3.2726,   2.0025, 682.0000])\n",
      "output:tensor([223329.6250])\n",
      "Batch Average Reconstruciton Loss:461707296.0\n",
      "input:tensor([  3.2687,   2.4325,   2.3096,   2.3985, 682.0000])\n",
      "output:tensor([223335.3906])\n",
      "Batch Average Reconstruciton Loss:6424440832.0\n",
      "input:tensor([  3.9933,   2.5545,   2.9232,   2.5205, 682.0000])\n",
      "output:tensor([223316.7500])\n",
      "Batch Average Reconstruciton Loss:629871936.0\n",
      "input:tensor([  3.9857,   2.6660,   2.8696,   2.6320, 682.0000])\n",
      "output:tensor([223313.4375])\n",
      "Batch Average Reconstruciton Loss:654262848.0\n",
      "input:tensor([  4.0377,   2.9595,   2.8565,   2.9145, 682.0000])\n",
      "output:tensor([223302.8125])\n",
      "Batch Average Reconstruciton Loss:501007072.0\n",
      "input:tensor([  4.9733,   4.4890,   3.6953,   4.4480, 682.0000])\n",
      "output:tensor([223229.1562])\n",
      "Batch Average Reconstruciton Loss:564782656.0\n",
      "input:tensor([ 27.4497,   3.0730,  34.6444,   3.0390, 682.0000])\n",
      "output:tensor([222709.0312])\n",
      "Batch Average Reconstruciton Loss:34808377344.0\n",
      "input:tensor([  4.1970,   2.6675,   3.0852,   2.6245, 682.0000])\n",
      "output:tensor([223309.0469])\n",
      "Batch Average Reconstruciton Loss:170301280.0\n",
      "input:tensor([  3.8613,   1.8605,   3.2703,   1.7805, 682.0000])\n",
      "output:tensor([223340.3594])\n",
      "Batch Average Reconstruciton Loss:1126652288.0\n",
      "input:tensor([  4.3930,   3.1180,   3.1255,   3.0520, 682.0000])\n",
      "output:tensor([223291.0312])\n",
      "Batch Average Reconstruciton Loss:6365371.5\n",
      "input:tensor([  7.4163,   3.5945,   6.1997,   3.4855, 682.0000])\n",
      "output:tensor([223210.0156])\n",
      "Batch Average Reconstruciton Loss:8001484288.0\n",
      "input:tensor([ 26.5843,  19.0580,  16.0550,  19.0540, 682.0000])\n",
      "output:tensor([222345.8906])\n",
      "Batch Average Reconstruciton Loss:34236430336.0\n",
      "input:tensor([  8.2887,   5.9605,   3.7301,   5.8995, 682.0000])\n",
      "output:tensor([223141.5156])\n",
      "Batch Average Reconstruciton Loss:10704077824.0\n",
      "input:tensor([  3.5597,   1.9110,   2.8631,   1.8070, 682.0000])\n",
      "output:tensor([223346.7344])\n",
      "Batch Average Reconstruciton Loss:3061549056.0\n",
      "input:tensor([ 26.1763,   2.4520,  33.7121,   2.3910, 682.0000])\n",
      "output:tensor([222755.4062])\n",
      "Batch Average Reconstruciton Loss:34172631040.0\n",
      "input:tensor([  3.7200,   1.7785,   3.1356,   1.7445, 682.0000])\n",
      "output:tensor([223345.0938])\n",
      "Batch Average Reconstruciton Loss:1876787584.0\n",
      "input:tensor([  3.4767,   1.7855,   2.8127,   1.7685, 682.0000])\n",
      "output:tensor([223350.4531])\n",
      "Batch Average Reconstruciton Loss:3841588224.0\n",
      "input:tensor([  4.3873,   3.3865,   3.0974,   3.3695, 682.0000])\n",
      "output:tensor([223280.5938])\n",
      "Batch Average Reconstruciton Loss:7977270.5\n",
      "input:tensor([  3.4717,   2.2365,   2.5406,   2.1325, 682.0000])\n",
      "output:tensor([223339.5156])\n",
      "Batch Average Reconstruciton Loss:3894070016.0\n",
      "input:tensor([  4.0717,   2.2040,   3.2146,   2.1860, 682.0000])\n",
      "output:tensor([223324.9219])\n",
      "Batch Average Reconstruciton Loss:412499264.0\n",
      "input:tensor([  3.1103,   1.7390,   2.4230,   1.7220, 682.0000])\n",
      "output:tensor([223360.1719])\n",
      "Batch Average Reconstruciton Loss:9134929920.0\n",
      "input:tensor([  4.3523,   2.5410,   2.8437,   2.4670, 682.0000])\n",
      "output:tensor([223315.2812])\n",
      "Batch Average Reconstruciton Loss:21240288.0\n",
      "input:tensor([  4.5303,   2.6620,   3.4564,   2.5850, 682.0000])\n",
      "output:tensor([223302.5938])\n",
      "Batch Average Reconstruciton Loss:18788702.0\n",
      "input:tensor([  4.3437,   2.6690,   3.2461,   2.6090, 682.0000])\n",
      "output:tensor([223306.1562])\n",
      "Batch Average Reconstruciton Loss:25723600.0\n",
      "input:tensor([  3.7190,   2.6220,   2.6467,   2.5870, 682.0000])\n",
      "output:tensor([223320.2500])\n",
      "Batch Average Reconstruciton Loss:1885101056.0\n",
      "input:tensor([  4.8043,   2.7425,   3.7137,   2.7245, 682.0000])\n",
      "output:tensor([223292.5469])\n",
      "Batch Average Reconstruciton Loss:282661728.0\n",
      "input:tensor([  4.2600,   2.4045,   3.2923,   2.3765, 682.0000])\n",
      "output:tensor([223315.1719])\n",
      "Batch Average Reconstruciton Loss:91180120.0\n",
      "input:tensor([  4.1457,   2.5215,   3.1004,   2.4425, 682.0000])\n",
      "output:tensor([223315.5625])\n",
      "Batch Average Reconstruciton Loss:255054880.0\n",
      "input:tensor([  4.3607,   3.0750,   3.1037,   3.0350, 682.0000])\n",
      "output:tensor([223292.4844])\n",
      "Batch Average Reconstruciton Loss:17602352.0\n",
      "input:tensor([  3.4793,   2.3025,   2.5184,   2.2565, 682.0000])\n",
      "output:tensor([223335.8594])\n",
      "Batch Average Reconstruciton Loss:3816291584.0\n",
      "input:tensor([  3.9177,   2.4380,   2.9188,   2.3950, 682.0000])\n",
      "output:tensor([223322.])\n",
      "Batch Average Reconstruciton Loss:893412096.0\n",
      "input:tensor([  3.2067,   2.1750,   2.3048,   2.1400, 682.0000])\n",
      "output:tensor([223345.3125])\n",
      "Batch Average Reconstruciton Loss:7397838336.0\n",
      "input:tensor([ 13.7227,   2.5635,  15.9632,   2.5245, 682.0000])\n",
      "output:tensor([223073.4375])\n",
      "Batch Average Reconstruciton Loss:22735945728.0\n",
      "input:tensor([  5.8843,   5.3200,   4.3981,   5.2860, 682.0000])\n",
      "output:tensor([223182.0938])\n",
      "Batch Average Reconstruciton Loss:2981061120.0\n",
      "input:tensor([  4.2727,   2.4945,   3.2638,   2.4605, 682.0000])\n",
      "output:tensor([223312.2969])\n",
      "Batch Average Reconstruciton Loss:78512056.0\n",
      "input:tensor([  3.5557,   2.3670,   2.3929,   2.2500, 682.0000])\n",
      "output:tensor([223335.8750])\n",
      "Batch Average Reconstruciton Loss:3097492992.0\n",
      "input:tensor([  3.5383,   1.8605,   2.8490,   1.8195, 682.0000])\n",
      "output:tensor([223347.3281])\n",
      "Batch Average Reconstruciton Loss:3250216704.0\n",
      "input:tensor([  5.4260,   4.6555,   3.9338,   4.5925, 682.0000])\n",
      "output:tensor([223216.4062])\n",
      "Batch Average Reconstruciton Loss:1631627264.0\n",
      "input:tensor([ 26.2630,   3.4360,  32.4577,   3.3080, 682.0000])\n",
      "output:tensor([222734.4688])\n",
      "Batch Average Reconstruciton Loss:34211115008.0\n",
      "input:tensor([  4.2750,   1.8825,   3.7456,   1.8475, 682.0000])\n",
      "output:tensor([223328.9688])\n",
      "Batch Average Reconstruciton Loss:76004072.0\n",
      "input:tensor([ 21.2523,   2.0755,  27.2190,   2.0055, 682.0000])\n",
      "output:tensor([222890.9844])\n",
      "Batch Average Reconstruciton Loss:31051368448.0\n",
      "input:tensor([  3.7610,   1.6845,   3.2736,   1.6465, 682.0000])\n",
      "output:tensor([223346.6250])\n",
      "Batch Average Reconstruciton Loss:1633240832.0\n",
      "input:tensor([ 20.7710,   2.3485,  26.1082,   2.2445, 682.0000])\n",
      "output:tensor([222899.0938])\n",
      "Batch Average Reconstruciton Loss:30674053120.0\n",
      "input:tensor([  3.7987,   2.2345,   2.8817,   2.2245, 682.0000])\n",
      "output:tensor([223330.0938])\n",
      "Batch Average Reconstruciton Loss:1429891456.0\n",
      "input:tensor([  3.6880,   2.5950,   2.6277,   2.5610, 682.0000])\n",
      "output:tensor([223321.7344])\n",
      "Batch Average Reconstruciton Loss:2084677248.0\n",
      "input:tensor([  4.0527,   2.6705,   2.9448,   2.6035, 682.0000])\n",
      "output:tensor([223312.5938])\n",
      "Batch Average Reconstruciton Loss:460720736.0\n",
      "input:tensor([  4.1367,   2.7910,   2.9879,   2.7140, 682.0000])\n",
      "output:tensor([223307.1562])\n",
      "Batch Average Reconstruciton Loss:272244832.0\n",
      "input:tensor([ 24.1483,   1.8375,  31.5917,   1.8175, 682.0000])\n",
      "output:tensor([222820.5781])\n",
      "Batch Average Reconstruciton Loss:33030000640.0\n",
      "input:tensor([  3.4240,   2.1695,   2.0224,   2.1015, 682.0000])\n",
      "output:tensor([223347.0625])\n",
      "Batch Average Reconstruciton Loss:4405366784.0\n",
      "input:tensor([  4.6390,   3.6935,   3.2894,   3.6765, 682.0000])\n",
      "output:tensor([223264.8750])\n",
      "Batch Average Reconstruciton Loss:88847120.0\n",
      "input:tensor([  3.9023,   2.3565,   2.8803,   2.3545, 682.0000])\n",
      "output:tensor([223324.4375])\n",
      "Batch Average Reconstruciton Loss:953732672.0\n",
      "input:tensor([  4.4017,   2.4755,   3.4101,   2.4415, 682.0000])\n",
      "output:tensor([223310.0156])\n",
      "Batch Average Reconstruciton Loss:4239416.5\n",
      "input:tensor([  4.6243,   2.9665,   2.4919,   2.8715, 682.0000])\n",
      "output:tensor([223301.4844])\n",
      "Batch Average Reconstruciton Loss:77167168.0\n",
      "input:tensor([  3.7037,   2.0665,   2.7232,   1.9905, 682.0000])\n",
      "output:tensor([223340.4375])\n",
      "Batch Average Reconstruciton Loss:1980478080.0\n",
      "input:tensor([  3.8333,   1.8190,   3.2437,   1.7590, 682.0000])\n",
      "output:tensor([223341.9375])\n",
      "Batch Average Reconstruciton Loss:1256068864.0\n",
      "input:tensor([  3.7170,   2.1630,   2.8596,   2.1210, 682.0000])\n",
      "output:tensor([223334.5625])\n",
      "Batch Average Reconstruciton Loss:1896379264.0\n",
      "input:tensor([  4.0040,   2.5100,   2.9728,   2.4030, 682.0000])\n",
      "output:tensor([223319.5312])\n",
      "Batch Average Reconstruciton Loss:596945536.0\n",
      "input:tensor([  3.7637,   2.2135,   2.8626,   2.1965, 682.0000])\n",
      "output:tensor([223331.5938])\n",
      "Batch Average Reconstruciton Loss:1619370752.0\n",
      "input:tensor([  5.6753,   5.2810,   4.2871,   5.1720, 682.0000])\n",
      "output:tensor([223188.7969])\n",
      "Batch Average Reconstruciton Loss:2342249984.0\n",
      "input:tensor([  3.5877,   2.5225,   2.5742,   2.4875, 682.0000])\n",
      "output:tensor([223325.9688])\n",
      "Batch Average Reconstruciton Loss:2827796736.0\n",
      "input:tensor([  4.6377,   2.4930,   3.6729,   2.4580, 682.0000])\n",
      "output:tensor([223304.0938])\n",
      "Batch Average Reconstruciton Loss:88418176.0\n",
      "input:tensor([  3.6420,   2.5575,   2.5985,   2.5225, 682.0000])\n",
      "output:tensor([223323.8906])\n",
      "Batch Average Reconstruciton Loss:2406305536.0\n",
      "input:tensor([  6.2860,   5.1590,   4.4883,   5.1250, 682.0000])\n",
      "output:tensor([223182.6094])\n",
      "Batch Average Reconstruciton Loss:4273447424.0\n",
      "input:tensor([  4.1343,   2.7210,   2.9982,   2.6860, 682.0000])\n",
      "output:tensor([223308.5312])\n",
      "Batch Average Reconstruciton Loss:276672288.0\n",
      "input:tensor([  3.6123,   1.9845,   2.8518,   1.9185, 682.0000])\n",
      "output:tensor([223342.7188])\n",
      "Batch Average Reconstruciton Loss:2628846848.0\n",
      "input:tensor([  4.1120,   2.2160,   3.2505,   2.2110, 682.0000])\n",
      "output:tensor([223323.3438])\n",
      "Batch Average Reconstruciton Loss:321185760.0\n",
      "input:tensor([  3.7727,   2.2045,   2.8911,   2.0975, 682.0000])\n",
      "output:tensor([223333.7656])\n",
      "Batch Average Reconstruciton Loss:1568970624.0\n",
      "input:tensor([  3.0953,   2.1725,   2.2083,   2.1295, 682.0000])\n",
      "output:tensor([223347.8281])\n",
      "Batch Average Reconstruciton Loss:9435046912.0\n",
      "input:tensor([  5.9190,   2.4510,   5.0582,   2.3520, 682.0000])\n",
      "output:tensor([223278.7344])\n",
      "Batch Average Reconstruciton Loss:3100566784.0\n",
      "input:tensor([ 30.7723,   3.1590,  39.2181,   3.0780, 682.0000])\n",
      "output:tensor([222622.7969])\n",
      "Batch Average Reconstruciton Loss:36246753280.0\n",
      "input:tensor([  6.4130,   5.1075,   4.5488,   5.0725, 682.0000])\n",
      "output:tensor([223182.4844])\n",
      "Batch Average Reconstruciton Loss:4691768320.0\n",
      "input:tensor([  4.2813,   2.4110,   3.3112,   2.3940, 682.0000])\n",
      "output:tensor([223314.2188])\n",
      "Batch Average Reconstruciton Loss:70388432.0\n",
      "input:tensor([ 30.1167,   1.8835,  40.0491,   1.8245, 682.0000])\n",
      "output:tensor([222665.8594])\n",
      "Batch Average Reconstruciton Loss:35996282880.0\n",
      "input:tensor([  3.6867,   2.5845,   2.6295,   2.5425, 682.0000])\n",
      "output:tensor([223322.2812])\n",
      "Batch Average Reconstruciton Loss:2093585792.0\n",
      "input:tensor([  3.3653,   2.0920,   2.4979,   2.0630, 682.0000])\n",
      "output:tensor([223344.3750])\n",
      "Batch Average Reconstruciton Loss:5101619712.0\n",
      "input:tensor([  3.9460,   2.4575,   2.9262,   2.4145, 682.0000])\n",
      "output:tensor([223320.9219])\n",
      "Batch Average Reconstruciton Loss:788097728.0\n",
      "input:tensor([  3.9250,   2.4290,   2.9124,   2.3950, 682.0000])\n",
      "output:tensor([223322.0781])\n",
      "Batch Average Reconstruciton Loss:865355264.0\n",
      "input:tensor([  4.8353,   1.8435,   4.5070,   1.8085, 682.0000])\n",
      "output:tensor([223316.2500])\n",
      "Batch Average Reconstruciton Loss:329794688.0\n",
      "input:tensor([  3.7183,   2.0830,   2.9152,   2.0160, 682.0000])\n",
      "output:tensor([223337.4375])\n",
      "Batch Average Reconstruciton Loss:1887777536.0\n",
      "input:tensor([  4.0263,   2.5730,   2.9573,   2.5390, 682.0000])\n",
      "output:tensor([223315.3750])\n",
      "Batch Average Reconstruciton Loss:531884672.0\n",
      "input:tensor([  3.8587,   1.8240,   3.2655,   1.7900, 682.0000])\n",
      "output:tensor([223340.6094])\n",
      "Batch Average Reconstruciton Loss:1138616448.0\n",
      "input:tensor([  4.0250,   3.0685,   2.8426,   3.0015, 682.0000])\n",
      "output:tensor([223299.7656])\n",
      "Batch Average Reconstruciton Loss:536396448.0\n",
      "input:tensor([  3.9130,   2.6200,   2.8213,   2.5850, 682.0000])\n",
      "output:tensor([223316.3906])\n",
      "Batch Average Reconstruciton Loss:911895616.0\n",
      "input:tensor([  4.1977,   2.4800,   3.0300,   2.4720, 682.0000])\n",
      "output:tensor([223315.4375])\n",
      "Batch Average Reconstruciton Loss:169170672.0\n",
      "input:tensor([  3.2317,   2.3660,   2.2859,   2.3220, 682.0000])\n",
      "output:tensor([223338.6719])\n",
      "Batch Average Reconstruciton Loss:6992861184.0\n",
      "input:tensor([  4.4610,   2.2395,   3.6718,   2.1795, 682.0000])\n",
      "output:tensor([223315.6562])\n",
      "Batch Average Reconstruciton Loss:890487.125\n",
      "input:tensor([  3.9600,   2.7000,   2.8356,   2.6820, 682.0000])\n",
      "output:tensor([223312.4375])\n",
      "Batch Average Reconstruciton Loss:739435456.0\n",
      "input:tensor([  3.4493,   2.1820,   2.3653,   2.0710, 682.0000])\n",
      "output:tensor([223343.7500])\n",
      "Batch Average Reconstruciton Loss:4127837696.0\n",
      "input:tensor([  3.3650,   2.0685,   2.5039,   2.0375, 682.0000])\n",
      "output:tensor([223345.2188])\n",
      "Batch Average Reconstruciton Loss:5105643008.0\n",
      "input:tensor([  4.1867,   1.8905,   3.6522,   1.8235, 682.0000])\n",
      "output:tensor([223331.4375])\n",
      "Batch Average Reconstruciton Loss:185274640.0\n",
      "input:tensor([  4.2667,   2.4430,   3.3030,   2.3740, 682.0000])\n",
      "output:tensor([223314.6406])\n",
      "Batch Average Reconstruciton Loss:84370824.0\n",
      "input:tensor([  3.3557,   2.1240,   2.4880,   2.0540, 682.0000])\n",
      "output:tensor([223344.4688])\n",
      "Batch Average Reconstruciton Loss:5223607808.0\n",
      "input:tensor([  3.4800,   2.3675,   1.6295,   2.3605, 682.0000])\n",
      "output:tensor([223342.0781])\n",
      "Batch Average Reconstruciton Loss:3808731648.0\n",
      "input:tensor([  3.3673,   2.1835,   2.4827,   2.0255, 682.0000])\n",
      "output:tensor([223344.5000])\n",
      "Batch Average Reconstruciton Loss:5076633600.0\n",
      "input:tensor([  3.9677,   2.4765,   2.9467,   2.4095, 682.0000])\n",
      "output:tensor([223320.3906])\n",
      "Batch Average Reconstruciton Loss:712922560.0\n",
      "input:tensor([  4.7413,   2.5230,   3.7867,   2.4780, 682.0000])\n",
      "output:tensor([223300.9531])\n",
      "Batch Average Reconstruciton Loss:198160608.0\n",
      "input:tensor([ 1675.4454,  1005.3028, 66077.2031,   892.8036,   886.0000])\n",
      "output:tensor([-468913.6562])\n",
      "Batch Average Reconstruciton Loss:220443066368.0\n",
      "input:tensor([  4.8813,   2.5225,   3.9570,   2.5045, 682.0000])\n",
      "output:tensor([223297.])\n",
      "Batch Average Reconstruciton Loss:402965472.0\n",
      "input:tensor([  4.1110,   2.2325,   3.2793,   2.1275, 682.0000])\n",
      "output:tensor([223324.9688])\n",
      "Batch Average Reconstruciton Loss:323245568.0\n",
      "input:tensor([  4.6453,   4.1070,   3.4107,   4.0680, 682.0000])\n",
      "output:tensor([223249.2969])\n",
      "Batch Average Reconstruciton Loss:94115160.0\n",
      "input:tensor([  3.5973,   1.9375,   2.8502,   1.9205, 682.0000])\n",
      "output:tensor([223343.3438])\n",
      "Batch Average Reconstruciton Loss:2747505920.0\n",
      "input:tensor([  3.7630,   2.1780,   2.8793,   2.1440, 682.0000])\n",
      "output:tensor([223333.0938])\n",
      "Batch Average Reconstruciton Loss:1622954240.0\n",
      "input:tensor([ 33.1943,  24.8480,  23.4681,  24.8300, 682.0000])\n",
      "output:tensor([221989.7812])\n",
      "Batch Average Reconstruciton Loss:36904247296.0\n",
      "input:tensor([  3.7453,   2.1735,   2.8686,   2.1135, 682.0000])\n",
      "output:tensor([223334.2344])\n",
      "Batch Average Reconstruciton Loss:1724638336.0\n",
      "input:tensor([  3.8327,   1.7775,   3.2816,   1.7365, 682.0000])\n",
      "output:tensor([223342.5312])\n",
      "Batch Average Reconstruciton Loss:1259218432.0\n",
      "input:tensor([  3.4727,   1.7530,   2.8514,   1.7180, 682.0000])\n",
      "output:tensor([223351.7031])\n",
      "Batch Average Reconstruciton Loss:3882199296.0\n",
      "input:tensor([ 18.9720,   3.5000,  21.8737,   3.4430, 682.0000])\n",
      "output:tensor([222921.2812])\n",
      "Batch Average Reconstruciton Loss:29115717632.0\n",
      "input:tensor([  3.7897,   2.2070,   2.8888,   2.1890, 682.0000])\n",
      "output:tensor([223331.2812])\n",
      "Batch Average Reconstruciton Loss:1477073920.0\n",
      "input:tensor([  7.3253,   8.0975,   6.6592,   8.0625, 682.0000])\n",
      "output:tensor([223043.3750])\n",
      "Batch Average Reconstruciton Loss:7677855744.0\n",
      "input:tensor([  3.9003,   2.8320,   2.7619,   2.7980, 682.0000])\n",
      "output:tensor([223309.5625])\n",
      "Batch Average Reconstruciton Loss:962701888.0\n",
      "input:tensor([  4.4593,   2.7815,   3.3089,   2.7455, 682.0000])\n",
      "output:tensor([223299.5938])\n",
      "Batch Average Reconstruciton Loss:713338.625\n",
      "input:tensor([  5.7297,   5.3580,   4.3668,   5.2630, 682.0000])\n",
      "output:tensor([223184.2188])\n",
      "Batch Average Reconstruciton Loss:2505024512.0\n",
      "input:tensor([  4.1137,   2.6895,   2.9770,   2.6845, 682.0000])\n",
      "output:tensor([223309.3594])\n",
      "Batch Average Reconstruciton Loss:318181408.0\n",
      "input:tensor([  3.1447,   1.7840,   2.4471,   1.7500, 682.0000])\n",
      "output:tensor([223358.3906])\n",
      "Batch Average Reconstruciton Loss:8481785344.0\n",
      "input:tensor([  3.6113,   2.4840,   2.5938,   2.4030, 682.0000])\n",
      "output:tensor([223328.0312])\n",
      "Batch Average Reconstruciton Loss:2638154496.0\n",
      "input:tensor([  4.4497,   2.7130,   3.3154,   2.7080, 682.0000])\n",
      "output:tensor([223301.2969])\n",
      "Batch Average Reconstruciton Loss:131984.625\n",
      "input:tensor([  4.1490,   2.7230,   3.0075,   2.6890, 682.0000])\n",
      "output:tensor([223308.1875])\n",
      "Batch Average Reconstruciton Loss:249191872.0\n",
      "input:tensor([  3.6023,   1.9660,   2.8458,   1.9610, 682.0000])\n",
      "output:tensor([223342.0312])\n",
      "Batch Average Reconstruciton Loss:2707638016.0\n",
      "input:tensor([  4.6230,   3.0005,   3.3765,   2.9395, 682.0000])\n",
      "output:tensor([223289.9688])\n",
      "Batch Average Reconstruciton Loss:75880976.0\n",
      "input:tensor([  4.1603,   2.2895,   3.2578,   2.2555, 682.0000])\n",
      "output:tensor([223320.8594])\n",
      "Batch Average Reconstruciton Loss:228648896.0\n",
      "input:tensor([  8.1013,   3.1075,   7.5575,   3.0435, 682.0000])\n",
      "output:tensor([223204.4531])\n",
      "Batch Average Reconstruciton Loss:10151661568.0\n",
      "input:tensor([  3.6830,   2.7280,   2.6041,   2.7220, 682.0000])\n",
      "output:tensor([223316.5938])\n",
      "Batch Average Reconstruciton Loss:2118706176.0\n",
      "input:tensor([  3.8780,   1.8425,   3.2746,   1.7985, 682.0000])\n",
      "output:tensor([223339.8750])\n",
      "Batch Average Reconstruciton Loss:1053789568.0\n",
      "input:tensor([  3.7753,   1.7450,   3.2725,   1.6400, 682.0000])\n",
      "output:tensor([223346.0156])\n",
      "Batch Average Reconstruciton Loss:1553304576.0\n",
      "input:tensor([  4.4403,   3.5350,   3.1465,   3.4910, 682.0000])\n",
      "output:tensor([223274.8594])\n",
      "Batch Average Reconstruciton Loss:17461.14453125\n",
      "input:tensor([  3.5200,   1.9585,   2.7542,   1.9195, 682.0000])\n",
      "output:tensor([223345.])\n",
      "Batch Average Reconstruciton Loss:3419091712.0\n",
      "input:tensor([  4.8417,   2.7800,   3.7149,   2.7350, 682.0000])\n",
      "output:tensor([223291.5000])\n",
      "Batch Average Reconstruciton Loss:338688800.0\n",
      "input:tensor([  4.4907,   2.2665,   3.6547,   2.1605, 682.0000])\n",
      "output:tensor([223315.7344])\n",
      "Batch Average Reconstruciton Loss:5821287.0\n",
      "input:tensor([  4.9390,   2.4790,   4.0364,   2.4610, 682.0000])\n",
      "output:tensor([223297.0625])\n",
      "Batch Average Reconstruciton Loss:503870624.0\n",
      "input:tensor([  3.9280,   2.4335,   2.9156,   2.4285, 682.0000])\n",
      "output:tensor([223321.1250])\n",
      "Batch Average Reconstruciton Loss:854093312.0\n",
      "input:tensor([  8.6690,   2.0005,   9.6387,   1.9675, 682.0000])\n",
      "output:tensor([223214.8438])\n",
      "Batch Average Reconstruciton Loss:11833924608.0\n",
      "input:tensor([  4.7050,   3.1110,   3.4068,   3.0680, 682.0000])\n",
      "output:tensor([223284.3594])\n",
      "Batch Average Reconstruciton Loss:154862080.0\n",
      "input:tensor([  5.3150,   3.0370,   4.1010,   2.9570, 682.0000])\n",
      "output:tensor([223274.0156])\n",
      "Batch Average Reconstruciton Loss:1341904512.0\n",
      "input:tensor([  3.4270,   2.1645,   2.5367,   2.1465, 682.0000])\n",
      "output:tensor([223340.4375])\n",
      "Batch Average Reconstruciton Loss:4372590080.0\n",
      "input:tensor([  5.1180,   3.6575,   2.4954,   3.6525, 682.0000])\n",
      "output:tensor([223269.2969])\n",
      "Batch Average Reconstruciton Loss:866907712.0\n",
      "input:tensor([  4.4190,   2.6435,   3.3281,   2.6055, 682.0000])\n",
      "output:tensor([223304.8125])\n",
      "Batch Average Reconstruciton Loss:1392842.5\n",
      "input:tensor([ 18.6570,  23.9720,  20.9266,  23.9290, 682.0000])\n",
      "output:tensor([222203.3594])\n",
      "Batch Average Reconstruciton Loss:28572276736.0\n",
      "input:tensor([  4.1943,   3.3345,   2.9721,   3.2765, 682.0000])\n",
      "output:tensor([223286.8594])\n",
      "Batch Average Reconstruciton Loss:174851440.0\n",
      "input:tensor([  4.1583,   2.8555,   2.9942,   2.8195, 682.0000])\n",
      "output:tensor([223303.5469])\n",
      "Batch Average Reconstruciton Loss:232667840.0\n",
      "input:tensor([  3.7700,   2.2355,   2.8823,   2.1315, 682.0000])\n",
      "output:tensor([223332.7031])\n",
      "Batch Average Reconstruciton Loss:1583824896.0\n",
      "input:tensor([  3.2793,   2.1905,   2.3790,   2.0835, 682.0000])\n",
      "output:tensor([223345.])\n",
      "Batch Average Reconstruciton Loss:6265513984.0\n",
      "input:tensor([  4.8653,   3.7910,   3.2813,   3.7150, 682.0000])\n",
      "output:tensor([223260.5469])\n",
      "Batch Average Reconstruciton Loss:375179360.0\n",
      "input:tensor([  5.3110,   3.0480,   3.5565,   3.0140, 682.0000])\n",
      "output:tensor([223278.3438])\n",
      "Batch Average Reconstruciton Loss:1331983104.0\n",
      "input:tensor([  3.4320,   2.5535,   2.4263,   2.4865, 682.0000])\n",
      "output:tensor([223328.9062])\n",
      "Batch Average Reconstruciton Loss:4318473728.0\n",
      "input:tensor([  4.3280,   3.0930,   3.0835,   2.9810, 682.0000])\n",
      "output:tensor([223294.2188])\n",
      "Batch Average Reconstruciton Loss:34937336.0\n",
      "input:tensor([  4.4863,   3.2670,   1.9822,   3.2400, 682.0000])\n",
      "output:tensor([223296.])\n",
      "Batch Average Reconstruciton Loss:4752400.0\n",
      "input:tensor([  5.9533,   2.1270,   5.7263,   2.0560, 682.0000])\n",
      "output:tensor([223282.0938])\n",
      "Batch Average Reconstruciton Loss:3209573120.0\n",
      "input:tensor([  3.1107,   1.7380,   2.4356,   1.7000, 682.0000])\n",
      "output:tensor([223360.6094])\n",
      "Batch Average Reconstruciton Loss:9128348672.0\n",
      "input:tensor([  3.6250,   2.4250,   2.6113,   2.3900, 682.0000])\n",
      "output:tensor([223328.6406])\n",
      "Batch Average Reconstruciton Loss:2532742400.0\n",
      "input:tensor([  3.5940,   2.4830,   2.4067,   2.3360, 682.0000])\n",
      "output:tensor([223331.9375])\n",
      "Batch Average Reconstruciton Loss:2775610368.0\n",
      "input:tensor([  3.8727,   2.3545,   2.9033,   2.3155, 682.0000])\n",
      "output:tensor([223325.5000])\n",
      "Batch Average Reconstruciton Loss:1077710464.0\n",
      "input:tensor([  4.2053,   2.5100,   3.1815,   2.4400, 682.0000])\n",
      "output:tensor([223314.2188])\n",
      "Batch Average Reconstruciton Loss:158175424.0\n",
      "input:tensor([  4.1960,   2.8185,   3.0249,   2.7775, 682.0000])\n",
      "output:tensor([223304.2656])\n",
      "Batch Average Reconstruciton Loss:171917584.0\n",
      "input:tensor([  3.5740,   1.9810,   2.8225,   1.8780, 682.0000])\n",
      "output:tensor([223344.5156])\n",
      "Batch Average Reconstruciton Loss:2939318784.0\n",
      "input:tensor([  4.2960,   3.0155,   3.0647,   2.9825, 682.0000])\n",
      "output:tensor([223295.5312])\n",
      "Batch Average Reconstruciton Loss:58010596.0\n",
      "input:tensor([  4.0790,   2.6700,   2.9688,   2.5960, 682.0000])\n",
      "output:tensor([223312.2344])\n",
      "Batch Average Reconstruciton Loss:395403904.0\n",
      "input:tensor([  4.5223,   2.8765,   3.3295,   2.8115, 682.0000])\n",
      "output:tensor([223296.0469])\n",
      "Batch Average Reconstruciton Loss:15523969.0\n",
      "input:tensor([  3.0860,   2.2250,   2.1898,   2.2080, 682.0000])\n",
      "output:tensor([223345.5938])\n",
      "Batch Average Reconstruciton Loss:9624866816.0\n",
      "input:tensor([  3.4963,   2.1240,   2.6326,   2.0440, 682.0000])\n",
      "output:tensor([223341.6719])\n",
      "Batch Average Reconstruciton Loss:3646267136.0\n",
      "input:tensor([  4.3150,   2.9505,   3.0918,   2.9075, 682.0000])\n",
      "output:tensor([223297.6250])\n",
      "Batch Average Reconstruciton Loss:43538552.0\n",
      "input:tensor([  4.2520,   2.3445,   3.3224,   2.3075, 682.0000])\n",
      "output:tensor([223317.2969])\n",
      "Batch Average Reconstruciton Loss:99694296.0\n",
      "input:tensor([  3.5417,   2.2585,   2.4843,   2.0915, 682.0000])\n",
      "output:tensor([223340.1719])\n",
      "Batch Average Reconstruciton Loss:3220997120.0\n",
      "input:tensor([  4.5837,   2.9100,   3.3662,   2.8700, 682.0000])\n",
      "output:tensor([223293.1875])\n",
      "Batch Average Reconstruciton Loss:47226960.0\n",
      "input:tensor([  3.7877,   2.7215,   2.6860,   2.6785, 682.0000])\n",
      "output:tensor([223315.7500])\n",
      "Batch Average Reconstruciton Loss:1488975872.0\n",
      "input:tensor([  4.1580,   3.2310,   2.9380,   3.1970, 682.0000])\n",
      "output:tensor([223290.6875])\n",
      "Batch Average Reconstruciton Loss:233640784.0\n",
      "input:tensor([  5.5470,   3.8460,   3.9685,   3.8060, 682.0000])\n",
      "output:tensor([223243.0625])\n",
      "Batch Average Reconstruciton Loss:1972076032.0\n",
      "input:tensor([  3.4093,   2.1510,   2.5202,   2.0740, 682.0000])\n",
      "output:tensor([223342.7656])\n",
      "Batch Average Reconstruciton Loss:4572901888.0\n",
      "input:tensor([  3.6743,   2.5810,   2.6187,   2.5400, 682.0000])\n",
      "output:tensor([223322.6562])\n",
      "Batch Average Reconstruciton Loss:2177000960.0\n",
      "input:tensor([  4.6490,   2.1870,   3.9378,   2.1520, 682.0000])\n",
      "output:tensor([223312.0781])\n",
      "Batch Average Reconstruciton Loss:98666040.0\n",
      "input:tensor([ 27.9570,   2.7345,  35.8170,   2.7175, 682.0000])\n",
      "output:tensor([222702.7188])\n",
      "Batch Average Reconstruciton Loss:35051225088.0\n",
      "input:tensor([  4.6750,   3.0390,   3.3970,   3.0220, 682.0000])\n",
      "output:tensor([223286.7031])\n",
      "Batch Average Reconstruciton Loss:123070248.0\n",
      "input:tensor([  5.4897,   2.7310,   4.5207,   2.6920, 682.0000])\n",
      "output:tensor([223277.5625])\n",
      "Batch Average Reconstruciton Loss:1812593408.0\n",
      "input:tensor([  6.6203,   4.5755,   4.7335,   4.5395, 682.0000])\n",
      "output:tensor([223197.3281])\n",
      "Batch Average Reconstruciton Loss:5381150720.0\n",
      "input:tensor([  4.8057,   3.7375,   2.6996,   3.6755, 682.0000])\n",
      "output:tensor([223268.9688])\n",
      "Batch Average Reconstruciton Loss:283786656.0\n",
      "input:tensor([  4.2807,   2.4800,   3.2723,   2.4380, 682.0000])\n",
      "output:tensor([223312.8438])\n",
      "Batch Average Reconstruciton Loss:71016960.0\n",
      "input:tensor([  4.0057,   2.0750,   3.2546,   2.0320, 682.0000])\n",
      "output:tensor([223330.4219])\n",
      "Batch Average Reconstruciton Loss:591393216.0\n",
      "input:tensor([  3.9437,   1.9795,   3.2561,   1.9205, 682.0000])\n",
      "output:tensor([223334.8750])\n",
      "Batch Average Reconstruciton Loss:795698304.0\n",
      "input:tensor([  4.0890,   2.7055,   2.9585,   2.6455, 682.0000])\n",
      "output:tensor([223310.6250])\n",
      "Batch Average Reconstruciton Loss:372157152.0\n",
      "input:tensor([  3.8677,   2.9220,   2.5422,   2.7900, 682.0000])\n",
      "output:tensor([223311.5000])\n",
      "Batch Average Reconstruciton Loss:1100481152.0\n",
      "input:tensor([  4.1600,   2.8730,   2.9943,   2.8660, 682.0000])\n",
      "output:tensor([223302.1875])\n",
      "Batch Average Reconstruciton Loss:229819920.0\n",
      "input:tensor([  3.9390,   1.9815,   3.2394,   1.9405, 682.0000])\n",
      "output:tensor([223334.5938])\n",
      "Batch Average Reconstruciton Loss:812615168.0\n",
      "input:tensor([  4.0753,   2.6505,   2.9664,   2.6335, 682.0000])\n",
      "output:tensor([223311.5625])\n",
      "Batch Average Reconstruciton Loss:404188416.0\n",
      "input:tensor([ 20.1170,  26.0540,  22.8142,  26.0220, 682.0000])\n",
      "output:tensor([222092.9688])\n",
      "Batch Average Reconstruciton Loss:29853263872.0\n",
      "input:tensor([  3.6267,   2.0350,   2.8544,   1.9220, 682.0000])\n",
      "output:tensor([223341.9062])\n",
      "Batch Average Reconstruciton Loss:2518744320.0\n",
      "input:tensor([ 23.8983,   2.2325,  30.7212,   2.1985, 682.0000])\n",
      "output:tensor([222818.7969])\n",
      "Batch Average Reconstruciton Loss:32873242624.0\n",
      "input:tensor([  5.6123,   3.0095,   4.4692,   2.9495, 682.0000])\n",
      "output:tensor([223267.3906])\n",
      "Batch Average Reconstruciton Loss:2163495424.0\n",
      "input:tensor([  3.6570,   2.1195,   2.8326,   1.9365, 682.0000])\n",
      "output:tensor([223340.5781])\n",
      "Batch Average Reconstruciton Loss:2296366848.0\n",
      "input:tensor([  3.5670,   2.2420,   2.6348,   2.2070, 682.0000])\n",
      "output:tensor([223335.5625])\n",
      "Batch Average Reconstruciton Loss:2999691264.0\n",
      "input:tensor([  4.6493,   2.5195,   3.6629,   2.5015, 682.0000])\n",
      "output:tensor([223302.7188])\n",
      "Batch Average Reconstruciton Loss:98778128.0\n",
      "input:tensor([  4.5637,   2.4190,   3.6386,   2.3910, 682.0000])\n",
      "output:tensor([223307.7031])\n",
      "Batch Average Reconstruciton Loss:35268196.0\n",
      "input:tensor([  3.3613,   2.1140,   2.4719,   2.1100, 682.0000])\n",
      "output:tensor([223343.2656])\n",
      "Batch Average Reconstruciton Loss:5152043008.0\n",
      "input:tensor([ 71.7920,  73.4600, 120.2450,  99.8733, 802.0000])\n",
      "output:tensor([257464.7031])\n",
      "Batch Average Reconstruciton Loss:60058177536.0\n",
      "input:tensor([  3.6867,   2.5935,   2.6310,   2.5275, 682.0000])\n",
      "output:tensor([223322.5469])\n",
      "Batch Average Reconstruciton Loss:2093561472.0\n",
      "input:tensor([  4.3727,   2.1230,   3.5203,   2.0180, 682.0000])\n",
      "output:tensor([223323.5312])\n",
      "Batch Average Reconstruciton Loss:12534919.0\n",
      "input:tensor([  3.9743,   1.9740,   3.2722,   1.9400, 682.0000])\n",
      "output:tensor([223333.9219])\n",
      "Batch Average Reconstruciton Loss:690011904.0\n",
      "input:tensor([  3.8793,   2.4980,   2.8295,   2.4570, 682.0000])\n",
      "output:tensor([223321.1562])\n",
      "Batch Average Reconstruciton Loss:1049296320.0\n",
      "input:tensor([  6.0490,   3.4695,   4.6605,   3.4095, 682.0000])\n",
      "output:tensor([223244.2500])\n",
      "Batch Average Reconstruciton Loss:3510592000.0\n",
      "input:tensor([ 10.1407,   7.7895,   4.6440,   7.6925, 682.0000])\n",
      "output:tensor([223047.6250])\n",
      "Batch Average Reconstruciton Loss:15680956416.0\n",
      "input:tensor([  3.9350,   2.8965,   1.6315,   2.8915, 682.0000])\n",
      "output:tensor([223318.2969])\n",
      "Batch Average Reconstruciton Loss:828213760.0\n",
      "input:tensor([ 19.8450,   8.2660,  17.7379,   8.1960, 682.0000])\n",
      "output:tensor([222786.4844])\n",
      "Batch Average Reconstruciton Loss:29859661824.0\n",
      "input:tensor([  4.5620,   3.9240,   3.1682,   3.8100, 682.0000])\n",
      "output:tensor([223261.2031])\n",
      "Batch Average Reconstruciton Loss:33793332.0\n",
      "input:tensor([  5.3557,   3.1945,   4.0282,   3.1615, 682.0000])\n",
      "output:tensor([223267.5312])\n",
      "Batch Average Reconstruciton Loss:1447310208.0\n",
      "input:tensor([  4.3073,   2.4600,   3.3162,   2.4250, 682.0000])\n",
      "output:tensor([223312.6250])\n",
      "Batch Average Reconstruciton Loss:48893308.0\n",
      "input:tensor([ 19.8047,   2.4135,  24.6586,   2.3355, 682.0000])\n",
      "output:tensor([222921.9375])\n",
      "Batch Average Reconstruciton Loss:29871224832.0\n",
      "input:tensor([ 12.3653,   2.2015,  14.5556,   2.1955, 682.0000])\n",
      "output:tensor([223115.0312])\n",
      "Batch Average Reconstruciton Loss:20417847296.0\n",
      "input:tensor([  3.5580,   2.3175,   2.5940,   2.2995, 682.0000])\n",
      "output:tensor([223332.9688])\n",
      "Batch Average Reconstruciton Loss:3077479168.0\n",
      "input:tensor([  4.1357,   2.8135,   2.7904,   2.6965, 682.0000])\n",
      "output:tensor([223309.4844])\n",
      "Batch Average Reconstruciton Loss:274085088.0\n",
      "input:tensor([  3.6740,   2.5680,   2.6254,   2.4870, 682.0000])\n",
      "output:tensor([223324.0312])\n",
      "Batch Average Reconstruciton Loss:2179112960.0\n",
      "input:tensor([  4.0437,   2.3905,   3.0799,   2.3315, 682.0000])\n",
      "output:tensor([223321.0312])\n",
      "Batch Average Reconstruciton Loss:484042624.0\n",
      "input:tensor([  4.2887,   3.4460,   3.0418,   3.4110, 682.0000])\n",
      "output:tensor([223280.5469])\n",
      "Batch Average Reconstruciton Loss:64423948.0\n",
      "input:tensor([  3.6177,   2.5180,   2.5817,   2.4840, 682.0000])\n",
      "output:tensor([223325.7188])\n",
      "Batch Average Reconstruciton Loss:2589210112.0\n",
      "input:tensor([ 77.8360,  73.1320, 129.3404,  99.5019, 802.0000])\n",
      "output:tensor([257315.7812])\n",
      "Batch Average Reconstruciton Loss:60457848832.0\n",
      "input:tensor([  4.0000,   2.6280,   2.8987,   2.5930, 682.0000])\n",
      "output:tensor([223314.3594])\n",
      "Batch Average Reconstruciton Loss:609380864.0\n",
      "input:tensor([  4.8333,   2.7925,   3.6995,   2.7515, 682.0000])\n",
      "output:tensor([223291.1719])\n",
      "Batch Average Reconstruciton Loss:325808704.0\n",
      "input:tensor([  4.6363,   3.4690,   3.2758,   3.4310, 682.0000])\n",
      "output:tensor([223273.5938])\n",
      "Batch Average Reconstruciton Loss:86705776.0\n",
      "input:tensor([  3.9690,   2.6220,   2.8863,   2.5530, 682.0000])\n",
      "output:tensor([223315.8750])\n",
      "Batch Average Reconstruciton Loss:708684288.0\n",
      "input:tensor([  4.5000,   2.3920,   3.6191,   2.3150, 682.0000])\n",
      "output:tensor([223310.7969])\n",
      "Batch Average Reconstruciton Loss:8218524.5\n",
      "input:tensor([  4.4430,   2.7145,   3.3286,   2.6535, 682.0000])\n",
      "output:tensor([223302.5938])\n",
      "Batch Average Reconstruciton Loss:875.7900390625\n",
      "input:tensor([  4.3727,   2.6380,   3.2810,   2.5980, 682.0000])\n",
      "output:tensor([223306.0312])\n",
      "Batch Average Reconstruciton Loss:12659142.0\n",
      "input:tensor([  4.4647,   2.8215,   2.4319,   2.7605, 682.0000])\n",
      "output:tensor([223308.1719])\n",
      "Batch Average Reconstruciton Loss:1252545.625\n",
      "input:tensor([ 18.4307,   2.2325,  22.9297,   2.1765, 682.0000])\n",
      "output:tensor([222960.9688])\n",
      "Batch Average Reconstruciton Loss:28607651840.0\n",
      "input:tensor([  4.2390,   2.3630,   3.3074,   2.3010, 682.0000])\n",
      "output:tensor([223317.5781])\n",
      "Batch Average Reconstruciton Loss:114477632.0\n",
      "input:tensor([  4.8863,   2.9140,   3.7015,   2.8790, 682.0000])\n",
      "output:tensor([223286.0938])\n",
      "Batch Average Reconstruciton Loss:410917248.0\n",
      "input:tensor([  3.3910,   1.6435,   2.8416,   1.6095, 682.0000])\n",
      "output:tensor([223356.5781])\n",
      "Batch Average Reconstruciton Loss:4786207744.0\n",
      "input:tensor([  5.0147,   3.1280,   3.7107,   3.0880, 682.0000])\n",
      "output:tensor([223277.1406])\n",
      "Batch Average Reconstruciton Loss:648065984.0\n",
      "input:tensor([  4.7070,   3.1035,   3.4111,   3.0665, 682.0000])\n",
      "output:tensor([223284.4062])\n",
      "Batch Average Reconstruciton Loss:157111344.0\n",
      "input:tensor([  3.7837,   2.1540,   2.9182,   2.1190, 682.0000])\n",
      "output:tensor([223333.3594])\n",
      "Batch Average Reconstruciton Loss:1509061504.0\n",
      "input:tensor([  4.2073,   2.8365,   2.3709,   2.8325, 682.0000])\n",
      "output:tensor([223309.5781])\n",
      "Batch Average Reconstruciton Loss:155486480.0\n",
      "input:tensor([  4.1783,   2.7785,   2.0925,   2.7725, 682.0000])\n",
      "output:tensor([223314.9844])\n",
      "Batch Average Reconstruciton Loss:198810448.0\n",
      "input:tensor([  3.5907,   2.3695,   2.5957,   2.3625, 682.0000])\n",
      "output:tensor([223330.4531])\n",
      "Batch Average Reconstruciton Loss:2802807296.0\n",
      "input:tensor([  4.9497,   2.9535,   2.9557,   2.9475, 682.0000])\n",
      "output:tensor([223291.2969])\n",
      "Batch Average Reconstruciton Loss:523187712.0\n",
      "input:tensor([  4.2560,   2.4625,   3.2592,   2.4205, 682.0000])\n",
      "output:tensor([223313.8438])\n",
      "Batch Average Reconstruciton Loss:95436416.0\n",
      "input:tensor([  6.1550,   4.2470,   3.8068,   4.2120, 682.0000])\n",
      "output:tensor([223223.9219])\n",
      "Batch Average Reconstruciton Loss:3850689280.0\n",
      "input:tensor([  5.0623,   2.1315,   4.5443,   2.0655, 682.0000])\n",
      "output:tensor([223303.9375])\n",
      "Batch Average Reconstruciton Loss:747854976.0\n",
      "input:tensor([  4.0213,   3.0930,   2.8401,   3.0230, 682.0000])\n",
      "output:tensor([223299.0156])\n",
      "Batch Average Reconstruciton Loss:546857472.0\n",
      "input:tensor([  4.6740,   2.6215,   3.6371,   2.5455, 682.0000])\n",
      "output:tensor([223300.5469])\n",
      "Batch Average Reconstruciton Loss:122379944.0\n",
      "input:tensor([  5.0840,   1.7730,   4.9491,   1.7310, 682.0000])\n",
      "output:tensor([223311.5625])\n",
      "Batch Average Reconstruciton Loss:794651456.0\n",
      "input:tensor([  3.4667,   2.2800,   2.5163,   2.2460, 682.0000])\n",
      "output:tensor([223336.5156])\n",
      "Batch Average Reconstruciton Loss:3946036224.0\n",
      "input:tensor([  4.0287,   3.1640,   2.6310,   3.0960, 682.0000])\n",
      "output:tensor([223298.5938])\n",
      "Batch Average Reconstruciton Loss:526078720.0\n",
      "input:tensor([  4.1097,   2.1830,   3.2758,   2.1140, 682.0000])\n",
      "output:tensor([223325.8750])\n",
      "Batch Average Reconstruciton Loss:326023648.0\n",
      "input:tensor([  3.8540,   2.3570,   2.8969,   2.2490, 682.0000])\n",
      "output:tensor([223327.4219])\n",
      "Batch Average Reconstruciton Loss:1160599936.0\n",
      "input:tensor([  4.3620,   3.0475,   3.1138,   2.9675, 682.0000])\n",
      "output:tensor([223294.3594])\n",
      "Batch Average Reconstruciton Loss:17012660.0\n",
      "input:tensor([  4.6027,   1.9300,   4.1206,   1.9250, 682.0000])\n",
      "output:tensor([223319.0312])\n",
      "Batch Average Reconstruciton Loss:60715752.0\n",
      "input:tensor([  6.3930,   2.0710,   6.3765,   2.0100, 682.0000])\n",
      "output:tensor([223272.1875])\n",
      "Batch Average Reconstruciton Loss:4637907968.0\n",
      "input:tensor([  4.0167,   2.5710,   2.9391,   2.5370, 682.0000])\n",
      "output:tensor([223315.7500])\n",
      "Batch Average Reconstruciton Loss:559570880.0\n",
      "input:tensor([  4.1277,   2.5290,   3.0626,   2.4450, 682.0000])\n",
      "output:tensor([223315.9844])\n",
      "Batch Average Reconstruciton Loss:289442688.0\n",
      "input:tensor([  4.8530,   4.3155,   3.5613,   4.2115, 682.0000])\n",
      "output:tensor([223239.6562])\n",
      "Batch Average Reconstruciton Loss:354555968.0\n",
      "input:tensor([  4.6990,   2.7750,   3.5641,   2.7040, 682.0000])\n",
      "output:tensor([223295.4375])\n",
      "Batch Average Reconstruciton Loss:148509264.0\n",
      "input:tensor([  4.0950,   2.9680,   2.8999,   2.9340, 682.0000])\n",
      "output:tensor([223301.1562])\n",
      "Batch Average Reconstruciton Loss:358944992.0\n",
      "input:tensor([  9.8900,   2.5205,  10.6628,   2.4865, 682.0000])\n",
      "output:tensor([223172.3750])\n",
      "Batch Average Reconstruciton Loss:15096883200.0\n",
      "input:tensor([  4.0763,   2.5460,   3.0196,   2.4860, 682.0000])\n",
      "output:tensor([223315.7969])\n",
      "Batch Average Reconstruciton Loss:401609728.0\n",
      "input:tensor([  7.6577,   7.8405,   6.3682,   7.8065, 682.0000])\n",
      "output:tensor([223052.1406])\n",
      "Batch Average Reconstruciton Loss:8743959552.0\n",
      "input:tensor([  3.9857,   2.5450,   2.9350,   2.4360, 682.0000])\n",
      "output:tensor([223318.9375])\n",
      "Batch Average Reconstruciton Loss:653981504.0\n",
      "input:tensor([  3.7953,   2.2250,   2.8888,   2.1910, 682.0000])\n",
      "output:tensor([223331.])\n",
      "Batch Average Reconstruciton Loss:1447269888.0\n",
      "input:tensor([ 20.9060,  14.9430,  12.6821,  14.8410, 682.0000])\n",
      "output:tensor([222591.7656])\n",
      "Batch Average Reconstruciton Loss:30674638848.0\n",
      "input:tensor([  4.2690,   2.4735,   3.2677,   2.4095, 682.0000])\n",
      "output:tensor([223313.7812])\n",
      "Batch Average Reconstruciton Loss:82069448.0\n",
      "input:tensor([  3.1597,   2.4520,   2.2317,   2.3830, 682.0000])\n",
      "output:tensor([223337.5625])\n",
      "Batch Average Reconstruciton Loss:8211882496.0\n",
      "input:tensor([  4.9870,   2.3375,   4.2492,   2.2725, 682.0000])\n",
      "output:tensor([223300.5000])\n",
      "Batch Average Reconstruciton Loss:594555072.0\n",
      "input:tensor([  4.0807,   3.3495,   2.9047,   3.3315, 682.0000])\n",
      "output:tensor([223287.2500])\n",
      "Batch Average Reconstruciton Loss:392465824.0\n",
      "input:tensor([  3.2510,   1.8650,   2.5059,   1.8230, 682.0000])\n",
      "output:tensor([223353.9531])\n",
      "Batch Average Reconstruciton Loss:6688466944.0\n",
      "input:tensor([  3.8747,   2.3480,   2.9011,   2.3120, 682.0000])\n",
      "output:tensor([223325.6875])\n",
      "Batch Average Reconstruciton Loss:1069048832.0\n",
      "input:tensor([  5.0377,   4.1205,   3.4456,   3.9725, 682.0000])\n",
      "output:tensor([223247.])\n",
      "Batch Average Reconstruciton Loss:693268928.0\n",
      "input:tensor([  4.2050,   2.0410,   3.4802,   2.0240, 682.0000])\n",
      "output:tensor([223326.4375])\n",
      "Batch Average Reconstruciton Loss:158346048.0\n",
      "input:tensor([ 35.5270,   2.5875,  46.6518,   2.5525, 682.0000])\n",
      "output:tensor([222511.8438])\n",
      "Batch Average Reconstruciton Loss:37865205760.0\n",
      "input:tensor([  5.3753,   3.6290,   3.2690,   3.5210, 682.0000])\n",
      "output:tensor([223261.8594])\n",
      "Batch Average Reconstruciton Loss:1498840320.0\n",
      "input:tensor([  3.9077,   2.4410,   2.9006,   2.3820, 682.0000])\n",
      "output:tensor([223322.5938])\n",
      "Batch Average Reconstruciton Loss:932533184.0\n",
      "input:tensor([  3.8260,   3.0330,   2.7063,   2.9920, 682.0000])\n",
      "output:tensor([223303.9375])\n",
      "Batch Average Reconstruciton Loss:1294205184.0\n",
      "input:tensor([  3.9087,   2.4240,   2.8970,   2.3890, 682.0000])\n",
      "output:tensor([223322.6250])\n",
      "Batch Average Reconstruciton Loss:928565632.0\n",
      "input:tensor([  5.1377,   3.2840,   3.7550,   3.2500, 682.0000])\n",
      "output:tensor([223269.6250])\n",
      "Batch Average Reconstruciton Loss:911171968.0\n",
      "input:tensor([  3.7290,   2.6435,   2.6566,   2.6015, 682.0000])\n",
      "output:tensor([223319.4531])\n",
      "Batch Average Reconstruciton Loss:1823592960.0\n",
      "input:tensor([  4.7903,   3.6995,   3.0076,   3.6635, 682.0000])\n",
      "output:tensor([223266.5312])\n",
      "Batch Average Reconstruciton Loss:261874320.0\n",
      "input:tensor([  4.8457,   3.7325,   3.4236,   3.6975, 682.0000])\n",
      "output:tensor([223260.2969])\n",
      "Batch Average Reconstruciton Loss:343779680.0\n",
      "input:tensor([ 20.2703,   2.1330,  25.7901,   2.0990, 682.0000])\n",
      "output:tensor([222913.7656])\n",
      "Batch Average Reconstruciton Loss:30267219968.0\n",
      "input:tensor([  5.0843,   3.5900,   3.6129,   3.5490, 682.0000])\n",
      "output:tensor([223260.9844])\n",
      "Batch Average Reconstruciton Loss:792534208.0\n",
      "input:tensor([  4.4650,   2.0680,   3.8087,   2.0620, 682.0000])\n",
      "output:tensor([223318.9219])\n",
      "Batch Average Reconstruciton Loss:1315429.75\n",
      "input:tensor([  4.6980,   2.4915,   3.7637,   2.4255, 682.0000])\n",
      "output:tensor([223303.3125])\n",
      "Batch Average Reconstruciton Loss:147605792.0\n",
      "input:tensor([  3.4600,   1.7645,   2.8280,   1.7285, 682.0000])\n",
      "output:tensor([223351.7031])\n",
      "Batch Average Reconstruciton Loss:4013640192.0\n",
      "input:tensor([  3.3310,   2.2450,   2.3973,   2.2110, 682.0000])\n",
      "output:tensor([223340.4844])\n",
      "Batch Average Reconstruciton Loss:5545411072.0\n",
      "input:tensor([  5.2277,   3.8570,   3.6941,   3.8370, 682.0000])\n",
      "output:tensor([223248.5000])\n",
      "Batch Average Reconstruciton Loss:1121479680.0\n",
      "input:tensor([  3.6387,   2.5315,   2.6068,   2.4525, 682.0000])\n",
      "output:tensor([223325.8906])\n",
      "Batch Average Reconstruciton Loss:2430599424.0\n",
      "input:tensor([  3.5880,   2.3455,   2.6060,   2.3395, 682.0000])\n",
      "output:tensor([223331.2188])\n",
      "Batch Average Reconstruciton Loss:2824474112.0\n",
      "input:tensor([  3.6690,   2.2315,   2.7505,   2.1915, 682.0000])\n",
      "output:tensor([223333.7344])\n",
      "Batch Average Reconstruciton Loss:2212692480.0\n",
      "input:tensor([  3.6070,   2.4490,   2.5965,   2.3850, 682.0000])\n",
      "output:tensor([223328.8750])\n",
      "Batch Average Reconstruciton Loss:2672075776.0\n",
      "input:tensor([ 14.0970,   2.1525,  16.8841,   2.0945, 682.0000])\n",
      "output:tensor([223074.7188])\n",
      "Batch Average Reconstruciton Loss:23318730752.0\n",
      "input:tensor([  3.1900,   1.8390,   2.4483,   1.8040, 682.0000])\n",
      "output:tensor([223355.9688])\n",
      "Batch Average Reconstruciton Loss:7676569088.0\n",
      "input:tensor([  3.9493,   2.4885,   2.9180,   2.4345, 682.0000])\n",
      "output:tensor([223320.1406])\n",
      "Batch Average Reconstruciton Loss:776283200.0\n",
      "input:tensor([  4.4267,   2.2350,   3.6307,   2.2080, 682.0000])\n",
      "output:tensor([223315.7812])\n",
      "Batch Average Reconstruciton Loss:608741.3125\n",
      "input:tensor([  3.3390,   1.9960,   2.5119,   1.9790, 682.0000])\n",
      "output:tensor([223347.6406])\n",
      "Batch Average Reconstruciton Loss:5438672896.0\n",
      "input:tensor([  7.7907,   4.3120,   6.0667,   4.3050, 682.0000])\n",
      "output:tensor([223179.2656])\n",
      "Batch Average Reconstruciton Loss:9186698240.0\n",
      "input:tensor([  4.0447,   2.5250,   3.0142,   2.4170, 682.0000])\n",
      "output:tensor([223318.1250])\n",
      "Batch Average Reconstruciton Loss:481489760.0\n",
      "input:tensor([ 22.2997,   2.5535,  28.0222,   2.5185, 682.0000])\n",
      "output:tensor([222853.2812])\n",
      "Batch Average Reconstruciton Loss:31815243776.0\n",
      "input:tensor([  3.9797,   3.1215,   2.5361,   3.0525, 682.0000])\n",
      "output:tensor([223301.6875])\n",
      "Batch Average Reconstruciton Loss:674197440.0\n",
      "input:tensor([  7.6613,   2.4280,   7.6582,   2.4210, 682.0000])\n",
      "output:tensor([223230.8906])\n",
      "Batch Average Reconstruciton Loss:8789042176.0\n",
      "input:tensor([  3.7360,   2.2220,   2.8510,   2.1190, 682.0000])\n",
      "output:tensor([223333.8750])\n",
      "Batch Average Reconstruciton Loss:1780091008.0\n",
      "input:tensor([  8.2950,   3.3695,   7.5302,   3.2675, 682.0000])\n",
      "output:tensor([223194.2656])\n",
      "Batch Average Reconstruciton Loss:10733843456.0\n",
      "input:tensor([  3.4570,   2.4730,   2.0580,   2.3990, 682.0000])\n",
      "output:tensor([223335.6406])\n",
      "Batch Average Reconstruciton Loss:4047295744.0\n",
      "input:tensor([  3.9873,   2.4670,   2.9603,   2.4510, 682.0000])\n",
      "output:tensor([223319.0781])\n",
      "Batch Average Reconstruciton Loss:648665984.0\n",
      "input:tensor([ 12.9167,   9.4235,   9.1441,   9.3635, 682.0000])\n",
      "output:tensor([222910.6250])\n",
      "Batch Average Reconstruciton Loss:21348315136.0\n",
      "input:tensor([  4.0560,   2.1550,   3.2578,   2.0980, 682.0000])\n",
      "output:tensor([223327.3438])\n",
      "Batch Average Reconstruciton Loss:451505408.0\n",
      "input:tensor([  3.9283,   1.8740,   3.3301,   1.8010, 682.0000])\n",
      "output:tensor([223338.3594])\n",
      "Batch Average Reconstruciton Loss:851801600.0\n",
      "input:tensor([  4.4650,   2.4590,   3.5022,   2.4240, 682.0000])\n",
      "output:tensor([223308.9844])\n",
      "Batch Average Reconstruciton Loss:1292733.5\n",
      "input:tensor([  3.9947,   3.0335,   1.6092,   2.9225, 682.0000])\n",
      "output:tensor([223315.6562])\n",
      "Batch Average Reconstruciton Loss:625767424.0\n",
      "input:tensor([  3.9547,   2.4060,   2.9670,   2.3740, 682.0000])\n",
      "output:tensor([223321.9375])\n",
      "Batch Average Reconstruciton Loss:757408896.0\n",
      "input:tensor([  3.9883,   2.4655,   2.9621,   2.4305, 682.0000])\n",
      "output:tensor([223319.5938])\n",
      "Batch Average Reconstruciton Loss:645434688.0\n",
      "input:tensor([  4.2063,   2.3530,   3.2699,   2.3180, 682.0000])\n",
      "output:tensor([223317.9844])\n",
      "Batch Average Reconstruciton Loss:156675680.0\n",
      "input:tensor([  4.1570,   2.7915,   2.9977,   2.7495, 682.0000])\n",
      "output:tensor([223305.9375])\n",
      "Batch Average Reconstruciton Loss:234949504.0\n",
      "input:tensor([  4.1840,   1.7985,   3.7246,   1.7235, 682.0000])\n",
      "output:tensor([223334.1719])\n",
      "Batch Average Reconstruciton Loss:189332864.0\n",
      "input:tensor([  3.9257,   2.4600,   2.9144,   2.4430, 682.0000])\n",
      "output:tensor([223320.5156])\n",
      "Batch Average Reconstruciton Loss:862919104.0\n",
      "input:tensor([  3.2807,   1.9600,   2.4729,   1.9250, 682.0000])\n",
      "output:tensor([223350.4062])\n",
      "Batch Average Reconstruciton Loss:6245360640.0\n",
      "input:tensor([  4.6183,   2.9705,   3.3764,   2.9095, 682.0000])\n",
      "output:tensor([223291.0781])\n",
      "Batch Average Reconstruciton Loss:72166352.0\n",
      "input:tensor([  4.3710,   3.0970,   3.1219,   2.9370, 682.0000])\n",
      "output:tensor([223294.3906])\n",
      "Batch Average Reconstruciton Loss:13363480.0\n",
      "input:tensor([  6.8133,   5.2580,   4.8170,   5.2190, 682.0000])\n",
      "output:tensor([223170.0625])\n",
      "Batch Average Reconstruciton Loss:6017580032.0\n",
      "input:tensor([  4.2217,   3.3585,   1.6681,   3.2805, 682.0000])\n",
      "output:tensor([223300.1719])\n",
      "Batch Average Reconstruciton Loss:136371664.0\n",
      "input:tensor([  4.0980,   2.2285,   2.6531,   2.2235, 682.0000])\n",
      "output:tensor([223329.4375])\n",
      "Batch Average Reconstruciton Loss:351171200.0\n",
      "input:tensor([  3.8653,   2.3585,   2.9028,   2.2915, 682.0000])\n",
      "output:tensor([223326.1719])\n",
      "Batch Average Reconstruciton Loss:1109811200.0\n",
      "input:tensor([ 30.4200,   2.1520,  40.0843,   2.0810, 682.0000])\n",
      "output:tensor([222652.9844])\n",
      "Batch Average Reconstruciton Loss:36116336640.0\n",
      "input:tensor([  4.0567,   3.1520,   2.8665,   3.0480, 682.0000])\n",
      "output:tensor([223297.1094])\n",
      "Batch Average Reconstruciton Loss:451090464.0\n",
      "input:tensor([  3.7720,   2.7425,   2.6735,   2.7245, 682.0000])\n",
      "output:tensor([223314.6562])\n",
      "Batch Average Reconstruciton Loss:1574132864.0\n",
      "input:tensor([  3.7410,   2.1565,   2.8838,   2.1125, 682.0000])\n",
      "output:tensor([223334.3281])\n",
      "Batch Average Reconstruciton Loss:1750223488.0\n",
      "input:tensor([  4.7130,   3.1505,   3.4014,   3.1145, 682.0000])\n",
      "output:tensor([223282.7500])\n",
      "Batch Average Reconstruciton Loss:163859200.0\n",
      "input:tensor([  3.8347,   2.3405,   2.8666,   2.3225, 682.0000])\n",
      "output:tensor([223326.2812])\n",
      "Batch Average Reconstruciton Loss:1250804736.0\n",
      "input:tensor([  4.8497,   3.1465,   3.5310,   3.1065, 682.0000])\n",
      "output:tensor([223280.1562])\n",
      "Batch Average Reconstruciton Loss:350818752.0\n",
      "input:tensor([  3.9757,   2.5000,   2.9381,   2.4930, 682.0000])\n",
      "output:tensor([223318.0469])\n",
      "Batch Average Reconstruciton Loss:686437568.0\n",
      "input:tensor([  4.9167,   3.1930,   3.5770,   3.1590, 682.0000])\n",
      "output:tensor([223277.1406])\n",
      "Batch Average Reconstruciton Loss:462858240.0\n",
      "input:tensor([  3.7813,   2.1895,   2.8866,   2.1485, 682.0000])\n",
      "output:tensor([223332.6250])\n",
      "Batch Average Reconstruciton Loss:1521653376.0\n",
      "input:tensor([  3.9123,   2.3350,   2.9565,   2.3160, 682.0000])\n",
      "output:tensor([223324.7031])\n",
      "Batch Average Reconstruciton Loss:913991744.0\n",
      "input:tensor([  4.2483,   2.9245,   3.0446,   2.8435, 682.0000])\n",
      "output:tensor([223300.7344])\n",
      "Batch Average Reconstruciton Loss:104086224.0\n",
      "input:tensor([  4.3973,   3.0475,   3.1405,   3.0135, 682.0000])\n",
      "output:tensor([223292.5312])\n",
      "Batch Average Reconstruciton Loss:5282958.5\n",
      "input:tensor([  3.8740,   2.3135,   2.9342,   2.2135, 682.0000])\n",
      "output:tensor([223328.1562])\n",
      "Batch Average Reconstruciton Loss:1071766400.0\n",
      "input:tensor([  3.8717,   3.0195,   2.7371,   2.9785, 682.0000])\n",
      "output:tensor([223303.6250])\n",
      "Batch Average Reconstruciton Loss:1083487744.0\n",
      "input:tensor([  3.7823,   2.2000,   2.8935,   2.1820, 682.0000])\n",
      "output:tensor([223331.5781])\n",
      "Batch Average Reconstruciton Loss:1516356480.0\n",
      "input:tensor([  3.6960,   2.0960,   2.8551,   2.0620, 682.0000])\n",
      "output:tensor([223337.0312])\n",
      "Batch Average Reconstruciton Loss:2030490880.0\n",
      "input:tensor([  3.9497,   2.4880,   2.7233,   2.3810, 682.0000])\n",
      "output:tensor([223323.5625])\n",
      "Batch Average Reconstruciton Loss:774867264.0\n",
      "input:tensor([  4.5553,   3.4075,   3.2209,   3.3385, 682.0000])\n",
      "output:tensor([223278.])\n",
      "Batch Average Reconstruciton Loss:30371120.0\n",
      "input:tensor([  3.5470,   1.8600,   2.8611,   1.8180, 682.0000])\n",
      "output:tensor([223347.1562])\n",
      "Batch Average Reconstruciton Loss:3172600576.0\n",
      "input:tensor([  6.6693,   4.7425,   4.7357,   4.7255, 682.0000])\n",
      "output:tensor([223190.3281])\n",
      "Batch Average Reconstruciton Loss:5542851584.0\n",
      "input:tensor([  3.6800,   2.0495,   2.8645,   2.0075, 682.0000])\n",
      "output:tensor([223338.9375])\n",
      "Batch Average Reconstruciton Loss:2136848896.0\n",
      "input:tensor([  4.0167,   2.5430,   2.9522,   2.5240, 682.0000])\n",
      "output:tensor([223316.2344])\n",
      "Batch Average Reconstruciton Loss:559547968.0\n",
      "input:tensor([  4.2823,   2.0200,   3.6492,   1.9460, 682.0000])\n",
      "output:tensor([223325.9844])\n",
      "Batch Average Reconstruciton Loss:69272592.0\n",
      "input:tensor([  3.5277,   2.3335,   2.5645,   2.2935, 682.0000])\n",
      "output:tensor([223333.5938])\n",
      "Batch Average Reconstruciton Loss:3349215488.0\n",
      "input:tensor([  4.2080,   3.6340,   3.0485,   3.5740, 682.0000])\n",
      "output:tensor([223275.2188])\n",
      "Batch Average Reconstruciton Loss:155395696.0\n",
      "input:tensor([  4.4407,   3.2405,   3.1500,   3.1365, 682.0000])\n",
      "output:tensor([223286.8281])\n",
      "Batch Average Reconstruciton Loss:10644.435546875\n",
      "input:tensor([  3.7153,   2.6210,   2.6440,   2.5870, 682.0000])\n",
      "output:tensor([223320.3281])\n",
      "Batch Average Reconstruciton Loss:1908088448.0\n",
      "input:tensor([  3.5693,   2.4340,   2.5701,   2.3560, 682.0000])\n",
      "output:tensor([223330.4531])\n",
      "Batch Average Reconstruciton Loss:2980346112.0\n",
      "input:tensor([  4.0800,   2.6725,   2.9624,   2.6375, 682.0000])\n",
      "output:tensor([223311.2188])\n",
      "Batch Average Reconstruciton Loss:393061600.0\n",
      "input:tensor([  4.7737,   3.1940,   3.4340,   3.1890, 682.0000])\n",
      "output:tensor([223279.4375])\n",
      "Batch Average Reconstruciton Loss:239396320.0\n",
      "input:tensor([  4.2487,   2.9130,   3.0399,   2.8770, 682.0000])\n",
      "output:tensor([223300.0469])\n",
      "Batch Average Reconstruciton Loss:103733272.0\n",
      "input:tensor([  4.4093,   3.3575,   2.1649,   3.3515, 682.0000])\n",
      "output:tensor([223291.0938])\n",
      "Batch Average Reconstruciton Loss:2842280.0\n",
      "input:tensor([  5.2727,   3.7835,   3.7512,   3.5945, 682.0000])\n",
      "output:tensor([223254.3125])\n",
      "Batch Average Reconstruciton Loss:1233014912.0\n",
      "input:tensor([ 27.5533,   2.0665,  36.1655,   2.0055, 682.0000])\n",
      "output:tensor([222728.2500])\n",
      "Batch Average Reconstruciton Loss:34866319360.0\n",
      "input:tensor([  4.4343,   3.1500,   3.1448,   3.1160, 682.0000])\n",
      "output:tensor([223288.4375])\n",
      "Batch Average Reconstruciton Loss:176872.8125\n",
      "input:tensor([  7.0837,   2.5915,   6.7462,   2.5255, 682.0000])\n",
      "output:tensor([223242.4375])\n",
      "Batch Average Reconstruciton Loss:6922645504.0\n",
      "input:tensor([  3.9677,   2.5695,   2.9054,   2.4615, 682.0000])\n",
      "output:tensor([223318.5312])\n",
      "Batch Average Reconstruciton Loss:713021824.0\n",
      "input:tensor([  3.4347,   2.2430,   2.5050,   2.2260, 682.0000])\n",
      "output:tensor([223337.8750])\n",
      "Batch Average Reconstruciton Loss:4287908608.0\n",
      "input:tensor([  5.0630,   3.1325,   3.7573,   3.0935, 682.0000])\n",
      "output:tensor([223275.9375])\n",
      "Batch Average Reconstruciton Loss:747745600.0\n",
      "input:tensor([  4.3007,   2.9980,   3.0721,   2.9640, 682.0000])\n",
      "output:tensor([223296.0312])\n",
      "Batch Average Reconstruciton Loss:54257496.0\n",
      "input:tensor([  4.4927,   2.7815,   3.3309,   2.7745, 682.0000])\n",
      "output:tensor([223298.2969])\n",
      "Batch Average Reconstruciton Loss:6221517.0\n",
      "input:tensor([  4.1767,   2.4005,   3.0583,   2.2275, 682.0000])\n",
      "output:tensor([223322.3438])\n",
      "Batch Average Reconstruciton Loss:201289584.0\n",
      "input:tensor([  4.5230,   2.3360,   3.6849,   2.3190, 682.0000])\n",
      "output:tensor([223310.3438])\n",
      "Batch Average Reconstruciton Loss:15898910.0\n",
      "input:tensor([  3.6203,   2.5070,   2.5901,   2.4900, 682.0000])\n",
      "output:tensor([223325.5625])\n",
      "Batch Average Reconstruciton Loss:2568709376.0\n",
      "input:tensor([  5.7763,   3.6645,   4.2455,   3.5975, 682.0000])\n",
      "output:tensor([223244.8281])\n",
      "Batch Average Reconstruciton Loss:2653262336.0\n",
      "input:tensor([  4.2823,   2.6120,   3.2078,   2.5140, 682.0000])\n",
      "output:tensor([223310.1875])\n",
      "Batch Average Reconstruciton Loss:69535792.0\n",
      "input:tensor([ 13.0607,   3.1560,  14.3159,   3.0550, 682.0000])\n",
      "output:tensor([223078.5312])\n",
      "Batch Average Reconstruciton Loss:21645922304.0\n",
      "input:tensor([ 14.8440,  10.2315,   7.4444,  10.1705, 682.0000])\n",
      "output:tensor([222879.5312])\n",
      "Batch Average Reconstruciton Loss:24352079872.0\n",
      "input:tensor([  3.9943,   2.2755,   3.0849,   2.2485, 682.0000])\n",
      "output:tensor([223324.7969])\n",
      "Batch Average Reconstruciton Loss:626360896.0\n",
      "input:tensor([  5.9380,   5.3645,   4.4435,   5.3305, 682.0000])\n",
      "output:tensor([223179.4531])\n",
      "Batch Average Reconstruciton Loss:3149392896.0\n",
      "input:tensor([  3.6360,   2.0050,   2.8492,   1.9690, 682.0000])\n",
      "output:tensor([223341.0156])\n",
      "Batch Average Reconstruciton Loss:2448862720.0\n",
      "input:tensor([  3.9490,   2.4205,   2.9383,   2.4155, 682.0000])\n",
      "output:tensor([223321.1250])\n",
      "Batch Average Reconstruciton Loss:777398976.0\n",
      "input:tensor([  4.7483,   2.4505,   3.8328,   2.4335, 682.0000])\n",
      "output:tensor([223302.2656])\n",
      "Batch Average Reconstruciton Loss:206993408.0\n",
      "input:tensor([  4.4127,   3.1500,   3.1279,   3.1430, 682.0000])\n",
      "output:tensor([223288.1719])\n",
      "Batch Average Reconstruciton Loss:2306838.75\n",
      "input:tensor([  4.1793,   2.3885,   3.2690,   2.3105, 682.0000])\n",
      "output:tensor([223318.0938])\n",
      "Batch Average Reconstruciton Loss:197118960.0\n",
      "input:tensor([  3.5237,   2.4455,   1.5363,   2.3475, 682.0000])\n",
      "output:tensor([223342.1094])\n",
      "Batch Average Reconstruciton Loss:3385248768.0\n",
      "input:tensor([  4.0920,   2.6785,   2.9724,   2.6445, 682.0000])\n",
      "output:tensor([223310.7500])\n",
      "Batch Average Reconstruciton Loss:365316320.0\n",
      "input:tensor([  5.0107,   2.6580,   4.0075,   2.5810, 682.0000])\n",
      "output:tensor([223291.7188])\n",
      "Batch Average Reconstruciton Loss:640784384.0\n",
      "input:tensor([  3.9813,   2.7535,   2.8626,   2.6425, 682.0000])\n",
      "output:tensor([223312.3594])\n",
      "Batch Average Reconstruciton Loss:668255616.0\n",
      "input:tensor([  4.2070,   2.6850,   3.0961,   2.6670, 682.0000])\n",
      "output:tensor([223307.5625])\n",
      "Batch Average Reconstruciton Loss:155986048.0\n",
      "input:tensor([  4.3527,   2.6250,   3.2752,   2.5430, 682.0000])\n",
      "output:tensor([223307.8438])\n",
      "Batch Average Reconstruciton Loss:21143040.0\n",
      "input:tensor([ 33.0783,   6.0790,  38.5450,   6.0400, 682.0000])\n",
      "output:tensor([222500.1719])\n",
      "Batch Average Reconstruciton Loss:37060550656.0\n",
      "input:tensor([  4.1303,   1.8045,   3.6324,   1.7405, 682.0000])\n",
      "output:tensor([223335.2344])\n",
      "Batch Average Reconstruciton Loss:283544032.0\n",
      "input:tensor([  3.8113,   2.4965,   2.7796,   2.4365, 682.0000])\n",
      "output:tensor([223322.9375])\n",
      "Batch Average Reconstruciton Loss:1365528832.0\n",
      "input:tensor([  4.1803,   2.1535,   3.4040,   2.0715, 682.0000])\n",
      "output:tensor([223325.1406])\n",
      "Batch Average Reconstruciton Loss:195352592.0\n",
      "input:tensor([  4.1317,   2.0355,   3.4496,   2.0015, 682.0000])\n",
      "output:tensor([223328.1875])\n",
      "Batch Average Reconstruciton Loss:281193088.0\n",
      "input:tensor([  5.2353,   4.9175,   4.0141,   4.8995, 682.0000])\n",
      "output:tensor([223207.0625])\n",
      "Batch Average Reconstruciton Loss:1137379840.0\n",
      "input:tensor([  3.5687,   2.3655,   1.7530,   2.3485, 682.0000])\n",
      "output:tensor([223340.1250])\n",
      "Batch Average Reconstruciton Loss:2984969472.0\n",
      "input:tensor([  3.5443,   2.3365,   2.5733,   2.2705, 682.0000])\n",
      "output:tensor([223333.8750])\n",
      "Batch Average Reconstruciton Loss:3197803520.0\n",
      "input:tensor([  6.5373,   3.0625,   5.5547,   3.0235, 682.0000])\n",
      "output:tensor([223243.5000])\n",
      "Batch Average Reconstruciton Loss:5112178688.0\n",
      "input:tensor([  3.6013,   2.4570,   2.5878,   2.4400, 682.0000])\n",
      "output:tensor([223327.5625])\n",
      "Batch Average Reconstruciton Loss:2717165568.0\n",
      "input:tensor([  5.2133,   2.6930,   4.2105,   2.6750, 682.0000])\n",
      "output:tensor([223284.6250])\n",
      "Batch Average Reconstruciton Loss:1089239296.0\n",
      "input:tensor([  4.5880,   3.2690,   3.2618,   3.1890, 682.0000])\n",
      "output:tensor([223282.4375])\n",
      "Batch Average Reconstruciton Loss:49934540.0\n",
      "input:tensor([  4.0280,   2.1015,   3.2554,   2.0825, 682.0000])\n",
      "output:tensor([223328.6250])\n",
      "Batch Average Reconstruciton Loss:526582016.0\n",
      "input:tensor([  3.2263,   1.8830,   2.4662,   1.8490, 682.0000])\n",
      "output:tensor([223353.7812])\n",
      "Batch Average Reconstruciton Loss:7075538432.0\n",
      "input:tensor([  2.9207,   1.8780,   2.1358,   1.8170, 682.0000])\n",
      "output:tensor([223361.4375])\n",
      "Batch Average Reconstruciton Loss:13522565120.0\n",
      "input:tensor([  4.2223,   3.4815,   3.0074,   3.3775, 682.0000])\n",
      "output:tensor([223282.0625])\n",
      "Batch Average Reconstruciton Loss:135930816.0\n",
      "input:tensor([  4.2143,   2.8605,   3.0236,   2.8535, 682.0000])\n",
      "output:tensor([223301.7344])\n",
      "Batch Average Reconstruciton Loss:146053648.0\n",
      "input:tensor([  6.3673,   5.8430,   4.7990,   5.8090, 682.0000])\n",
      "output:tensor([223153.9844])\n",
      "Batch Average Reconstruciton Loss:4537232896.0\n",
      "input:tensor([  3.5127,   1.7685,   2.8987,   1.6925, 682.0000])\n",
      "output:tensor([223351.2500])\n",
      "Batch Average Reconstruciton Loss:3487581696.0\n",
      "input:tensor([  4.3880,   2.3950,   3.4837,   2.2900, 682.0000])\n",
      "output:tensor([223314.0469])\n",
      "Batch Average Reconstruciton Loss:7600790.5\n",
      "input:tensor([  3.7753,   2.3470,   2.7982,   2.3160, 682.0000])\n",
      "output:tensor([223327.7500])\n",
      "Batch Average Reconstruciton Loss:1554744576.0\n",
      "input:tensor([  4.4220,   2.2000,   3.6683,   2.1320, 682.0000])\n",
      "output:tensor([223317.7344])\n",
      "Batch Average Reconstruciton Loss:1030764.3125\n",
      "input:tensor([  4.5023,   3.5575,   3.1873,   3.5515, 682.0000])\n",
      "output:tensor([223272.])\n",
      "Batch Average Reconstruciton Loss:8655364.0\n",
      "input:tensor([  7.4563,   8.2075,   6.7174,   8.1045, 682.0000])\n",
      "output:tensor([223039.1562])\n",
      "Batch Average Reconstruciton Loss:8099667968.0\n",
      "input:tensor([  4.2307,   3.3515,   1.6644,   3.3325, 682.0000])\n",
      "output:tensor([223298.8906])\n",
      "Batch Average Reconstruciton Loss:124972488.0\n",
      "input:tensor([  4.0633,   2.1335,   3.2538,   2.1165, 682.0000])\n",
      "output:tensor([223327.0781])\n",
      "Batch Average Reconstruciton Loss:432969600.0\n",
      "input:tensor([ 18.9500,   2.5350,  23.3159,   2.4170, 682.0000])\n",
      "output:tensor([222942.0625])\n",
      "Batch Average Reconstruciton Loss:29102333952.0\n",
      "input:tensor([  3.2153,   1.8310,   2.5038,   1.7610, 682.0000])\n",
      "output:tensor([223356.2500])\n",
      "Batch Average Reconstruciton Loss:7253204992.0\n",
      "input:tensor([  3.9790,   3.0170,   2.8088,   2.9440, 682.0000])\n",
      "output:tensor([223302.6094])\n",
      "Batch Average Reconstruciton Loss:676332352.0\n",
      "input:tensor([  4.0817,   2.1465,   3.2646,   2.1405, 682.0000])\n",
      "output:tensor([223326.0312])\n",
      "Batch Average Reconstruciton Loss:388561728.0\n",
      "input:tensor([  4.2647,   2.9310,   2.0191,   2.9250, 682.0000])\n",
      "output:tensor([223309.4062])\n",
      "Batch Average Reconstruciton Loss:86482440.0\n",
      "input:tensor([  5.1960,   4.9670,   4.0378,   4.9280, 682.0000])\n",
      "output:tensor([223206.])\n",
      "Batch Average Reconstruciton Loss:1042644096.0\n",
      "input:tensor([  3.7333,   2.0965,   2.9109,   2.0355, 682.0000])\n",
      "output:tensor([223336.6875])\n",
      "Batch Average Reconstruciton Loss:1795836672.0\n",
      "input:tensor([  3.9270,   2.3875,   2.9290,   2.3675, 682.0000])\n",
      "output:tensor([223323.])\n",
      "Batch Average Reconstruciton Loss:857728384.0\n",
      "input:tensor([  8.9477,   3.4265,   8.3119,   3.3925, 682.0000])\n",
      "output:tensor([223175.2344])\n",
      "Batch Average Reconstruciton Loss:12613139456.0\n",
      "input:tensor([  4.1397,   2.3425,   3.2178,   2.2625, 682.0000])\n",
      "output:tensor([223320.7500])\n",
      "Batch Average Reconstruciton Loss:266089504.0\n",
      "input:tensor([  4.1283,   2.7505,   2.9864,   2.7145, 682.0000])\n",
      "output:tensor([223307.6875])\n",
      "Batch Average Reconstruciton Loss:288432896.0\n",
      "input:tensor([  4.9620,   3.9800,   3.5197,   3.9380, 682.0000])\n",
      "output:tensor([223249.3594])\n",
      "Batch Average Reconstruciton Loss:544305664.0\n",
      "input:tensor([  6.2513,   3.0910,   4.5459,   3.0840, 682.0000])\n",
      "output:tensor([223255.5469])\n",
      "Batch Average Reconstruciton Loss:4169226496.0\n",
      "input:tensor([  3.7743,   2.1895,   2.8667,   2.1835, 682.0000])\n",
      "output:tensor([223332.0156])\n",
      "Batch Average Reconstruciton Loss:1559932800.0\n",
      "input:tensor([  4.1757,   2.7730,   3.0257,   2.6990, 682.0000])\n",
      "output:tensor([223306.9062])\n",
      "Batch Average Reconstruciton Loss:203350272.0\n",
      "input:tensor([  3.7287,   2.0865,   2.9070,   2.0505, 682.0000])\n",
      "output:tensor([223336.5000])\n",
      "Batch Average Reconstruciton Loss:1824186752.0\n",
      "input:tensor([  3.4890,   1.6910,   2.9184,   1.6490, 682.0000])\n",
      "output:tensor([223353.2031])\n",
      "Batch Average Reconstruciton Loss:3717194240.0\n",
      "input:tensor([  4.5123,   3.3475,   3.1956,   3.2275, 682.0000])\n",
      "output:tensor([223282.1719])\n",
      "Batch Average Reconstruciton Loss:11834783.0\n",
      "input:tensor([  4.5627,   2.8600,   3.3718,   2.7560, 682.0000])\n",
      "output:tensor([223296.7344])\n",
      "Batch Average Reconstruciton Loss:34571276.0\n",
      "input:tensor([  3.2427,   1.9675,   2.4744,   1.7715, 682.0000])\n",
      "output:tensor([223354.5781])\n",
      "Batch Average Reconstruciton Loss:6817213952.0\n",
      "input:tensor([  4.1667,   1.8230,   3.6747,   1.7630, 682.0000])\n",
      "output:tensor([223333.6406])\n",
      "Batch Average Reconstruciton Loss:217455120.0\n",
      "input:tensor([  4.7243,   3.1110,   3.4271,   3.0720, 682.0000])\n",
      "output:tensor([223283.8438])\n",
      "Batch Average Reconstruciton Loss:177072096.0\n",
      "input:tensor([  4.5590,   2.4625,   3.4370,   2.3775, 682.0000])\n",
      "output:tensor([223309.8125])\n",
      "Batch Average Reconstruciton Loss:32693380.0\n",
      "input:tensor([  3.5217,   2.6910,   2.4861,   2.5540, 682.0000])\n",
      "output:tensor([223324.1875])\n",
      "Batch Average Reconstruciton Loss:3405984512.0\n",
      "input:tensor([  4.5727,   1.9125,   4.1024,   1.8705, 682.0000])\n",
      "output:tensor([223321.0938])\n",
      "Batch Average Reconstruciton Loss:40705596.0\n",
      "input:tensor([  3.6833,   2.1245,   2.8508,   2.0905, 682.0000])\n",
      "output:tensor([223336.1719])\n",
      "Batch Average Reconstruciton Loss:2114604416.0\n",
      "input:tensor([  3.1663,   1.8175,   2.4498,   1.7975, 682.0000])\n",
      "output:tensor([223356.5938])\n",
      "Batch Average Reconstruciton Loss:8089096704.0\n",
      "input:tensor([  4.3367,   2.5585,   3.2843,   2.5535, 682.0000])\n",
      "output:tensor([223308.3750])\n",
      "Batch Average Reconstruciton Loss:29578642.0\n",
      "input:tensor([  6.2720,   5.3355,   4.5258,   5.2915, 682.0000])\n",
      "output:tensor([223176.3281])\n",
      "Batch Average Reconstruciton Loss:4226732800.0\n",
      "input:tensor([  4.1323,   3.0690,   2.9194,   3.0510, 682.0000])\n",
      "output:tensor([223296.5469])\n",
      "Batch Average Reconstruciton Loss:280946304.0\n",
      "input:tensor([  4.6297,   2.6465,   3.5945,   2.5185, 682.0000])\n",
      "output:tensor([223301.8438])\n",
      "Batch Average Reconstruciton Loss:81574200.0\n",
      "input:tensor([  3.4627,   2.3530,   2.4978,   2.2730, 682.0000])\n",
      "output:tensor([223335.2969])\n",
      "Batch Average Reconstruciton Loss:3987758592.0\n",
      "input:tensor([  4.7803,   2.6945,   3.7067,   2.6875, 682.0000])\n",
      "output:tensor([223294.3125])\n",
      "Batch Average Reconstruciton Loss:248923584.0\n",
      "input:tensor([  4.5417,   2.3990,   3.6525,   2.3650, 682.0000])\n",
      "output:tensor([223308.6719])\n",
      "Batch Average Reconstruciton Loss:23879562.0\n",
      "input:tensor([  3.9497,   2.3280,   2.9930,   2.2830, 682.0000])\n",
      "output:tensor([223324.8438])\n",
      "Batch Average Reconstruciton Loss:774795904.0\n",
      "input:tensor([  3.9497,   2.4640,   2.9468,   2.3590, 682.0000])\n",
      "output:tensor([223321.9531])\n",
      "Batch Average Reconstruciton Loss:774956864.0\n",
      "input:tensor([  3.7647,   2.3325,   2.7998,   2.2935, 682.0000])\n",
      "output:tensor([223328.5625])\n",
      "Batch Average Reconstruciton Loss:1613985408.0\n",
      "input:tensor([  3.8310,   2.7555,   2.7192,   2.6825, 682.0000])\n",
      "output:tensor([223314.4688])\n",
      "Batch Average Reconstruciton Loss:1269178496.0\n",
      "input:tensor([  4.3020,   2.8920,   3.1043,   2.8580, 682.0000])\n",
      "output:tensor([223299.4688])\n",
      "Batch Average Reconstruciton Loss:53151844.0\n",
      "input:tensor([  4.1203,   2.7040,   2.9950,   2.6860, 682.0000])\n",
      "output:tensor([223308.8906])\n",
      "Batch Average Reconstruciton Loss:304436512.0\n",
      "input:tensor([  3.3733,   2.0390,   2.5357,   2.0020, 682.0000])\n",
      "output:tensor([223346.])\n",
      "Batch Average Reconstruciton Loss:5002025472.0\n",
      "input:tensor([  3.6880,   2.1540,   2.6430,   2.0820, 682.0000])\n",
      "output:tensor([223338.2656])\n",
      "Batch Average Reconstruciton Loss:2083167872.0\n",
      "input:tensor([  3.9507,   1.9360,   3.3013,   1.8590, 682.0000])\n",
      "output:tensor([223336.3125])\n",
      "Batch Average Reconstruciton Loss:770655744.0\n",
      "input:tensor([  3.9410,   2.5125,   2.8930,   2.4775, 682.0000])\n",
      "output:tensor([223319.1562])\n",
      "Batch Average Reconstruciton Loss:806210368.0\n",
      "input:tensor([  4.2900,   3.2155,   3.0313,   3.1485, 682.0000])\n",
      "output:tensor([223289.6875])\n",
      "Batch Average Reconstruciton Loss:63127992.0\n",
      "input:tensor([  4.1270,   2.1345,   3.3247,   2.1005, 682.0000])\n",
      "output:tensor([223326.0312])\n",
      "Batch Average Reconstruciton Loss:290428704.0\n",
      "input:tensor([  4.5210,   2.8955,   3.3128,   2.8565, 682.0000])\n",
      "output:tensor([223294.9375])\n",
      "Batch Average Reconstruciton Loss:15015141.0\n",
      "input:tensor([  4.4567,   2.7085,   3.3257,   2.7005, 682.0000])\n",
      "output:tensor([223301.3750])\n",
      "Batch Average Reconstruciton Loss:508903.875\n",
      "input:tensor([  3.4780,   1.8155,   2.8079,   1.7985, 682.0000])\n",
      "output:tensor([223349.4219])\n",
      "Batch Average Reconstruciton Loss:3828092160.0\n",
      "input:tensor([  3.7470,   2.1515,   2.8780,   2.1095, 682.0000])\n",
      "output:tensor([223334.4531])\n",
      "Batch Average Reconstruciton Loss:1714833408.0\n",
      "input:tensor([  4.3250,   3.0415,   3.0820,   3.0055, 682.0000])\n",
      "output:tensor([223294.1875])\n",
      "Batch Average Reconstruciton Loss:36842624.0\n",
      "input:tensor([  4.9633,   2.7825,   3.8709,   2.7045, 682.0000])\n",
      "output:tensor([223289.2344])\n",
      "Batch Average Reconstruciton Loss:548647936.0\n",
      "input:tensor([  7.4923,   3.4965,   6.3651,   3.4615, 682.0000])\n",
      "output:tensor([223209.0625])\n",
      "Batch Average Reconstruciton Loss:8245922816.0\n",
      "input:tensor([  3.8787,   2.5240,   2.8268,   2.4900, 682.0000])\n",
      "output:tensor([223320.1094])\n",
      "Batch Average Reconstruciton Loss:1052216768.0\n",
      "input:tensor([  3.5943,   2.4565,   2.5802,   2.4155, 682.0000])\n",
      "output:tensor([223328.3438])\n",
      "Batch Average Reconstruciton Loss:2773250048.0\n",
      "input:tensor([  4.0100,   2.0650,   3.2563,   2.0260, 682.0000])\n",
      "output:tensor([223330.6094])\n",
      "Batch Average Reconstruciton Loss:578469376.0\n",
      "input:tensor([  3.7217,   2.3655,   2.7265,   2.3245, 682.0000])\n",
      "output:tensor([223328.6719])\n",
      "Batch Average Reconstruciton Loss:1867823872.0\n",
      "input:tensor([  3.9757,   2.5465,   2.9150,   2.4505, 682.0000])\n",
      "output:tensor([223318.8594])\n",
      "Batch Average Reconstruciton Loss:686394944.0\n",
      "input:tensor([  3.5953,   2.5455,   2.3581,   2.4215, 682.0000])\n",
      "output:tensor([223329.6094])\n",
      "Batch Average Reconstruciton Loss:2765012992.0\n",
      "input:tensor([  5.8647,   2.7725,   4.9588,   2.7115, 682.0000])\n",
      "output:tensor([223267.9531])\n",
      "Batch Average Reconstruciton Loss:2928861184.0\n",
      "input:tensor([  5.4073,   2.1750,   4.9404,   2.1330, 682.0000])\n",
      "output:tensor([223293.8594])\n",
      "Batch Average Reconstruciton Loss:1587134720.0\n",
      "input:tensor([  4.7533,   4.1645,   3.4807,   4.1295, 682.0000])\n",
      "output:tensor([223245.2500])\n",
      "Batch Average Reconstruciton Loss:211680672.0\n",
      "input:tensor([  4.1630,   2.3880,   3.2431,   2.2010, 682.0000])\n",
      "output:tensor([223321.3125])\n",
      "Batch Average Reconstruciton Loss:224061600.0\n",
      "input:tensor([  4.0220,   2.5660,   2.9566,   2.4990, 682.0000])\n",
      "output:tensor([223316.5312])\n",
      "Batch Average Reconstruciton Loss:544124160.0\n",
      "input:tensor([  3.7563,   2.2055,   2.8804,   2.1005, 682.0000])\n",
      "output:tensor([223333.9531])\n",
      "Batch Average Reconstruciton Loss:1660810880.0\n",
      "input:tensor([ 31.6753,  24.5645,  22.4283,  24.5305, 682.0000])\n",
      "output:tensor([222027.5781])\n",
      "Batch Average Reconstruciton Loss:36370141184.0\n",
      "input:tensor([  3.1913,   1.8500,   2.4466,   1.7910, 682.0000])\n",
      "output:tensor([223356.1719])\n",
      "Batch Average Reconstruciton Loss:7653770240.0\n",
      "input:tensor([  3.8297,   1.8350,   3.2318,   1.8170, 682.0000])\n",
      "output:tensor([223340.4844])\n",
      "Batch Average Reconstruciton Loss:1273741568.0\n",
      "input:tensor([  3.7777,   2.2300,   2.8858,   2.1220, 682.0000])\n",
      "output:tensor([223332.9062])\n",
      "Batch Average Reconstruciton Loss:1541590528.0\n",
      "input:tensor([  5.5863,   1.8990,   5.4896,   1.8290, 682.0000])\n",
      "output:tensor([223296.6406])\n",
      "Batch Average Reconstruciton Loss:2090376960.0\n",
      "input:tensor([  3.7480,   1.7205,   3.2491,   1.6415, 682.0000])\n",
      "output:tensor([223346.7656])\n",
      "Batch Average Reconstruciton Loss:1708022912.0\n",
      "input:tensor([  7.0490,   3.8125,   5.6078,   3.7345, 682.0000])\n",
      "output:tensor([223211.7031])\n",
      "Batch Average Reconstruciton Loss:6803396096.0\n",
      "input:tensor([  3.2347,   2.4495,   2.2832,   2.4095, 682.0000])\n",
      "output:tensor([223335.5781])\n",
      "Batch Average Reconstruciton Loss:6945959424.0\n",
      "input:tensor([  5.2873,   4.4795,   3.8150,   4.4515, 682.0000])\n",
      "output:tensor([223224.5469])\n",
      "Batch Average Reconstruciton Loss:1267826176.0\n",
      "input:tensor([  3.6780,   2.5690,   2.6239,   2.5340, 682.0000])\n",
      "output:tensor([223322.8281])\n",
      "Batch Average Reconstruciton Loss:2151955200.0\n",
      "input:tensor([  4.9260,   2.5035,   4.0147,   2.4675, 682.0000])\n",
      "output:tensor([223297.])\n",
      "Batch Average Reconstruciton Loss:480354880.0\n",
      "input:tensor([  4.1913,   2.7710,   3.0403,   2.7070, 682.0000])\n",
      "output:tensor([223306.4062])\n",
      "Batch Average Reconstruciton Loss:178826256.0\n",
      "input:tensor([  3.6787,   2.5955,   2.6230,   2.5245, 682.0000])\n",
      "output:tensor([223322.7812])\n",
      "Batch Average Reconstruciton Loss:2147415936.0\n",
      "input:tensor([ 36.2040,   2.1080,  48.2772,   2.0730, 682.0000])\n",
      "output:tensor([222504.3594])\n",
      "Batch Average Reconstruciton Loss:38065709056.0\n",
      "input:tensor([  3.6060,   2.4565,   2.5951,   2.3885, 682.0000])\n",
      "output:tensor([223328.7344])\n",
      "Batch Average Reconstruciton Loss:2679953408.0\n",
      "input:tensor([  4.5463,   3.1390,   3.0995,   3.0330, 682.0000])\n",
      "output:tensor([223289.9375])\n",
      "Batch Average Reconstruciton Loss:25927828.0\n",
      "input:tensor([  3.7600,   2.1135,   2.9122,   2.0775, 682.0000])\n",
      "output:tensor([223335.1562])\n",
      "Batch Average Reconstruciton Loss:1639832320.0\n",
      "input:tensor([  4.1503,   2.7560,   2.9965,   2.6800, 682.0000])\n",
      "output:tensor([223308.1562])\n",
      "Batch Average Reconstruciton Loss:246767776.0\n",
      "input:tensor([  3.0373,   2.0660,   2.1845,   2.0310, 682.0000])\n",
      "output:tensor([223352.2812])\n",
      "Batch Average Reconstruciton Loss:10660504576.0\n",
      "input:tensor([  3.4707,   1.7165,   2.8897,   1.6785, 682.0000])\n",
      "output:tensor([223352.7188])\n",
      "Batch Average Reconstruciton Loss:3902660864.0\n",
      "input:tensor([  3.4263,   2.1710,   2.5242,   2.1360, 682.0000])\n",
      "output:tensor([223340.7656])\n",
      "Batch Average Reconstruciton Loss:4379955712.0\n",
      "input:tensor([  3.1593,   1.7710,   2.4712,   1.6890, 682.0000])\n",
      "output:tensor([223359.6250])\n",
      "Batch Average Reconstruciton Loss:8213864960.0\n",
      "input:tensor([  4.0633,   3.1535,   2.8696,   3.1225, 682.0000])\n",
      "output:tensor([223295.1250])\n",
      "Batch Average Reconstruciton Loss:434300384.0\n",
      "input:tensor([  3.7920,   1.7880,   3.2334,   1.7480, 682.0000])\n",
      "output:tensor([223343.0938])\n",
      "Batch Average Reconstruciton Loss:1463820416.0\n",
      "input:tensor([  8.9897,   1.7445,  10.4030,   1.6755, 682.0000])\n",
      "output:tensor([223213.2969])\n",
      "Batch Average Reconstruciton Loss:12738349056.0\n",
      "input:tensor([  3.6120,   2.3950,   2.6136,   2.3540, 682.0000])\n",
      "output:tensor([223330.])\n",
      "Batch Average Reconstruciton Loss:2632716032.0\n",
      "input:tensor([  3.9323,   1.9830,   3.2527,   1.9660, 682.0000])\n",
      "output:tensor([223333.8594])\n",
      "Batch Average Reconstruciton Loss:837184512.0\n",
      "input:tensor([  5.2707,   3.9725,   3.7229,   3.9305, 682.0000])\n",
      "output:tensor([223244.1875])\n",
      "Batch Average Reconstruciton Loss:1227324288.0\n",
      "input:tensor([  3.2747,   1.9990,   2.4470,   1.9550, 682.0000])\n",
      "output:tensor([223349.5625])\n",
      "Batch Average Reconstruciton Loss:6333364224.0\n",
      "input:tensor([  3.9727,   2.5060,   2.9368,   2.4890, 682.0000])\n",
      "output:tensor([223318.1250])\n",
      "Batch Average Reconstruciton Loss:696319936.0\n",
      "input:tensor([ 77.8428,  73.0117, 130.2111,  99.3474, 802.0000])\n",
      "output:tensor([257311.5469])\n",
      "Batch Average Reconstruciton Loss:60456259584.0\n",
      "input:tensor([  4.0983,   2.6890,   2.9740,   2.6550, 682.0000])\n",
      "output:tensor([223310.2812])\n",
      "Batch Average Reconstruciton Loss:351177056.0\n",
      "input:tensor([  4.0453,   3.1230,   2.8580,   3.1170, 682.0000])\n",
      "output:tensor([223295.9062])\n",
      "Batch Average Reconstruciton Loss:480709728.0\n",
      "input:tensor([  3.8137,   1.7930,   3.2575,   1.7580, 682.0000])\n",
      "output:tensor([223342.2969])\n",
      "Batch Average Reconstruciton Loss:1352378752.0\n",
      "input:tensor([  5.0140,   3.3915,   3.6010,   3.3475, 682.0000])\n",
      "output:tensor([223269.])\n",
      "Batch Average Reconstruciton Loss:646328960.0\n",
      "input:tensor([  8.8150,   5.4525,   6.5612,   5.3735, 682.0000])\n",
      "output:tensor([223124.1562])\n",
      "Batch Average Reconstruciton Loss:12229961728.0\n",
      "input:tensor([  4.1390,   2.7945,   2.9778,   2.7535, 682.0000])\n",
      "output:tensor([223306.2344])\n",
      "Batch Average Reconstruciton Loss:267805552.0\n",
      "input:tensor([  3.8980,   2.4495,   2.8890,   2.3815, 682.0000])\n",
      "output:tensor([223322.7500])\n",
      "Batch Average Reconstruciton Loss:971335168.0\n",
      "input:tensor([ 11.0783,   2.1690,  12.6453,   2.1270, 682.0000])\n",
      "output:tensor([223151.2344])\n",
      "Batch Average Reconstruciton Loss:17850892288.0\n",
      "input:tensor([  3.8850,   2.7750,   2.7591,   2.7410, 682.0000])\n",
      "output:tensor([223311.7812])\n",
      "Batch Average Reconstruciton Loss:1025870848.0\n",
      "input:tensor([  4.5457,   3.8290,   3.2620,   3.7940, 682.0000])\n",
      "output:tensor([223261.7812])\n",
      "Batch Average Reconstruciton Loss:25318822.0\n",
      "input:tensor([ 26.9313,   2.4010,  34.7988,   2.3660, 682.0000])\n",
      "output:tensor([222736.9062])\n",
      "Batch Average Reconstruciton Loss:34559889408.0\n",
      "input:tensor([  8.7180,   3.5175,   7.9620,   3.4825, 682.0000])\n",
      "output:tensor([223178.1719])\n",
      "Batch Average Reconstruciton Loss:11966210048.0\n",
      "input:tensor([  4.0477,   2.0370,   3.3048,   1.9960, 682.0000])\n",
      "output:tensor([223330.7500])\n",
      "Batch Average Reconstruciton Loss:472986368.0\n",
      "input:tensor([  3.8280,   2.1860,   2.9289,   2.1460, 682.0000])\n",
      "output:tensor([223331.7500])\n",
      "Batch Average Reconstruciton Loss:1282445568.0\n",
      "input:tensor([  3.2690,   1.8835,   2.4919,   1.8495, 682.0000])\n",
      "output:tensor([223353.0312])\n",
      "Batch Average Reconstruciton Loss:6416645632.0\n",
      "input:tensor([ 73.2418,  83.5570, 111.5530, 101.9108, 802.0000])\n",
      "output:tensor([257384.2812])\n",
      "Batch Average Reconstruciton Loss:60138872832.0\n",
      "input:tensor([  4.0700,   2.6315,   2.9731,   2.5945, 682.0000])\n",
      "output:tensor([223312.7188])\n",
      "Batch Average Reconstruciton Loss:417069568.0\n",
      "input:tensor([  4.2467,   2.4575,   3.2664,   2.3755, 682.0000])\n",
      "output:tensor([223315.0781])\n",
      "Batch Average Reconstruciton Loss:105676792.0\n",
      "input:tensor([  3.6167,   1.9440,   2.8888,   1.8690, 682.0000])\n",
      "output:tensor([223343.9531])\n",
      "Batch Average Reconstruciton Loss:2595092224.0\n",
      "input:tensor([  4.0850,   2.6590,   2.9721,   2.6250, 682.0000])\n",
      "output:tensor([223311.5156])\n",
      "Batch Average Reconstruciton Loss:381361696.0\n",
      "input:tensor([  4.0597,   2.6585,   2.9648,   2.5505, 682.0000])\n",
      "output:tensor([223313.7344])\n",
      "Batch Average Reconstruciton Loss:442734848.0\n",
      "input:tensor([  3.9547,   2.4750,   2.9265,   2.4710, 682.0000])\n",
      "output:tensor([223319.1875])\n",
      "Batch Average Reconstruciton Loss:757560256.0\n",
      "input:tensor([  4.0647,   3.1205,   2.8710,   3.0525, 682.0000])\n",
      "output:tensor([223297.1875])\n",
      "Batch Average Reconstruciton Loss:430845280.0\n",
      "input:tensor([  3.1600,   1.7835,   2.4779,   1.7205, 682.0000])\n",
      "output:tensor([223358.6250])\n",
      "Batch Average Reconstruciton Loss:8202086912.0\n",
      "input:tensor([  3.8887,   2.8300,   2.7522,   2.7920, 682.0000])\n",
      "output:tensor([223309.9688])\n",
      "Batch Average Reconstruciton Loss:1010606080.0\n",
      "input:tensor([  6.0850,   3.3620,   4.7399,   3.3260, 682.0000])\n",
      "output:tensor([223246.2656])\n",
      "Batch Average Reconstruciton Loss:3626721280.0\n",
      "input:tensor([  3.1730,   1.7800,   2.4734,   1.7460, 682.0000])\n",
      "output:tensor([223357.9375])\n",
      "Batch Average Reconstruciton Loss:7970929664.0\n",
      "input:tensor([ 22.6293,  17.4755,  16.0124,  17.3575, 682.0000])\n",
      "output:tensor([222447.7500])\n",
      "Batch Average Reconstruciton Loss:31901800448.0\n",
      "input:tensor([  3.4787,   2.2130,   2.5610,   2.1470, 682.0000])\n",
      "output:tensor([223339.1250])\n",
      "Batch Average Reconstruciton Loss:3822686208.0\n",
      "input:tensor([  3.5787,   2.4750,   2.5743,   2.2970, 682.0000])\n",
      "output:tensor([223331.3594])\n",
      "Batch Average Reconstruciton Loss:2901614848.0\n",
      "input:tensor([  4.8203,   2.6330,   3.7945,   2.5920, 682.0000])\n",
      "output:tensor([223296.])\n",
      "Batch Average Reconstruciton Loss:306284992.0\n",
      "input:tensor([  3.4410,   2.2275,   2.3347,   2.0755, 682.0000])\n",
      "output:tensor([223343.5625])\n",
      "Batch Average Reconstruciton Loss:4217779968.0\n",
      "input:tensor([  4.1843,   3.3100,   1.6557,   3.2510, 682.0000])\n",
      "output:tensor([223301.9531])\n",
      "Batch Average Reconstruciton Loss:189696816.0\n",
      "input:tensor([  2.8430,   1.8530,   2.0682,   1.8470, 682.0000])\n",
      "output:tensor([223362.4844])\n",
      "Batch Average Reconstruciton Loss:15766447104.0\n",
      "input:tensor([  4.9763,   3.3760,   3.5890,   3.2810, 682.0000])\n",
      "output:tensor([223271.3750])\n",
      "Batch Average Reconstruciton Loss:572519296.0\n",
      "input:tensor([  4.4283,   3.9785,   3.3069,   3.9735, 682.0000])\n",
      "output:tensor([223256.4531])\n",
      "Batch Average Reconstruciton Loss:570851.0625\n",
      "input:tensor([  3.6677,   2.5805,   2.6155,   2.5075, 682.0000])\n",
      "output:tensor([223323.5625])\n",
      "Batch Average Reconstruciton Loss:2222975232.0\n",
      "input:tensor([  3.2430,   1.9145,   2.4570,   1.8705, 682.0000])\n",
      "output:tensor([223352.8281])\n",
      "Batch Average Reconstruciton Loss:6812384768.0\n",
      "input:tensor([  3.8803,   1.7350,   3.3801,   1.7000, 682.0000])\n",
      "output:tensor([223342.3438])\n",
      "Batch Average Reconstruciton Loss:1043655424.0\n",
      "input:tensor([  3.5677,   2.3725,   2.5757,   2.3315, 682.0000])\n",
      "output:tensor([223331.6719])\n",
      "Batch Average Reconstruciton Loss:2994423808.0\n",
      "input:tensor([  4.2707,   2.4725,   3.2693,   2.4305, 682.0000])\n",
      "output:tensor([223313.2500])\n",
      "Batch Average Reconstruciton Loss:80438480.0\n",
      "input:tensor([  4.9810,   1.9900,   4.5714,   1.9550, 682.0000])\n",
      "output:tensor([223308.7812])\n",
      "Batch Average Reconstruciton Loss:583308544.0\n",
      "input:tensor([  4.7413,   2.4440,   3.8519,   2.4260, 682.0000])\n",
      "output:tensor([223302.3906])\n",
      "Batch Average Reconstruciton Loss:198201088.0\n",
      "input:tensor([  4.0930,   3.1145,   2.8910,   3.1095, 682.0000])\n",
      "output:tensor([223295.3125])\n",
      "Batch Average Reconstruciton Loss:363652992.0\n",
      "input:tensor([  3.9767,   2.4970,   2.9283,   2.4300, 682.0000])\n",
      "output:tensor([223319.7500])\n",
      "Batch Average Reconstruciton Loss:683051264.0\n",
      "input:tensor([  5.1660,   3.7190,   3.6615,   3.6440, 682.0000])\n",
      "output:tensor([223255.8125])\n",
      "Batch Average Reconstruciton Loss:975363648.0\n",
      "input:tensor([  3.7083,   2.7160,   2.6408,   2.5170, 682.0000])\n",
      "output:tensor([223321.1875])\n",
      "Batch Average Reconstruciton Loss:1952297600.0\n",
      "input:tensor([  9.1030,   2.1475,   9.8809,   2.0835, 682.0000])\n",
      "output:tensor([223203.1719])\n",
      "Batch Average Reconstruciton Loss:13048075264.0\n",
      "input:tensor([  3.6883,   2.5550,   2.6348,   2.5120, 682.0000])\n",
      "output:tensor([223323.3125])\n",
      "Batch Average Reconstruciton Loss:2082342144.0\n",
      "input:tensor([  3.6370,   2.4985,   2.6026,   2.4235, 682.0000])\n",
      "output:tensor([223327.])\n",
      "Batch Average Reconstruciton Loss:2442830592.0\n",
      "input:tensor([ 24.3163,   1.7570,  32.0149,   1.7220, 682.0000])\n",
      "output:tensor([222817.5312])\n",
      "Batch Average Reconstruciton Loss:33131837440.0\n",
      "input:tensor([  3.7577,   2.6675,   2.6713,   2.6325, 682.0000])\n",
      "output:tensor([223317.9531])\n",
      "Batch Average Reconstruciton Loss:1654540800.0\n",
      "input:tensor([  3.1857,   1.8345,   2.4549,   1.7935, 682.0000])\n",
      "output:tensor([223356.2344])\n",
      "Batch Average Reconstruciton Loss:7750824448.0\n",
      "input:tensor([  3.9490,   2.4645,   2.9347,   2.3975, 682.0000])\n",
      "output:tensor([223321.1250])\n",
      "Batch Average Reconstruciton Loss:777398976.0\n",
      "input:tensor([  3.9537,   2.9935,   2.7915,   2.9585, 682.0000])\n",
      "output:tensor([223302.9375])\n",
      "Batch Average Reconstruciton Loss:761929088.0\n",
      "input:tensor([  3.6717,   2.2075,   2.7512,   2.1905, 682.0000])\n",
      "output:tensor([223333.9844])\n",
      "Batch Average Reconstruciton Loss:2194268160.0\n",
      "input:tensor([  4.8793,   3.3030,   2.4622,   3.2690, 682.0000])\n",
      "output:tensor([223285.5469])\n",
      "Batch Average Reconstruciton Loss:399182304.0\n",
      "input:tensor([  4.2450,   3.3755,   3.0120,   3.3385, 682.0000])\n",
      "output:tensor([223283.8906])\n",
      "Batch Average Reconstruciton Loss:108224688.0\n",
      "input:tensor([  3.1347,   1.7225,   2.4884,   1.6845, 682.0000])\n",
      "output:tensor([223360.3438])\n",
      "Batch Average Reconstruciton Loss:8667731968.0\n",
      "input:tensor([  6.4840,   2.6610,   5.8647,   2.6280, 682.0000])\n",
      "output:tensor([223254.9219])\n",
      "Batch Average Reconstruciton Loss:4936878080.0\n",
      "input:tensor([  4.2147,   3.3810,   2.9897,   3.3110, 682.0000])\n",
      "output:tensor([223285.0781])\n",
      "Batch Average Reconstruciton Loss:146021168.0\n",
      "input:tensor([  4.1493,   2.7575,   2.9985,   2.7125, 682.0000])\n",
      "output:tensor([223307.3125])\n",
      "Batch Average Reconstruciton Loss:248619968.0\n",
      "input:tensor([  5.4403,   2.2880,   4.8685,   2.2130, 682.0000])\n",
      "output:tensor([223291.0625])\n",
      "Batch Average Reconstruciton Loss:1676825728.0\n",
      "input:tensor([  3.2243,   1.8000,   2.5277,   1.7340, 682.0000])\n",
      "output:tensor([223356.9062])\n",
      "Batch Average Reconstruciton Loss:7107180032.0\n",
      "input:tensor([  3.4830,   1.8260,   2.7964,   1.8210, 682.0000])\n",
      "output:tensor([223348.8125])\n",
      "Batch Average Reconstruciton Loss:3777723392.0\n",
      "input:tensor([  3.9723,   2.7020,   2.8519,   2.6670, 682.0000])\n",
      "output:tensor([223312.4844])\n",
      "Batch Average Reconstruciton Loss:697726656.0\n",
      "input:tensor([  3.9837,   2.4090,   2.9964,   2.3370, 682.0000])\n",
      "output:tensor([223322.2188])\n",
      "Batch Average Reconstruciton Loss:660221760.0\n",
      "input:tensor([  3.4070,   2.1625,   2.5090,   2.1275, 682.0000])\n",
      "output:tensor([223341.4375])\n",
      "Batch Average Reconstruciton Loss:4600035840.0\n",
      "input:tensor([  4.3517,   2.0895,   3.6674,   2.0735, 682.0000])\n",
      "output:tensor([223321.1250])\n",
      "Batch Average Reconstruciton Loss:21509884.0\n",
      "input:tensor([  4.2910,   3.0440,   2.0007,   2.8480, 682.0000])\n",
      "output:tensor([223310.0625])\n",
      "Batch Average Reconstruciton Loss:61967400.0\n",
      "input:tensor([  4.9797,   4.5780,   3.7495,   4.5050, 682.0000])\n",
      "output:tensor([223226.1406])\n",
      "Batch Average Reconstruciton Loss:576775040.0\n",
      "input:tensor([  4.7987,   2.3525,   4.0116,   2.3095, 682.0000])\n",
      "output:tensor([223303.9844])\n",
      "Batch Average Reconstruciton Loss:274895872.0\n",
      "input:tensor([  3.9140,   2.3820,   2.9363,   2.3040, 682.0000])\n",
      "output:tensor([223324.7188])\n",
      "Batch Average Reconstruciton Loss:907472320.0\n",
      "input:tensor([  3.6043,   2.4505,   2.5869,   2.4465, 682.0000])\n",
      "output:tensor([223327.4688])\n",
      "Batch Average Reconstruciton Loss:2693250048.0\n",
      "input:tensor([  4.5233,   2.9585,   2.3397,   2.8505, 682.0000])\n",
      "output:tensor([223304.8125])\n",
      "Batch Average Reconstruciton Loss:15982505.0\n",
      "input:tensor([  4.3700,   2.8130,   3.2046,   2.7530, 682.0000])\n",
      "output:tensor([223301.1562])\n",
      "Batch Average Reconstruciton Loss:13696244.0\n",
      "input:tensor([  3.8590,   1.8980,   3.2025,   1.8530, 682.0000])\n",
      "output:tensor([223338.9062])\n",
      "Batch Average Reconstruciton Loss:1137179648.0\n",
      "input:tensor([  3.2987,   1.9970,   2.4827,   1.9270, 682.0000])\n",
      "output:tensor([223349.6719])\n",
      "Batch Average Reconstruciton Loss:5987405824.0\n",
      "input:tensor([  3.7153,   2.1925,   2.8289,   2.1155, 682.0000])\n",
      "output:tensor([223334.7188])\n",
      "Batch Average Reconstruciton Loss:1906831488.0\n",
      "input:tensor([  3.6787,   2.0660,   2.8594,   2.0320, 682.0000])\n",
      "output:tensor([223338.2188])\n",
      "Batch Average Reconstruciton Loss:2145985408.0\n",
      "input:tensor([  4.2613,   2.9070,   2.0045,   2.8900, 682.0000])\n",
      "output:tensor([223310.7500])\n",
      "Batch Average Reconstruciton Loss:89875144.0\n",
      "input:tensor([  4.2510,   1.9775,   3.6732,   1.8735, 682.0000])\n",
      "output:tensor([223328.3281])\n",
      "Batch Average Reconstruciton Loss:100574256.0\n",
      "input:tensor([  6.0537,   5.6470,   4.6085,   5.6120, 682.0000])\n",
      "output:tensor([223166.3906])\n",
      "Batch Average Reconstruciton Loss:3516299008.0\n",
      "input:tensor([  3.8313,   1.8220,   3.2800,   1.7190, 682.0000])\n",
      "output:tensor([223342.5312])\n",
      "Batch Average Reconstruciton Loss:1265613952.0\n",
      "input:tensor([  3.6480,   2.5120,   2.6116,   2.4710, 682.0000])\n",
      "output:tensor([223325.4375])\n",
      "Batch Average Reconstruciton Loss:2362403584.0\n",
      "input:tensor([  4.4427,   1.8130,   4.0653,   1.7720, 682.0000])\n",
      "output:tensor([223326.3906])\n",
      "Batch Average Reconstruciton Loss:1398.058837890625\n",
      "input:tensor([  3.8290,   2.2915,   2.8900,   2.2505, 682.0000])\n",
      "output:tensor([223328.4219])\n",
      "Batch Average Reconstruciton Loss:1277817856.0\n",
      "input:tensor([  4.4090,   3.2010,   3.1258,   3.1580, 682.0000])\n",
      "output:tensor([223287.2969])\n",
      "Batch Average Reconstruciton Loss:2912835.5\n",
      "input:tensor([  4.5963,   1.7815,   4.2967,   1.7185, 682.0000])\n",
      "output:tensor([223323.9375])\n",
      "Batch Average Reconstruciton Loss:56249064.0\n",
      "input:tensor([ 15.7853,   4.2155,  16.6462,   4.1185, 682.0000])\n",
      "output:tensor([222986.6250])\n",
      "Batch Average Reconstruciton Loss:25645979648.0\n",
      "input:tensor([  4.1703,   2.8050,   3.0030,   2.7700, 682.0000])\n",
      "output:tensor([223305.0938])\n",
      "Batch Average Reconstruciton Loss:212165632.0\n",
      "input:tensor([  3.4637,   1.7120,   2.8622,   1.7060, 682.0000])\n",
      "output:tensor([223352.4062])\n",
      "Batch Average Reconstruciton Loss:3975251200.0\n",
      "input:tensor([  3.7887,   2.8340,   2.6774,   2.7990, 682.0000])\n",
      "output:tensor([223311.6250])\n",
      "Batch Average Reconstruciton Loss:1483973376.0\n",
      "input:tensor([  3.1767,   1.8050,   2.4705,   1.7030, 682.0000])\n",
      "output:tensor([223358.7500])\n",
      "Batch Average Reconstruciton Loss:7906455040.0\n",
      "input:tensor([  4.8320,   2.6145,   3.8165,   2.5975, 682.0000])\n",
      "output:tensor([223295.6875])\n",
      "Batch Average Reconstruciton Loss:323916768.0\n",
      "input:tensor([  3.6963,   2.0990,   2.8716,   2.0650, 682.0000])\n",
      "output:tensor([223336.7344])\n",
      "Batch Average Reconstruciton Loss:2028355328.0\n",
      "input:tensor([  3.4117,   2.1700,   2.5132,   2.1310, 682.0000])\n",
      "output:tensor([223341.1719])\n",
      "Batch Average Reconstruciton Loss:4546242048.0\n",
      "input:tensor([  4.2863,   2.9960,   3.0557,   2.9620, 682.0000])\n",
      "output:tensor([223296.4531])\n",
      "Batch Average Reconstruciton Loss:66203396.0\n",
      "input:tensor([  3.1703,   1.7360,   2.4990,   1.6720, 682.0000])\n",
      "output:tensor([223360.0469])\n",
      "Batch Average Reconstruciton Loss:8017582080.0\n",
      "input:tensor([  3.5250,   1.7505,   2.9006,   1.7435, 682.0000])\n",
      "output:tensor([223350.])\n",
      "Batch Average Reconstruciton Loss:3371892736.0\n",
      "input:tensor([  5.2040,   4.8460,   1.8796,   4.7720, 682.0000])\n",
      "output:tensor([223234.2344])\n",
      "Batch Average Reconstruciton Loss:1063492608.0\n",
      "input:tensor([  3.3897,   2.1770,   2.4948,   2.1360, 682.0000])\n",
      "output:tensor([223341.4375])\n",
      "Batch Average Reconstruciton Loss:4804231168.0\n",
      "input:tensor([  4.5860,   2.4120,   3.6967,   2.3440, 682.0000])\n",
      "output:tensor([223308.0938])\n",
      "Batch Average Reconstruciton Loss:48959320.0\n",
      "input:tensor([  3.8673,   2.3530,   2.9030,   2.2760, 682.0000])\n",
      "output:tensor([223326.5781])\n",
      "Batch Average Reconstruciton Loss:1100940416.0\n",
      "input:tensor([  4.6790,   2.5715,   3.6762,   2.5115, 682.0000])\n",
      "output:tensor([223301.4688])\n",
      "Batch Average Reconstruciton Loss:127474688.0\n",
      "input:tensor([  4.2433,   2.0390,   3.5798,   1.9410, 682.0000])\n",
      "output:tensor([223327.0938])\n",
      "Batch Average Reconstruciton Loss:109221440.0\n",
      "input:tensor([  3.8693,   1.6810,   3.4292,   1.6400, 682.0000])\n",
      "output:tensor([223344.0156])\n",
      "Batch Average Reconstruciton Loss:1091045888.0\n",
      "input:tensor([  4.0883,   2.6210,   2.9810,   2.5800, 682.0000])\n",
      "output:tensor([223312.9375])\n",
      "Batch Average Reconstruciton Loss:373612672.0\n",
      "input:tensor([  3.6840,   2.0650,   2.8926,   2.0230, 682.0000])\n",
      "output:tensor([223338.0312])\n",
      "Batch Average Reconstruciton Loss:2110021376.0\n",
      "input:tensor([  4.0930,   2.8095,   1.8826,   2.7495, 682.0000])\n",
      "output:tensor([223318.3750])\n",
      "Batch Average Reconstruciton Loss:362773920.0\n",
      "input:tensor([  3.8443,   2.2925,   2.8952,   2.2765, 682.0000])\n",
      "output:tensor([223327.5312])\n",
      "Batch Average Reconstruciton Loss:1205094400.0\n",
      "input:tensor([  5.0453,   3.9650,   3.5690,   3.9050, 682.0000])\n",
      "output:tensor([223248.9531])\n",
      "Batch Average Reconstruciton Loss:709260928.0\n",
      "input:tensor([ 21.2960,  15.5060,  12.6671,  15.4450, 682.0000])\n",
      "output:tensor([222566.6562])\n",
      "Batch Average Reconstruciton Loss:30970599424.0\n",
      "input:tensor([  3.9460,   2.9200,   2.7884,   2.9020, 682.0000])\n",
      "output:tensor([223305.2344])\n",
      "Batch Average Reconstruciton Loss:788978752.0\n",
      "input:tensor([  4.7153,   3.1220,   3.4120,   3.0620, 682.0000])\n",
      "output:tensor([223284.2188])\n",
      "Batch Average Reconstruciton Loss:166596288.0\n",
      "input:tensor([  4.9603,   2.7840,   3.8499,   2.6720, 682.0000])\n",
      "output:tensor([223290.2969])\n",
      "Batch Average Reconstruciton Loss:543043648.0\n",
      "input:tensor([  4.1230,   2.7415,   2.9874,   2.7245, 682.0000])\n",
      "output:tensor([223307.5938])\n",
      "Batch Average Reconstruciton Loss:299061888.0\n",
      "input:tensor([  3.4913,   1.7430,   2.8813,   1.7090, 682.0000])\n",
      "output:tensor([223351.5156])\n",
      "Batch Average Reconstruciton Loss:3694267392.0\n",
      "input:tensor([  3.9013,   2.9570,   2.7567,   2.8350, 682.0000])\n",
      "output:tensor([223307.3438])\n",
      "Batch Average Reconstruciton Loss:958809920.0\n",
      "input:tensor([  3.5737,   2.4355,   2.5753,   2.3345, 682.0000])\n",
      "output:tensor([223330.8594])\n",
      "Batch Average Reconstruciton Loss:2943620352.0\n",
      "input:tensor([  3.9890,   2.0065,   3.3013,   1.9655, 682.0000])\n",
      "output:tensor([223332.4688])\n",
      "Batch Average Reconstruciton Loss:642700160.0\n",
      "input:tensor([  3.7133,   2.1490,   2.8732,   2.0680, 682.0000])\n",
      "output:tensor([223335.9219])\n",
      "Batch Average Reconstruciton Loss:1919235328.0\n",
      "input:tensor([  5.3787,   2.7920,   4.3785,   2.6860, 682.0000])\n",
      "output:tensor([223279.7656])\n",
      "Batch Average Reconstruciton Loss:1509148928.0\n",
      "input:tensor([  4.0830,   2.7065,   2.9626,   2.6345, 682.0000])\n",
      "output:tensor([223310.9062])\n",
      "Batch Average Reconstruciton Loss:386047584.0\n",
      "input:tensor([  3.9713,   2.6650,   2.8678,   2.6060, 682.0000])\n",
      "output:tensor([223314.2656])\n",
      "Batch Average Reconstruciton Loss:700964480.0\n",
      "input:tensor([  4.1097,   2.1910,   3.2617,   2.1740, 682.0000])\n",
      "output:tensor([223324.4688])\n",
      "Batch Average Reconstruciton Loss:326074432.0\n",
      "input:tensor([  3.9797,   2.6115,   2.8920,   2.5935, 682.0000])\n",
      "output:tensor([223314.7969])\n",
      "Batch Average Reconstruciton Loss:673516864.0\n",
      "input:tensor([  3.5950,   2.4350,   2.5896,   2.3610, 682.0000])\n",
      "output:tensor([223329.8438])\n",
      "Batch Average Reconstruciton Loss:2767723264.0\n",
      "input:tensor([ 35.0360,   2.7110,  45.8076,   2.6760, 682.0000])\n",
      "output:tensor([222521.7031])\n",
      "Batch Average Reconstruciton Loss:37716631552.0\n",
      "input:tensor([  4.2397,   2.9400,   3.0406,   2.8330, 682.0000])\n",
      "output:tensor([223300.9531])\n",
      "Batch Average Reconstruciton Loss:114063400.0\n",
      "input:tensor([  4.9223,   1.9910,   4.5236,   1.9300, 682.0000])\n",
      "output:tensor([223310.5312])\n",
      "Batch Average Reconstruciton Loss:474391552.0\n",
      "input:tensor([  4.3067,   2.9765,   2.0539,   2.8735, 682.0000])\n",
      "output:tensor([223309.4062])\n",
      "Batch Average Reconstruciton Loss:49443312.0\n",
      "input:tensor([  3.2127,   1.8690,   2.4572,   1.8650, 682.0000])\n",
      "output:tensor([223353.7812])\n",
      "Batch Average Reconstruciton Loss:7297296896.0\n",
      "input:tensor([  5.2177,   3.8700,   2.4209,   3.8370, 682.0000])\n",
      "output:tensor([223262.1250])\n",
      "Batch Average Reconstruciton Loss:1098201600.0\n",
      "input:tensor([  3.9823,   2.4980,   2.9360,   2.4540, 682.0000])\n",
      "output:tensor([223319.0156])\n",
      "Batch Average Reconstruciton Loss:664659136.0\n",
      "input:tensor([  5.0983,   2.6790,   4.1056,   2.5510, 682.0000])\n",
      "output:tensor([223290.2656])\n",
      "Batch Average Reconstruciton Loss:824681344.0\n",
      "input:tensor([  3.8250,   2.7605,   2.7094,   2.7255, 682.0000])\n",
      "output:tensor([223313.5000])\n",
      "Batch Average Reconstruciton Loss:1298341120.0\n",
      "input:tensor([ 26.2867,  19.5355,  15.9532,  19.4405, 682.0000])\n",
      "output:tensor([222335.3594])\n",
      "Batch Average Reconstruciton Loss:34076184576.0\n",
      "input:tensor([  3.5747,   2.4315,   2.5731,   2.4135, 682.0000])\n",
      "output:tensor([223328.9375])\n",
      "Batch Average Reconstruciton Loss:2935370752.0\n",
      "input:tensor([  4.0607,   2.6340,   2.9572,   2.5980, 682.0000])\n",
      "output:tensor([223312.8750])\n",
      "Batch Average Reconstruciton Loss:440249568.0\n",
      "input:tensor([ 13.8680,   3.7735,  14.6283,   3.7045, 682.0000])\n",
      "output:tensor([223043.7188])\n",
      "Batch Average Reconstruciton Loss:22955800576.0\n",
      "input:tensor([  4.0260,   2.5200,   2.9699,   2.4850, 682.0000])\n",
      "output:tensor([223317.1875])\n",
      "Batch Average Reconstruciton Loss:532723904.0\n",
      "input:tensor([  3.5440,   2.2845,   2.5908,   2.2445, 682.0000])\n",
      "output:tensor([223334.8750])\n",
      "Batch Average Reconstruciton Loss:3200744704.0\n",
      "input:tensor([ 13.5613,   2.2810,  16.1307,   2.2460, 682.0000])\n",
      "output:tensor([223083.3281])\n",
      "Batch Average Reconstruciton Loss:22480302080.0\n",
      "input:tensor([  4.6017,   2.3665,   3.7200,   2.3595, 682.0000])\n",
      "output:tensor([223307.7812])\n",
      "Batch Average Reconstruciton Loss:59811372.0\n",
      "input:tensor([  4.0583,   2.1225,   3.2715,   2.0635, 682.0000])\n",
      "output:tensor([223328.3906])\n",
      "Batch Average Reconstruciton Loss:445488960.0\n",
      "input:tensor([  3.3567,   2.1135,   2.4901,   2.0315, 682.0000])\n",
      "output:tensor([223345.1094])\n",
      "Batch Average Reconstruciton Loss:5210802688.0\n",
      "input:tensor([  4.1537,   2.7735,   2.9983,   2.7385, 682.0000])\n",
      "output:tensor([223306.4531])\n",
      "Batch Average Reconstruciton Loss:240825296.0\n",
      "input:tensor([  3.5403,   1.8385,   2.8879,   1.7275, 682.0000])\n",
      "output:tensor([223349.4531])\n",
      "Batch Average Reconstruciton Loss:3231984640.0\n",
      "input:tensor([  4.0427,   3.6320,   2.9111,   3.4410, 682.0000])\n",
      "output:tensor([223281.8281])\n",
      "Batch Average Reconstruciton Loss:488461792.0\n",
      "input:tensor([  3.2953,   1.9320,   2.5171,   1.8650, 682.0000])\n",
      "output:tensor([223351.5781])\n",
      "Batch Average Reconstruciton Loss:6034248192.0\n",
      "input:tensor([  4.1980,   2.8655,   2.2411,   2.6805, 682.0000])\n",
      "output:tensor([223314.5625])\n",
      "Batch Average Reconstruciton Loss:168699504.0\n",
      "input:tensor([  4.2937,   2.4835,   3.2832,   2.4505, 682.0000])\n",
      "output:tensor([223312.2188])\n",
      "Batch Average Reconstruciton Loss:59687696.0\n",
      "input:tensor([  4.3377,   2.0405,   3.6665,   2.0355, 682.0000])\n",
      "output:tensor([223322.7656])\n",
      "Batch Average Reconstruciton Loss:28850158.0\n",
      "input:tensor([  4.0007,   3.0760,   2.6861,   2.9240, 682.0000])\n",
      "output:tensor([223303.5625])\n",
      "Batch Average Reconstruciton Loss:607890624.0\n",
      "input:tensor([  3.6543,   2.5230,   2.6135,   2.4630, 682.0000])\n",
      "output:tensor([223325.4375])\n",
      "Batch Average Reconstruciton Loss:2316839936.0\n",
      "input:tensor([  3.8310,   2.8415,   2.7073,   2.8255, 682.0000])\n",
      "output:tensor([223310.1094])\n",
      "Batch Average Reconstruciton Loss:1269489152.0\n",
      "input:tensor([  3.8113,   2.6870,   2.7101,   2.6520, 682.0000])\n",
      "output:tensor([223316.2812])\n",
      "Batch Average Reconstruciton Loss:1366020864.0\n",
      "input:tensor([  4.2923,   2.4485,   3.3005,   2.4145, 682.0000])\n",
      "output:tensor([223313.3125])\n",
      "Batch Average Reconstruciton Loss:60788336.0\n",
      "input:tensor([  3.9563,   2.4780,   2.9333,   2.4610, 682.0000])\n",
      "output:tensor([223319.3438])\n",
      "Batch Average Reconstruciton Loss:751727872.0\n",
      "input:tensor([  3.1977,   2.3380,   2.0979,   2.2420, 682.0000])\n",
      "output:tensor([223343.3281])\n",
      "Batch Average Reconstruciton Loss:7548598784.0\n",
      "input:tensor([  3.7890,   2.1710,   2.7395,   2.0670, 682.0000])\n",
      "output:tensor([223336.3281])\n",
      "Batch Average Reconstruciton Loss:1480300416.0\n",
      "input:tensor([  3.3927,   2.1465,   2.4968,   2.1175, 682.0000])\n",
      "output:tensor([223342.1406])\n",
      "Batch Average Reconstruciton Loss:4768297472.0\n",
      "input:tensor([  7.6407,   2.4935,   7.6335,   2.4325, 682.0000])\n",
      "output:tensor([223230.3750])\n",
      "Batch Average Reconstruciton Loss:8723256320.0\n",
      "input:tensor([  3.9647,   2.5135,   2.9304,   2.3995, 682.0000])\n",
      "output:tensor([223320.4688])\n",
      "Batch Average Reconstruciton Loss:723046912.0\n",
      "input:tensor([  4.0650,   2.6420,   2.9700,   2.5460, 682.0000])\n",
      "output:tensor([223313.9375])\n",
      "Batch Average Reconstruciton Loss:429320992.0\n",
      "input:tensor([  3.9653,   2.5015,   2.9121,   2.4825, 682.0000])\n",
      "output:tensor([223318.7031])\n",
      "Batch Average Reconstruciton Loss:720884736.0\n",
      "input:tensor([  3.1877,   1.7995,   2.4681,   1.7915, 682.0000])\n",
      "output:tensor([223356.4844])\n",
      "Batch Average Reconstruciton Loss:7716307456.0\n",
      "input:tensor([  3.8457,   1.9555,   3.1685,   1.8745, 682.0000])\n",
      "output:tensor([223338.2500])\n",
      "Batch Average Reconstruciton Loss:1198180864.0\n",
      "input:tensor([  4.0453,   2.9905,   2.6987,   2.9495, 682.0000])\n",
      "output:tensor([223303.2031])\n",
      "Batch Average Reconstruciton Loss:480389824.0\n",
      "input:tensor([  5.2253,   3.7565,   3.7044,   3.7115, 682.0000])\n",
      "output:tensor([223252.6250])\n",
      "Batch Average Reconstruciton Loss:1116136192.0\n",
      "input:tensor([  4.1900,   2.3185,   3.2820,   2.2795, 682.0000])\n",
      "output:tensor([223319.3750])\n",
      "Batch Average Reconstruciton Loss:180489152.0\n",
      "input:tensor([  6.5537,   5.4970,   4.7061,   5.4280, 682.0000])\n",
      "output:tensor([223166.2500])\n",
      "Batch Average Reconstruciton Loss:5155275776.0\n",
      "input:tensor([ 13.5577,   2.3585,  16.0249,   2.2545, 682.0000])\n",
      "output:tensor([223083.4531])\n",
      "Batch Average Reconstruciton Loss:22474342400.0\n",
      "input:tensor([  4.7533,   3.6285,   3.3580,   3.5865, 682.0000])\n",
      "output:tensor([223265.8594])\n",
      "Batch Average Reconstruciton Loss:212280800.0\n",
      "input:tensor([  3.2097,   1.7370,   2.5458,   1.6960, 682.0000])\n",
      "output:tensor([223358.5000])\n",
      "Batch Average Reconstruciton Loss:7345775616.0\n",
      "input:tensor([  4.0837,   2.7070,   2.9576,   2.6680, 682.0000])\n",
      "output:tensor([223310.0938])\n",
      "Batch Average Reconstruciton Loss:384509216.0\n",
      "input:tensor([  4.2037,   2.8525,   3.0210,   2.7915, 682.0000])\n",
      "output:tensor([223303.5000])\n",
      "Batch Average Reconstruciton Loss:160795088.0\n",
      "input:tensor([  4.5727,   3.4220,   1.9754,   3.4170, 682.0000])\n",
      "output:tensor([223289.0625])\n",
      "Batch Average Reconstruciton Loss:40297896.0\n",
      "input:tensor([  4.8373,   3.2860,   3.4704,   3.2510, 682.0000])\n",
      "output:tensor([223275.8125])\n",
      "Batch Average Reconstruciton Loss:331378784.0\n",
      "input:tensor([  4.1170,   2.7330,   2.9839,   2.6650, 682.0000])\n",
      "output:tensor([223309.2812])\n",
      "Batch Average Reconstruciton Loss:311265536.0\n",
      "input:tensor([  3.1773,   1.8260,   2.4421,   1.7920, 682.0000])\n",
      "output:tensor([223356.5938])\n",
      "Batch Average Reconstruciton Loss:7895283200.0\n",
      "input:tensor([ 26.6197,   1.8210,  35.1384,   1.8150, 682.0000])\n",
      "output:tensor([222756.5469])\n",
      "Batch Average Reconstruciton Loss:34406744064.0\n",
      "input:tensor([  3.8050,   2.7320,   2.7011,   2.6750, 682.0000])\n",
      "output:tensor([223315.3750])\n",
      "Batch Average Reconstruciton Loss:1398358016.0\n",
      "input:tensor([  4.3213,   3.3935,   3.0571,   3.3595, 682.0000])\n",
      "output:tensor([223281.8750])\n",
      "Batch Average Reconstruciton Loss:39402300.0\n",
      "input:tensor([  4.3533,   3.0275,   3.1068,   2.9675, 682.0000])\n",
      "output:tensor([223294.7344])\n",
      "Batch Average Reconstruciton Loss:20942208.0\n",
      "input:tensor([  3.3627,   2.0705,   2.5140,   2.0355, 682.0000])\n",
      "output:tensor([223345.1406])\n",
      "Batch Average Reconstruciton Loss:5134991872.0\n",
      "input:tensor([  4.0250,   2.5995,   2.9562,   2.4885, 682.0000])\n",
      "output:tensor([223316.3906])\n",
      "Batch Average Reconstruciton Loss:535626656.0\n",
      "input:tensor([  3.9717,   2.0115,   3.2460,   1.9765, 682.0000])\n",
      "output:tensor([223332.9375])\n",
      "Batch Average Reconstruciton Loss:698865408.0\n",
      "input:tensor([  3.7480,   2.1230,   2.8945,   2.0790, 682.0000])\n",
      "output:tensor([223335.3438])\n",
      "Batch Average Reconstruciton Loss:1708967168.0\n",
      "input:tensor([  9.0900,  10.2240,   8.3350,  10.1300, 682.0000])\n",
      "output:tensor([222932.2031])\n",
      "Batch Average Reconstruciton Loss:12950713344.0\n",
      "input:tensor([  3.7550,   2.1915,   2.8762,   2.1145, 682.0000])\n",
      "output:tensor([223333.8281])\n",
      "Batch Average Reconstruciton Loss:1668491392.0\n",
      "input:tensor([  4.3037,   2.5275,   2.8428,   2.4245, 682.0000])\n",
      "output:tensor([223317.])\n",
      "Batch Average Reconstruciton Loss:51609856.0\n",
      "input:tensor([  3.5953,   2.4755,   2.5741,   2.4345, 682.0000])\n",
      "output:tensor([223327.7188])\n",
      "Batch Average Reconstruciton Loss:2765211904.0\n",
      "input:tensor([  3.7160,   2.1015,   2.8763,   2.0615, 682.0000])\n",
      "output:tensor([223336.5312])\n",
      "Batch Average Reconstruciton Loss:1902483584.0\n",
      "input:tensor([  3.9867,   1.7290,   3.5302,   1.6940, 682.0000])\n",
      "output:tensor([223339.8281])\n",
      "Batch Average Reconstruciton Loss:649697856.0\n",
      "input:tensor([  3.9443,   2.3935,   2.9785,   2.2895, 682.0000])\n",
      "output:tensor([223324.1719])\n",
      "Batch Average Reconstruciton Loss:793877312.0\n",
      "input:tensor([  4.1010,   2.2125,   3.2822,   2.1085, 682.0000])\n",
      "output:tensor([223325.7344])\n",
      "Batch Average Reconstruciton Loss:344706208.0\n",
      "input:tensor([  70.8510,   92.0070,  118.4439,  130.0709, 1058.0000])\n",
      "output:tensor([340426.2500])\n",
      "Batch Average Reconstruciton Loss:103825244160.0\n",
      "input:tensor([  5.3120,   1.9125,   5.1140,   1.8955, 682.0000])\n",
      "output:tensor([223301.7812])\n",
      "Batch Average Reconstruciton Loss:1336252032.0\n",
      "input:tensor([  5.2090,   2.7410,   4.1716,   2.7070, 682.0000])\n",
      "output:tensor([223283.7969])\n",
      "Batch Average Reconstruciton Loss:1078715008.0\n",
      "input:tensor([  3.7037,   2.5845,   2.6545,   2.4775, 682.0000])\n",
      "output:tensor([223323.4688])\n",
      "Batch Average Reconstruciton Loss:1981988608.0\n",
      "input:tensor([  4.7237,   3.5005,   3.3375,   3.4645, 682.0000])\n",
      "output:tensor([223270.8125])\n",
      "Batch Average Reconstruciton Loss:175955248.0\n",
      "input:tensor([  3.7940,   2.2555,   2.8821,   2.2345, 682.0000])\n",
      "output:tensor([223329.6719])\n",
      "Batch Average Reconstruciton Loss:1454303232.0\n",
      "input:tensor([  4.8260,   2.3095,   4.0834,   2.2425, 682.0000])\n",
      "output:tensor([223305.0469])\n",
      "Batch Average Reconstruciton Loss:315135168.0\n",
      "input:tensor([  3.8737,   2.4440,   2.6890,   2.3730, 682.0000])\n",
      "output:tensor([223325.4062])\n",
      "Batch Average Reconstruciton Loss:1073387520.0\n",
      "input:tensor([  3.9913,   2.5145,   2.9587,   2.4805, 682.0000])\n",
      "output:tensor([223317.8438])\n",
      "Batch Average Reconstruciton Loss:636056256.0\n",
      "input:tensor([  3.9593,   2.9570,   2.7956,   2.9200, 682.0000])\n",
      "output:tensor([223304.1875])\n",
      "Batch Average Reconstruciton Loss:742170816.0\n",
      "input:tensor([  3.9253,   2.4445,   2.9217,   2.3995, 682.0000])\n",
      "output:tensor([223321.7031])\n",
      "Batch Average Reconstruciton Loss:864083456.0\n",
      "input:tensor([  4.2823,   2.4250,   3.1688,   2.3070, 682.0000])\n",
      "output:tensor([223317.7969])\n",
      "Batch Average Reconstruciton Loss:69408944.0\n",
      "input:tensor([  3.3253,   2.0310,   2.4835,   1.9980, 682.0000])\n",
      "output:tensor([223347.2188])\n",
      "Batch Average Reconstruciton Loss:5620318208.0\n",
      "input:tensor([  3.6020,   2.4440,   2.5917,   2.4380, 682.0000])\n",
      "output:tensor([223327.7031])\n",
      "Batch Average Reconstruciton Loss:2711836672.0\n",
      "input:tensor([  4.1657,   2.3545,   3.2382,   2.2945, 682.0000])\n",
      "output:tensor([223319.3438])\n",
      "Batch Average Reconstruciton Loss:219562944.0\n",
      "input:tensor([  5.7917,   2.2295,   5.3953,   2.1595, 682.0000])\n",
      "output:tensor([223283.6562])\n",
      "Batch Average Reconstruciton Loss:2704276224.0\n",
      "input:tensor([  5.0037,   3.9245,   3.5413,   3.8905, 682.0000])\n",
      "output:tensor([223250.4531])\n",
      "Batch Average Reconstruciton Loss:624772672.0\n",
      "input:tensor([  4.7293,   2.1055,   4.1266,   2.0455, 682.0000])\n",
      "output:tensor([223312.7188])\n",
      "Batch Average Reconstruciton Loss:183811744.0\n",
      "input:tensor([  4.0023,   2.5350,   2.9402,   2.5000, 682.0000])\n",
      "output:tensor([223317.1875])\n",
      "Batch Average Reconstruciton Loss:602104256.0\n",
      "input:tensor([  4.4600,   2.2435,   3.6531,   2.2095, 682.0000])\n",
      "output:tensor([223315.0781])\n",
      "Batch Average Reconstruciton Loss:797588.5625\n",
      "input:tensor([  3.7897,   2.7085,   2.6886,   2.6905, 682.0000])\n",
      "output:tensor([223315.5156])\n",
      "Batch Average Reconstruciton Loss:1478285952.0\n",
      "input:tensor([  4.3450,   1.8755,   3.8638,   1.8415, 682.0000])\n",
      "output:tensor([223327.1875])\n",
      "Batch Average Reconstruciton Loss:24808494.0\n",
      "input:tensor([  4.3567,   3.0505,   3.1063,   3.0065, 682.0000])\n",
      "output:tensor([223293.4688])\n",
      "Batch Average Reconstruciton Loss:19391088.0\n",
      "input:tensor([  3.1253,   1.7415,   2.4507,   1.6745, 682.0000])\n",
      "output:tensor([223360.9219])\n",
      "Batch Average Reconstruciton Loss:8844476416.0\n",
      "input:tensor([  3.6327,   2.4925,   2.5972,   2.4735, 682.0000])\n",
      "output:tensor([223325.9219])\n",
      "Batch Average Reconstruciton Loss:2475269376.0\n",
      "input:tensor([  5.1750,   2.3480,   4.4698,   2.2810, 682.0000])\n",
      "output:tensor([223295.8281])\n",
      "Batch Average Reconstruciton Loss:998865152.0\n",
      "input:tensor([ 10.6317,   2.3865,  11.8827,   2.3225, 682.0000])\n",
      "output:tensor([223156.9531])\n",
      "Batch Average Reconstruciton Loss:16861270016.0\n",
      "input:tensor([  4.1350,   2.2480,   3.2830,   2.2060, 682.0000])\n",
      "output:tensor([223322.5312])\n",
      "Batch Average Reconstruciton Loss:274911936.0\n",
      "input:tensor([  3.8857,   2.4085,   2.9077,   2.3055, 682.0000])\n",
      "output:tensor([223325.])\n",
      "Batch Average Reconstruciton Loss:1022208768.0\n",
      "input:tensor([  3.6983,   1.9935,   2.9400,   1.9335, 682.0000])\n",
      "output:tensor([223340.4062])\n",
      "Batch Average Reconstruciton Loss:2014985856.0\n",
      "input:tensor([  3.6910,   2.6270,   2.6330,   2.5890, 682.0000])\n",
      "output:tensor([223320.5781])\n",
      "Batch Average Reconstruciton Loss:2064922880.0\n",
      "input:tensor([  3.5067,   1.7960,   2.8663,   1.7220, 682.0000])\n",
      "output:tensor([223350.6094])\n",
      "Batch Average Reconstruciton Loss:3544939008.0\n",
      "input:tensor([  3.8583,   2.3135,   2.9222,   2.2085, 682.0000])\n",
      "output:tensor([223328.5938])\n",
      "Batch Average Reconstruciton Loss:1140913152.0\n",
      "input:tensor([  3.4973,   1.7110,   2.9318,   1.6320, 682.0000])\n",
      "output:tensor([223353.1719])\n",
      "Batch Average Reconstruciton Loss:3635104512.0\n",
      "input:tensor([  4.0057,   2.5610,   2.9365,   2.5260, 682.0000])\n",
      "output:tensor([223316.2812])\n",
      "Batch Average Reconstruciton Loss:592081216.0\n",
      "input:tensor([ 14.7543,   2.4190,  17.5930,   2.3850, 682.0000])\n",
      "output:tensor([223050.0156])\n",
      "Batch Average Reconstruciton Loss:24278630400.0\n",
      "input:tensor([  4.2640,   2.4235,   3.2876,   2.4115, 682.0000])\n",
      "output:tensor([223314.0781])\n",
      "Batch Average Reconstruciton Loss:87066104.0\n",
      "input:tensor([  4.0653,   3.1840,   2.8742,   3.1030, 682.0000])\n",
      "output:tensor([223295.2188])\n",
      "Batch Average Reconstruciton Loss:429267904.0\n",
      "input:tensor([  3.1053,   1.7125,   2.4325,   1.6785, 682.0000])\n",
      "output:tensor([223361.5156])\n",
      "Batch Average Reconstruciton Loss:9232996352.0\n",
      "input:tensor([  4.3323,   1.8025,   3.9103,   1.7435, 682.0000])\n",
      "output:tensor([223330.0625])\n",
      "Batch Average Reconstruciton Loss:31876610.0\n",
      "input:tensor([  8.1580,   4.9160,   6.1214,   4.8490, 682.0000])\n",
      "output:tensor([223154.7344])\n",
      "Batch Average Reconstruciton Loss:10313769984.0\n",
      "input:tensor([  4.3290,   3.0210,   3.0858,   2.9790, 682.0000])\n",
      "output:tensor([223294.9844])\n",
      "Batch Average Reconstruciton Loss:34304632.0\n",
      "input:tensor([  3.8510,   2.8035,   2.7275,   2.7995, 682.0000])\n",
      "output:tensor([223310.7188])\n",
      "Batch Average Reconstruciton Loss:1175411968.0\n",
      "input:tensor([  3.9037,   2.3840,   2.9131,   2.3680, 682.0000])\n",
      "output:tensor([223323.4531])\n",
      "Batch Average Reconstruciton Loss:948427328.0\n",
      "input:tensor([  3.3547,   1.8165,   2.6451,   1.7815, 682.0000])\n",
      "output:tensor([223352.9219])\n",
      "Batch Average Reconstruciton Loss:5235112448.0\n",
      "input:tensor([  3.4693,   1.8190,   2.8316,   1.7150, 682.0000])\n",
      "output:tensor([223351.3438])\n",
      "Batch Average Reconstruciton Loss:3916588800.0\n",
      "input:tensor([  4.0043,   2.6505,   2.7141,   2.5885, 682.0000])\n",
      "output:tensor([223316.1562])\n",
      "Batch Average Reconstruciton Loss:596133440.0\n",
      "input:tensor([  4.1103,   3.2270,   2.9065,   3.1230, 682.0000])\n",
      "output:tensor([223293.4062])\n",
      "Batch Average Reconstruciton Loss:325787840.0\n",
      "input:tensor([  4.0943,   2.1975,   3.2699,   2.1625, 682.0000])\n",
      "output:tensor([223324.7500])\n",
      "Batch Average Reconstruciton Loss:359528992.0\n",
      "input:tensor([  3.7827,   2.2075,   2.8804,   2.1895, 682.0000])\n",
      "output:tensor([223331.4219])\n",
      "Batch Average Reconstruciton Loss:1514577920.0\n",
      "input:tensor([  3.7810,   2.1635,   2.9003,   2.1295, 682.0000])\n",
      "output:tensor([223333.2188])\n",
      "Batch Average Reconstruciton Loss:1523401856.0\n",
      "input:tensor([  4.5720,   3.6340,   3.2394,   3.6000, 682.0000])\n",
      "output:tensor([223268.6562])\n",
      "Batch Average Reconstruciton Loss:39635288.0\n",
      "input:tensor([  3.6143,   2.5210,   2.5766,   2.4870, 682.0000])\n",
      "output:tensor([223325.6875])\n",
      "Batch Average Reconstruciton Loss:2615024640.0\n",
      "input:tensor([  4.5047,   3.3370,   2.9890,   3.2700, 682.0000])\n",
      "output:tensor([223283.4844])\n",
      "Batch Average Reconstruciton Loss:9409460.0\n",
      "input:tensor([  3.7403,   2.1595,   2.8870,   2.0535, 682.0000])\n",
      "output:tensor([223335.7500])\n",
      "Batch Average Reconstruciton Loss:1754039040.0\n",
      "input:tensor([  3.9783,   2.4860,   2.9597,   2.4260, 682.0000])\n",
      "output:tensor([223319.6250])\n",
      "Batch Average Reconstruciton Loss:677632512.0\n",
      "input:tensor([  3.6343,   2.4285,   2.6264,   2.3155, 682.0000])\n",
      "output:tensor([223330.2188])\n",
      "Batch Average Reconstruciton Loss:2462321152.0\n",
      "input:tensor([  3.9217,   2.4705,   2.8922,   2.4085, 682.0000])\n",
      "output:tensor([223321.5312])\n",
      "Batch Average Reconstruciton Loss:878083200.0\n",
      "input:tensor([  3.6047,   2.4470,   2.5873,   2.4100, 682.0000])\n",
      "output:tensor([223328.3750])\n",
      "Batch Average Reconstruciton Loss:2690561792.0\n",
      "input:tensor([  4.4083,   3.1105,   3.1401,   3.0925, 682.0000])\n",
      "output:tensor([223289.7656])\n",
      "Batch Average Reconstruciton Loss:3021458.75\n",
      "input:tensor([  4.4177,   2.2725,   3.6430,   2.1085, 682.0000])\n",
      "output:tensor([223317.8750])\n",
      "Batch Average Reconstruciton Loss:1525533.75\n",
      "input:tensor([  9.0187,   3.4190,   8.4560,   3.3580, 682.0000])\n",
      "output:tensor([223173.8594])\n",
      "Batch Average Reconstruciton Loss:12809680896.0\n",
      "input:tensor([  3.9703,   3.9650,   1.6506,   3.9580, 682.0000])\n",
      "output:tensor([223279.5938])\n",
      "Batch Average Reconstruciton Loss:706145920.0\n",
      "input:tensor([  4.1847,   2.3180,   3.2715,   2.2770, 682.0000])\n",
      "output:tensor([223319.5938])\n",
      "Batch Average Reconstruciton Loss:188688864.0\n",
      "input:tensor([  4.0937,   2.1345,   3.2810,   2.1305, 682.0000])\n",
      "output:tensor([223326.0938])\n",
      "Batch Average Reconstruciton Loss:360996448.0\n",
      "input:tensor([  3.6277,   2.0060,   2.8575,   1.9260, 682.0000])\n",
      "output:tensor([223342.0938])\n",
      "Batch Average Reconstruciton Loss:2511203072.0\n",
      "input:tensor([  3.5073,   1.9095,   2.7668,   1.8655, 682.0000])\n",
      "output:tensor([223346.8906])\n",
      "Batch Average Reconstruciton Loss:3538954240.0\n",
      "input:tensor([  4.1430,   2.5220,   3.0984,   2.4870, 682.0000])\n",
      "output:tensor([223314.4688])\n",
      "Batch Average Reconstruciton Loss:260032752.0\n",
      "input:tensor([  4.1147,   2.1735,   3.3083,   2.1135, 682.0000])\n",
      "output:tensor([223325.5938])\n",
      "Batch Average Reconstruciton Loss:315538592.0\n",
      "input:tensor([  3.7307,   2.1410,   2.8718,   2.0990, 682.0000])\n",
      "output:tensor([223335.0469])\n",
      "Batch Average Reconstruciton Loss:1812115712.0\n",
      "input:tensor([  4.5460,   2.4115,   3.6449,   2.3945, 682.0000])\n",
      "output:tensor([223307.8438])\n",
      "Batch Average Reconstruciton Loss:25947244.0\n",
      "input:tensor([  4.1047,   2.5555,   3.0368,   2.5135, 682.0000])\n",
      "output:tensor([223314.5000])\n",
      "Batch Average Reconstruciton Loss:337144672.0\n",
      "input:tensor([  3.6773,   1.9855,   2.9129,   1.9435, 682.0000])\n",
      "output:tensor([223340.7500])\n",
      "Batch Average Reconstruciton Loss:2154839552.0\n",
      "input:tensor([  3.7770,   2.2075,   2.8805,   2.1695, 682.0000])\n",
      "output:tensor([223332.])\n",
      "Batch Average Reconstruciton Loss:1545276160.0\n",
      "input:tensor([  4.3807,   2.8250,   2.2919,   2.8090, 682.0000])\n",
      "output:tensor([223309.2969])\n",
      "Batch Average Reconstruciton Loss:9864016.0\n",
      "input:tensor([  4.4970,   2.3680,   3.6041,   2.3250, 682.0000])\n",
      "output:tensor([223310.9688])\n",
      "Batch Average Reconstruciton Loss:7398230.0\n",
      "input:tensor([  4.2303,   2.8445,   2.0656,   2.8405, 682.0000])\n",
      "output:tensor([223312.3125])\n",
      "Batch Average Reconstruciton Loss:125097232.0\n",
      "input:tensor([  3.4107,   2.1530,   2.5110,   2.1190, 682.0000])\n",
      "output:tensor([223341.6875])\n",
      "Batch Average Reconstruciton Loss:4557642240.0\n",
      "input:tensor([  4.5040,   3.2635,   2.0168,   3.2075, 682.0000])\n",
      "output:tensor([223296.2656])\n",
      "Batch Average Reconstruciton Loss:9285828.0\n",
      "input:tensor([  6.4420,   2.3430,   6.1339,   2.3090, 682.0000])\n",
      "output:tensor([223263.8750])\n",
      "Batch Average Reconstruciton Loss:4799008256.0\n",
      "input:tensor([  3.6743,   2.4180,   2.6768,   2.3510, 682.0000])\n",
      "output:tensor([223328.4844])\n",
      "Batch Average Reconstruciton Loss:2176457216.0\n",
      "input:tensor([  4.8443,   1.8910,   4.4808,   1.8560, 682.0000])\n",
      "output:tensor([223314.7344])\n",
      "Batch Average Reconstruciton Loss:343721760.0\n",
      "input:tensor([  6.8343,   6.4300,   5.2498,   6.3960, 682.0000])\n",
      "output:tensor([223123.2188])\n",
      "Batch Average Reconstruciton Loss:6079979008.0\n",
      "input:tensor([  4.4973,   2.8410,   2.7750,   2.7370, 682.0000])\n",
      "output:tensor([223304.5156])\n",
      "Batch Average Reconstruciton Loss:7450255.5\n",
      "input:tensor([  3.8323,   2.8860,   2.7059,   2.8500, 682.0000])\n",
      "output:tensor([223309.])\n",
      "Batch Average Reconstruciton Loss:1263162624.0\n",
      "input:tensor([  4.0733,   3.1695,   2.8793,   3.1295, 682.0000])\n",
      "output:tensor([223294.5781])\n",
      "Batch Average Reconstruciton Loss:409674688.0\n",
      "input:tensor([  7.6417,   3.4165,   6.6514,   3.3065, 682.0000])\n",
      "output:tensor([223209.1562])\n",
      "Batch Average Reconstruciton Loss:8722468864.0\n",
      "input:tensor([  3.9270,   2.4105,   2.9209,   2.3935, 682.0000])\n",
      "output:tensor([223322.1875])\n",
      "Batch Average Reconstruciton Loss:857775936.0\n",
      "input:tensor([  4.2873,   3.2195,   3.0273,   3.1855, 682.0000])\n",
      "output:tensor([223288.7812])\n",
      "Batch Average Reconstruciton Loss:65451640.0\n",
      "input:tensor([  4.3393,   2.5715,   3.2969,   2.4965, 682.0000])\n",
      "output:tensor([223309.4844])\n",
      "Batch Average Reconstruciton Loss:28063672.0\n",
      "input:tensor([  5.1807,   3.8355,   3.6608,   3.8005, 682.0000])\n",
      "output:tensor([223250.5000])\n",
      "Batch Average Reconstruciton Loss:1009301120.0\n",
      "input:tensor([  3.7870,   2.7555,   2.6865,   2.6755, 682.0000])\n",
      "output:tensor([223315.4531])\n",
      "Batch Average Reconstruciton Loss:1492550912.0\n",
      "input:tensor([  3.2290,   2.0285,   2.4068,   1.9185, 682.0000])\n",
      "output:tensor([223351.0938])\n",
      "Batch Average Reconstruciton Loss:7033322496.0\n",
      "input:tensor([  3.9293,   2.4385,   2.9291,   2.3935, 682.0000])\n",
      "output:tensor([223321.7969])\n",
      "Batch Average Reconstruciton Loss:849034880.0\n",
      "input:tensor([  4.3830,   2.2930,   3.5153,   2.2750, 682.0000])\n",
      "output:tensor([223315.2031])\n",
      "Batch Average Reconstruciton Loss:9082972.0\n",
      "input:tensor([  3.5557,   2.3900,   2.5674,   2.3730, 682.0000])\n",
      "output:tensor([223330.6562])\n",
      "Batch Average Reconstruciton Loss:3098073856.0\n",
      "input:tensor([  4.4780,   2.8760,   3.3114,   2.6810, 682.0000])\n",
      "output:tensor([223300.])\n",
      "Batch Average Reconstruciton Loss:3143529.0\n",
      "input:tensor([  3.8393,   2.8035,   2.6000,   2.6395, 682.0000])\n",
      "output:tensor([223316.2500])\n",
      "Batch Average Reconstruciton Loss:1229326336.0\n",
      "input:tensor([  4.5377,   2.8610,   2.7630,   2.8270, 682.0000])\n",
      "output:tensor([223301.7500])\n",
      "Batch Average Reconstruciton Loss:21965626.0\n",
      "input:tensor([  4.3253,   1.7440,   3.9781,   1.6430, 682.0000])\n",
      "output:tensor([223332.5469])\n",
      "Batch Average Reconstruciton Loss:36161620.0\n",
      "input:tensor([  5.0623,   3.1405,   3.7535,   3.1065, 682.0000])\n",
      "output:tensor([223275.5625])\n",
      "Batch Average Reconstruciton Loss:746303872.0\n",
      "input:tensor([  9.9713,   2.9040,  10.1454,   2.7980, 682.0000])\n",
      "output:tensor([223165.1406])\n",
      "Batch Average Reconstruciton Loss:15296777216.0\n",
      "input:tensor([  4.4177,   3.5775,   1.7085,   3.5675, 682.0000])\n",
      "output:tensor([223288.1406])\n",
      "Batch Average Reconstruciton Loss:1599869.25\n",
      "input:tensor([  4.5110,   3.0465,   3.2499,   2.9805, 682.0000])\n",
      "output:tensor([223291.])\n",
      "Batch Average Reconstruciton Loss:11451456.0\n",
      "input:tensor([  4.0720,   3.1955,   2.8785,   3.1185, 682.0000])\n",
      "output:tensor([223294.5938])\n",
      "Batch Average Reconstruciton Loss:412918912.0\n",
      "input:tensor([  4.8603,   4.2960,   3.5743,   4.2350, 682.0000])\n",
      "output:tensor([223239.0625])\n",
      "Batch Average Reconstruciton Loss:366265440.0\n",
      "input:tensor([  9.1003,   7.2170,   4.0292,   7.1130, 682.0000])\n",
      "output:tensor([223085.9062])\n",
      "Batch Average Reconstruciton Loss:13013996544.0\n",
      "input:tensor([  3.5257,   1.8765,   2.8389,   1.8025, 682.0000])\n",
      "output:tensor([223347.8594])\n",
      "Batch Average Reconstruciton Loss:3365988608.0\n",
      "input:tensor([ 12.2813,  15.3700,  12.1696,  15.3650, 682.0000])\n",
      "output:tensor([222671.1875])\n",
      "Batch Average Reconstruciton Loss:20135096320.0\n",
      "input:tensor([  4.6127,   3.9025,   1.3794,   3.8355, 682.0000])\n",
      "output:tensor([223279.4062])\n",
      "Batch Average Reconstruciton Loss:67558640.0\n",
      "input:tensor([  3.1553,   1.7940,   2.4523,   1.7190, 682.0000])\n",
      "output:tensor([223358.8906])\n",
      "Batch Average Reconstruciton Loss:8286298624.0\n",
      "input:tensor([ 36.7293,   3.9450,  46.4188,   3.8530, 682.0000])\n",
      "output:tensor([222454.5312])\n",
      "Batch Average Reconstruciton Loss:38199345152.0\n",
      "input:tensor([  7.1787,   7.0610,   5.7172,   7.0260, 682.0000])\n",
      "output:tensor([223092.0312])\n",
      "Batch Average Reconstruciton Loss:7208864256.0\n",
      "input:tensor([  3.4263,   2.1840,   2.5217,   2.1420, 682.0000])\n",
      "output:tensor([223340.5000])\n",
      "Batch Average Reconstruciton Loss:4379991040.0\n",
      "input:tensor([  4.8110,   3.2095,   3.4784,   3.1425, 682.0000])\n",
      "output:tensor([223279.5469])\n",
      "Batch Average Reconstruciton Loss:291915904.0\n",
      "input:tensor([  3.9420,   2.9580,   2.7831,   2.9240, 682.0000])\n",
      "output:tensor([223304.3906])\n",
      "Batch Average Reconstruciton Loss:803416896.0\n",
      "input:tensor([  4.2213,   2.8635,   2.0691,   2.7655, 682.0000])\n",
      "output:tensor([223314.0469])\n",
      "Batch Average Reconstruciton Loss:136491392.0\n",
      "input:tensor([  4.3203,   2.5365,   3.2826,   2.4575, 682.0000])\n",
      "output:tensor([223311.2031])\n",
      "Batch Average Reconstruciton Loss:39700040.0\n",
      "input:tensor([  4.9157,   3.1640,   3.5919,   3.1300, 682.0000])\n",
      "output:tensor([223278.])\n",
      "Batch Average Reconstruciton Loss:461132672.0\n",
      "input:tensor([  4.2980,   2.4505,   3.3046,   2.4165, 682.0000])\n",
      "output:tensor([223313.1562])\n",
      "Batch Average Reconstruciton Loss:56127724.0\n",
      "input:tensor([  5.1043,   3.2835,   3.7401,   3.2245, 682.0000])\n",
      "output:tensor([223270.7812])\n",
      "Batch Average Reconstruciton Loss:836700800.0\n",
      "input:tensor([  4.1840,   2.8215,   3.0113,   2.7785, 682.0000])\n",
      "output:tensor([223304.5000])\n",
      "Batch Average Reconstruciton Loss:190150304.0\n",
      "input:tensor([  4.1417,   2.7470,   2.9926,   2.7070, 682.0000])\n",
      "output:tensor([223307.7344])\n",
      "Batch Average Reconstruciton Loss:262740288.0\n",
      "input:tensor([  4.7023,   2.4075,   3.8375,   2.3735, 682.0000])\n",
      "output:tensor([223304.6719])\n",
      "Batch Average Reconstruciton Loss:152415616.0\n",
      "input:tensor([  5.1147,   3.1930,   2.8833,   3.1870, 682.0000])\n",
      "output:tensor([223281.7500])\n",
      "Batch Average Reconstruciton Loss:860234240.0\n",
      "input:tensor([  3.8067,   1.7195,   3.2909,   1.7025, 682.0000])\n",
      "output:tensor([223344.1875])\n",
      "Batch Average Reconstruciton Loss:1387623040.0\n",
      "input:tensor([  8.7390,  10.6350,   7.8793,  10.5560, 682.0000])\n",
      "output:tensor([222925.7500])\n",
      "Batch Average Reconstruciton Loss:11970930688.0\n",
      "input:tensor([  3.7223,   2.1240,   2.8644,   2.0900, 682.0000])\n",
      "output:tensor([223335.6406])\n",
      "Batch Average Reconstruciton Loss:1863161984.0\n",
      "input:tensor([  4.9903,   3.1455,   3.6803,   3.0455, 682.0000])\n",
      "output:tensor([223278.5938])\n",
      "Batch Average Reconstruciton Loss:599985152.0\n",
      "input:tensor([  3.8567,   2.3980,   2.8993,   2.2010, 682.0000])\n",
      "output:tensor([223328.1406])\n",
      "Batch Average Reconstruciton Loss:1148454784.0\n",
      "input:tensor([  4.0177,   2.5700,   2.9356,   2.5310, 682.0000])\n",
      "output:tensor([223315.9219])\n",
      "Batch Average Reconstruciton Loss:556633344.0\n",
      "input:tensor([  3.7387,   2.1710,   2.8622,   2.0680, 682.0000])\n",
      "output:tensor([223335.5469])\n",
      "Batch Average Reconstruciton Loss:1763954048.0\n",
      "input:tensor([  3.6697,   2.0355,   2.8629,   2.0025, 682.0000])\n",
      "output:tensor([223339.3281])\n",
      "Batch Average Reconstruciton Loss:2207559424.0\n",
      "input:tensor([  4.1007,   2.1995,   3.2552,   2.1825, 682.0000])\n",
      "output:tensor([223324.3125])\n",
      "Batch Average Reconstruciton Loss:345502112.0\n",
      "input:tensor([  4.5730,   3.4550,   1.7397,   3.3520, 682.0000])\n",
      "output:tensor([223292.8594])\n",
      "Batch Average Reconstruciton Loss:40549632.0\n",
      "input:tensor([  4.4537,   2.9515,   3.2283,   2.9455, 682.0000])\n",
      "output:tensor([223293.7188])\n",
      "Batch Average Reconstruciton Loss:308823.34375\n",
      "input:tensor([  3.2093,   1.9070,   2.4543,   1.8390, 682.0000])\n",
      "output:tensor([223354.0938])\n",
      "Batch Average Reconstruciton Loss:7352017408.0\n",
      "input:tensor([  3.7810,   2.6450,   2.6937,   2.6040, 682.0000])\n",
      "output:tensor([223318.4375])\n",
      "Batch Average Reconstruciton Loss:1524555904.0\n",
      "input:tensor([  4.1343,   2.6720,   3.0259,   2.6010, 682.0000])\n",
      "output:tensor([223310.8906])\n",
      "Batch Average Reconstruciton Loss:276593792.0\n",
      "input:tensor([  3.6700,   2.1905,   2.7717,   2.1515, 682.0000])\n",
      "output:tensor([223334.9375])\n",
      "Batch Average Reconstruciton Loss:2205716992.0\n",
      "input:tensor([  3.2923,   1.9605,   2.5015,   1.8985, 682.0000])\n",
      "output:tensor([223350.6250])\n",
      "Batch Average Reconstruciton Loss:6077040640.0\n",
      "input:tensor([  3.8253,   2.2655,   2.9009,   2.2315, 682.0000])\n",
      "output:tensor([223329.1094])\n",
      "Batch Average Reconstruciton Loss:1295632128.0\n",
      "input:tensor([ 20.4673,  15.2955,  14.4705,  15.2345, 682.0000])\n",
      "output:tensor([222563.6406])\n",
      "Batch Average Reconstruciton Loss:30309640192.0\n",
      "input:tensor([  3.6550,   2.5670,   2.6075,   2.5030, 682.0000])\n",
      "output:tensor([223324.0469])\n",
      "Batch Average Reconstruciton Loss:2312162816.0\n",
      "input:tensor([  4.8907,   2.8605,   3.7137,   2.8385, 682.0000])\n",
      "output:tensor([223287.5000])\n",
      "Batch Average Reconstruciton Loss:418304768.0\n",
      "input:tensor([  3.7347,   2.5255,   2.6849,   2.4885, 682.0000])\n",
      "output:tensor([223323.1875])\n",
      "Batch Average Reconstruciton Loss:1788935808.0\n",
      "input:tensor([  3.6487,   2.4945,   2.6201,   2.4205, 682.0000])\n",
      "output:tensor([223326.7969])\n",
      "Batch Average Reconstruciton Loss:2357413632.0\n",
      "input:tensor([  3.6490,   2.5080,   2.6104,   2.4740, 682.0000])\n",
      "output:tensor([223325.4375])\n",
      "Batch Average Reconstruciton Loss:2355118336.0\n",
      "input:tensor([  4.2353,   2.3810,   3.2833,   2.3460, 682.0000])\n",
      "output:tensor([223316.5469])\n",
      "Batch Average Reconstruciton Loss:118885288.0\n",
      "input:tensor([  4.6767,   2.2485,   3.9648,   2.1515, 682.0000])\n",
      "output:tensor([223310.8594])\n",
      "Batch Average Reconstruciton Loss:125302488.0\n",
      "input:tensor([  3.4363,   2.1940,   2.5186,   2.1590, 682.0000])\n",
      "output:tensor([223339.9219])\n",
      "Batch Average Reconstruciton Loss:4269325824.0\n",
      "input:tensor([  3.9040,   2.3940,   2.9074,   2.3870, 682.0000])\n",
      "output:tensor([223322.9062])\n",
      "Batch Average Reconstruciton Loss:947106368.0\n",
      "input:tensor([  3.4357,   2.2610,   2.4968,   2.2220, 682.0000])\n",
      "output:tensor([223337.8438])\n",
      "Batch Average Reconstruciton Loss:4276918784.0\n",
      "input:tensor([  3.7973,   2.2210,   2.8852,   2.2030, 682.0000])\n",
      "output:tensor([223330.7500])\n",
      "Batch Average Reconstruciton Loss:1436807936.0\n",
      "input:tensor([ 38.9127,   5.8390,  47.0243,   5.8220, 682.0000])\n",
      "output:tensor([222355.3438])\n",
      "Batch Average Reconstruciton Loss:38754783232.0\n",
      "input:tensor([  3.5080,   1.8075,   2.8713,   1.7335, 682.0000])\n",
      "output:tensor([223350.1562])\n",
      "Batch Average Reconstruciton Loss:3532144128.0\n",
      "input:tensor([  3.8253,   2.2340,   2.9224,   2.1750, 682.0000])\n",
      "output:tensor([223330.5938])\n",
      "Batch Average Reconstruciton Loss:1295525248.0\n",
      "input:tensor([ 16.5657,   2.2315,  20.4224,   2.1725, 682.0000])\n",
      "output:tensor([223007.7656])\n",
      "Batch Average Reconstruciton Loss:26609688576.0\n",
      "input:tensor([  4.7470,   2.6200,   3.7145,   2.5840, 682.0000])\n",
      "output:tensor([223297.9844])\n",
      "Batch Average Reconstruciton Loss:205176528.0\n",
      "input:tensor([  3.7147,   2.5730,   2.6535,   2.5320, 682.0000])\n",
      "output:tensor([223322.1406])\n",
      "Batch Average Reconstruciton Loss:1912125696.0\n",
      "input:tensor([  4.0370,   2.6175,   2.9592,   2.6005, 682.0000])\n",
      "output:tensor([223313.2500])\n",
      "Batch Average Reconstruciton Loss:502376192.0\n",
      "input:tensor([  3.7350,   2.6215,   1.6111,   2.6035, 682.0000])\n",
      "output:tensor([223330.7656])\n",
      "Batch Average Reconstruciton Loss:1786350080.0\n",
      "input:tensor([  5.1280,   2.6790,   4.1415,   2.5700, 682.0000])\n",
      "output:tensor([223289.0781])\n",
      "Batch Average Reconstruciton Loss:890489920.0\n",
      "input:tensor([  4.3137,   2.4610,   3.3322,   2.3820, 682.0000])\n",
      "output:tensor([223313.4375])\n",
      "Batch Average Reconstruciton Loss:44269892.0\n",
      "input:tensor([  4.0090,   2.0880,   3.2526,   2.0530, 682.0000])\n",
      "output:tensor([223329.7500])\n",
      "Batch Average Reconstruciton Loss:581448832.0\n",
      "input:tensor([  3.7493,   2.7130,   2.6603,   2.6310, 682.0000])\n",
      "output:tensor([223317.7031])\n",
      "Batch Average Reconstruciton Loss:1702577152.0\n",
      "input:tensor([  3.5307,   2.3495,   2.5637,   2.2895, 682.0000])\n",
      "output:tensor([223333.4844])\n",
      "Batch Average Reconstruciton Loss:3321622016.0\n",
      "input:tensor([  4.2380,   1.9645,   3.6467,   1.9045, 682.0000])\n",
      "output:tensor([223328.1250])\n",
      "Batch Average Reconstruciton Loss:115452336.0\n",
      "input:tensor([  4.1180,   2.6720,   2.1479,   2.5980, 682.0000])\n",
      "output:tensor([223320.5469])\n",
      "Batch Average Reconstruciton Loss:308826240.0\n",
      "input:tensor([ 67.9368,  71.9773, 112.6414,  98.2326, 802.0000])\n",
      "output:tensor([257644.0938])\n",
      "Batch Average Reconstruciton Loss:59801812992.0\n",
      "input:tensor([  4.8027,   3.1455,   3.4801,   3.1385, 682.0000])\n",
      "output:tensor([223280.4062])\n",
      "Batch Average Reconstruciton Loss:279839584.0\n",
      "input:tensor([  4.3623,   3.0550,   3.1091,   2.9420, 682.0000])\n",
      "output:tensor([223294.9375])\n",
      "Batch Average Reconstruciton Loss:16859750.0\n",
      "input:tensor([  3.9110,   2.4010,   2.9177,   2.3640, 682.0000])\n",
      "output:tensor([223323.2188])\n",
      "Batch Average Reconstruciton Loss:919349760.0\n",
      "input:tensor([  4.1353,   2.9435,   2.6283,   2.7705, 682.0000])\n",
      "output:tensor([223308.0156])\n",
      "Batch Average Reconstruciton Loss:274763264.0\n",
      "input:tensor([  4.3077,   2.9935,   3.0731,   2.9485, 682.0000])\n",
      "output:tensor([223296.4062])\n",
      "Batch Average Reconstruciton Loss:48868400.0\n",
      "input:tensor([  4.5727,   2.4465,   3.6316,   2.4045, 682.0000])\n",
      "output:tensor([223307.0625])\n",
      "Batch Average Reconstruciton Loss:40526752.0\n",
      "input:tensor([  3.6037,   2.4620,   2.5889,   2.3950, 682.0000])\n",
      "output:tensor([223328.6094])\n",
      "Batch Average Reconstruciton Loss:2698427392.0\n",
      "input:tensor([  3.9003,   1.8335,   3.3365,   1.7745, 682.0000])\n",
      "output:tensor([223339.7031])\n",
      "Batch Average Reconstruciton Loss:960832384.0\n",
      "input:tensor([  3.9483,   3.0555,   1.5390,   2.9885, 682.0000])\n",
      "output:tensor([223315.0156])\n",
      "Batch Average Reconstruciton Loss:780084032.0\n",
      "input:tensor([  4.1317,   2.2015,   3.2847,   2.1965, 682.0000])\n",
      "output:tensor([223323.2812])\n",
      "Batch Average Reconstruciton Loss:281357632.0\n",
      "input:tensor([ 13.1480,   1.6860,  16.3192,   1.6520, 682.0000])\n",
      "output:tensor([223106.9062])\n",
      "Batch Average Reconstruciton Loss:21802856448.0\n",
      "input:tensor([  4.3550,   3.4275,   3.0807,   3.3665, 682.0000])\n",
      "output:tensor([223280.7188])\n",
      "Batch Average Reconstruciton Loss:20279542.0\n",
      "input:tensor([  3.5397,   2.3165,   2.5677,   2.2985, 682.0000])\n",
      "output:tensor([223333.4688])\n",
      "Batch Average Reconstruciton Loss:3239719168.0\n",
      "input:tensor([  3.8440,   2.8145,   2.7219,   2.7555, 682.0000])\n",
      "output:tensor([223311.8281])\n",
      "Batch Average Reconstruciton Loss:1207782912.0\n",
      "input:tensor([  3.7967,   2.2270,   2.8874,   2.1630, 682.0000])\n",
      "output:tensor([223331.6875])\n",
      "Batch Average Reconstruciton Loss:1440226176.0\n",
      "input:tensor([  4.7713,   2.2155,   4.0970,   2.1805, 682.0000])\n",
      "output:tensor([223308.0312])\n",
      "Batch Average Reconstruciton Loss:237160960.0\n",
      "input:tensor([  4.0537,   2.3670,   3.0902,   2.3320, 682.0000])\n",
      "output:tensor([223321.0312])\n",
      "Batch Average Reconstruciton Loss:457787488.0\n",
      "input:tensor([  3.8730,   1.8605,   3.2443,   1.8425, 682.0000])\n",
      "output:tensor([223338.9688])\n",
      "Batch Average Reconstruciton Loss:1075382912.0\n",
      "input:tensor([ 12.7480,   9.0015,   9.0675,   8.8735, 682.0000])\n",
      "output:tensor([222930.])\n",
      "Batch Average Reconstruciton Loss:21058072576.0\n",
      "input:tensor([  3.9853,   1.9455,   3.3169,   1.9275, 682.0000])\n",
      "output:tensor([223333.9688])\n",
      "Batch Average Reconstruciton Loss:654286848.0\n",
      "input:tensor([  4.0740,   2.6905,   2.8012,   2.5635, 682.0000])\n",
      "output:tensor([223314.6875])\n",
      "Batch Average Reconstruciton Loss:407245024.0\n",
      "input:tensor([ 10.6427,   3.1850,  10.6234,   3.1150, 682.0000])\n",
      "output:tensor([223141.9688])\n",
      "Batch Average Reconstruciton Loss:16882316288.0\n",
      "input:tensor([  4.3407,   3.5475,   1.7734,   3.5105, 682.0000])\n",
      "output:tensor([223290.])\n",
      "Batch Average Reconstruciton Loss:27520516.0\n",
      "input:tensor([  3.4010,   2.6400,   2.4022,   2.5490, 682.0000])\n",
      "output:tensor([223327.0156])\n",
      "Batch Average Reconstruciton Loss:4671993856.0\n",
      "input:tensor([  3.8713,   2.3720,   2.9005,   2.3180, 682.0000])\n",
      "output:tensor([223325.3125])\n",
      "Batch Average Reconstruciton Loss:1083508352.0\n",
      "input:tensor([  3.8067,   2.2685,   2.8874,   2.2015, 682.0000])\n",
      "output:tensor([223330.1719])\n",
      "Batch Average Reconstruciton Loss:1388667392.0\n",
      "input:tensor([  3.8593,   1.7925,   3.2955,   1.7325, 682.0000])\n",
      "output:tensor([223342.0469])\n",
      "Batch Average Reconstruciton Loss:1135484672.0\n",
      "input:tensor([  4.0243,   2.0705,   3.2553,   2.0645, 682.0000])\n",
      "output:tensor([223329.4219])\n",
      "Batch Average Reconstruciton Loss:536875712.0\n",
      "input:tensor([  3.5423,   1.8840,   2.8535,   1.8050, 682.0000])\n",
      "output:tensor([223347.3594])\n",
      "Batch Average Reconstruciton Loss:3214168832.0\n",
      "input:tensor([  4.9950,   1.8065,   4.7759,   1.7895, 682.0000])\n",
      "output:tensor([223312.5469])\n",
      "Batch Average Reconstruciton Loss:610759424.0\n",
      "input:tensor([  3.7877,   2.2320,   2.8748,   2.1970, 682.0000])\n",
      "output:tensor([223331.0156])\n",
      "Batch Average Reconstruciton Loss:1487798016.0\n",
      "input:tensor([  9.8503,   2.7505,  10.3355,   2.7115, 682.0000])\n",
      "output:tensor([223168.2031])\n",
      "Batch Average Reconstruciton Loss:14996746240.0\n",
      "input:tensor([  4.4040,   2.1610,   3.6640,   2.1020, 682.0000])\n",
      "output:tensor([223319.1250])\n",
      "Batch Average Reconstruciton Loss:3728278.25\n",
      "input:tensor([  7.2407,   4.2200,   5.5002,   4.1860, 682.0000])\n",
      "output:tensor([223195.1562])\n",
      "Batch Average Reconstruciton Loss:7428915200.0\n",
      "input:tensor([  3.5977,   2.4855,   2.5716,   2.4435, 682.0000])\n",
      "output:tensor([223327.3906])\n",
      "Batch Average Reconstruciton Loss:2746452736.0\n",
      "input:tensor([  3.9470,   2.4390,   2.9458,   2.3790, 682.0000])\n",
      "output:tensor([223321.7812])\n",
      "Batch Average Reconstruciton Loss:784460288.0\n",
      "input:tensor([  4.1723,   2.8340,   3.0086,   2.6970, 682.0000])\n",
      "output:tensor([223306.5469])\n",
      "Batch Average Reconstruciton Loss:208815600.0\n",
      "input:tensor([  4.8573,   2.1645,   4.3050,   1.9865, 682.0000])\n",
      "output:tensor([223310.3125])\n",
      "Batch Average Reconstruciton Loss:364172800.0\n",
      "input:tensor([  3.7857,   2.1965,   2.8957,   2.1605, 682.0000])\n",
      "output:tensor([223332.0938])\n",
      "Batch Average Reconstruciton Loss:1498379392.0\n",
      "input:tensor([  3.6650,   2.6290,   2.6020,   2.5940, 682.0000])\n",
      "output:tensor([223321.0625])\n",
      "Batch Average Reconstruciton Loss:2241732608.0\n",
      "input:tensor([  3.8753,   2.3350,   2.9284,   2.2530, 682.0000])\n",
      "output:tensor([223327.])\n",
      "Batch Average Reconstruciton Loss:1066087808.0\n",
      "input:tensor([  3.7890,   2.2790,   2.8642,   2.1480, 682.0000])\n",
      "output:tensor([223331.8438])\n",
      "Batch Average Reconstruciton Loss:1480645504.0\n",
      "input:tensor([  4.2093,   2.8915,   3.0204,   2.8345, 682.0000])\n",
      "output:tensor([223301.9531])\n",
      "Batch Average Reconstruciton Loss:152894384.0\n",
      "input:tensor([  3.8107,   2.3080,   2.8754,   2.2660, 682.0000])\n",
      "output:tensor([223328.2188])\n",
      "Batch Average Reconstruciton Loss:1368539904.0\n",
      "input:tensor([  3.5667,   2.4150,   2.5731,   2.3460, 682.0000])\n",
      "output:tensor([223330.9062])\n",
      "Batch Average Reconstruciton Loss:3003050240.0\n",
      "input:tensor([  4.5693,   2.7890,   3.4249,   2.7150, 682.0000])\n",
      "output:tensor([223297.8750])\n",
      "Batch Average Reconstruciton Loss:38413656.0\n",
      "input:tensor([  4.8383,   2.7975,   3.7004,   2.7565, 682.0000])\n",
      "output:tensor([223290.9688])\n",
      "Batch Average Reconstruciton Loss:333499488.0\n",
      "input:tensor([  6.3117,   6.0195,   4.8992,   5.9785, 682.0000])\n",
      "output:tensor([223147.3750])\n",
      "Batch Average Reconstruciton Loss:4353145856.0\n",
      "input:tensor([  4.2560,   2.6155,   3.2100,   2.4505, 682.0000])\n",
      "output:tensor([223312.])\n",
      "Batch Average Reconstruciton Loss:95472440.0\n",
      "input:tensor([  3.7350,   2.1410,   2.8663,   2.0200, 682.0000])\n",
      "output:tensor([223337.0469])\n",
      "Batch Average Reconstruciton Loss:1785819136.0\n",
      "input:tensor([  4.5163,   1.7080,   4.2460,   1.6650, 682.0000])\n",
      "output:tensor([223327.4688])\n",
      "Batch Average Reconstruciton Loss:13545850.0\n",
      "input:tensor([  3.5130,   2.3190,   2.5496,   2.2590, 682.0000])\n",
      "output:tensor([223334.9375])\n",
      "Batch Average Reconstruciton Loss:3486319360.0\n",
      "input:tensor([  4.0010,   2.0420,   3.2546,   2.0230, 682.0000])\n",
      "output:tensor([223331.0469])\n",
      "Batch Average Reconstruciton Loss:605502144.0\n",
      "input:tensor([  6.3440,   4.3015,   2.8917,   4.2415, 682.0000])\n",
      "output:tensor([223230.4062])\n",
      "Batch Average Reconstruciton Loss:4470581248.0\n",
      "input:tensor([  4.4533,   2.7765,   3.2967,   2.7165, 682.0000])\n",
      "output:tensor([223300.5938])\n",
      "Batch Average Reconstruciton Loss:298764.71875\n",
      "input:tensor([ 16.6957,   2.1220,  20.7167,   2.0880, 682.0000])\n",
      "output:tensor([223006.5000])\n",
      "Batch Average Reconstruciton Loss:26761525248.0\n",
      "input:tensor([  3.6473,   2.1005,   2.8194,   1.9965, 682.0000])\n",
      "output:tensor([223339.5000])\n",
      "Batch Average Reconstruciton Loss:2365898240.0\n",
      "input:tensor([ 38.2617,  29.3255,  23.0641,  29.3185, 682.0000])\n",
      "output:tensor([221780.1094])\n",
      "Batch Average Reconstruciton Loss:38358441984.0\n",
      "input:tensor([  4.8907,   2.3815,   4.0767,   2.3215, 682.0000])\n",
      "output:tensor([223301.6875])\n",
      "Batch Average Reconstruciton Loss:418885312.0\n",
      "input:tensor([  3.5677,   2.3335,   2.4706,   2.1715, 682.0000])\n",
      "output:tensor([223337.2344])\n",
      "Batch Average Reconstruciton Loss:2993815040.0\n",
      "input:tensor([  4.9770,   3.0735,   3.7048,   3.0035, 682.0000])\n",
      "output:tensor([223280.2969])\n",
      "Batch Average Reconstruciton Loss:574239616.0\n",
      "input:tensor([  9.2993,   4.4250,   7.8175,   4.3900, 682.0000])\n",
      "output:tensor([223141.1562])\n",
      "Batch Average Reconstruciton Loss:13564598272.0\n",
      "input:tensor([  3.6590,   2.5170,   2.6165,   2.4810, 682.0000])\n",
      "output:tensor([223324.9844])\n",
      "Batch Average Reconstruciton Loss:2283598848.0\n",
      "input:tensor([  3.6080,   2.3085,   1.8608,   2.2495, 682.0000])\n",
      "output:tensor([223341.6719])\n",
      "Batch Average Reconstruciton Loss:2662903552.0\n",
      "input:tensor([  3.9803,   2.0300,   3.2654,   1.9220, 682.0000])\n",
      "output:tensor([223333.8281])\n",
      "Batch Average Reconstruciton Loss:670352768.0\n",
      "input:tensor([  3.9560,   2.5205,   2.9107,   2.5035, 682.0000])\n",
      "output:tensor([223318.0938])\n",
      "Batch Average Reconstruciton Loss:752948480.0\n",
      "input:tensor([  4.2090,   2.1825,   3.3928,   2.1125, 682.0000])\n",
      "output:tensor([223323.6094])\n",
      "Batch Average Reconstruciton Loss:152803984.0\n",
      "input:tensor([ 33.6663,  47.7960,  43.8132,  47.7620, 682.0000])\n",
      "output:tensor([220947.5312])\n",
      "Batch Average Reconstruciton Loss:36665176064.0\n",
      "input:tensor([  3.6267,   2.4230,   2.6159,   2.3790, 682.0000])\n",
      "output:tensor([223328.8906])\n",
      "Batch Average Reconstruciton Loss:2520050944.0\n",
      "input:tensor([  8.1333,   5.2720,   5.9166,   5.2110, 682.0000])\n",
      "output:tensor([223144.3281])\n",
      "Batch Average Reconstruciton Loss:10236852224.0\n",
      "input:tensor([ 29.7623,  24.3025,  18.2513,  24.1105, 682.0000])\n",
      "output:tensor([222106.])\n",
      "Batch Average Reconstruciton Loss:35635998720.0\n",
      "input:tensor([  3.4153,   2.1775,   2.5098,   2.1115, 682.0000])\n",
      "output:tensor([223341.5938])\n",
      "Batch Average Reconstruciton Loss:4504209408.0\n",
      "input:tensor([  5.5467,   3.8830,   3.9504,   3.8490, 682.0000])\n",
      "output:tensor([223241.7969])\n",
      "Batch Average Reconstruciton Loss:1970986752.0\n",
      "input:tensor([ 10.0240,   1.7005,  11.9382,   1.5965, 682.0000])\n",
      "output:tensor([223188.2969])\n",
      "Batch Average Reconstruciton Loss:15432172544.0\n",
      "input:tensor([ 18.7013,   4.7565,  20.1556,   4.6945, 682.0000])\n",
      "output:tensor([222897.8281])\n",
      "Batch Average Reconstruciton Loss:28850323456.0\n",
      "input:tensor([  4.0540,   2.6385,   2.9554,   2.6205, 682.0000])\n",
      "output:tensor([223312.3594])\n",
      "Batch Average Reconstruciton Loss:457302848.0\n",
      "input:tensor([  3.7777,   2.2100,   2.8756,   2.1760, 682.0000])\n",
      "output:tensor([223331.8438])\n",
      "Batch Average Reconstruciton Loss:1541673984.0\n",
      "input:tensor([  5.1607,   2.1330,   4.6618,   2.0930, 682.0000])\n",
      "output:tensor([223300.9219])\n",
      "Batch Average Reconstruciton Loss:965837248.0\n",
      "input:tensor([  3.6540,   2.0990,   2.8198,   2.0810, 682.0000])\n",
      "output:tensor([223337.3281])\n",
      "Batch Average Reconstruciton Loss:2318005760.0\n",
      "input:tensor([  3.6470,   2.0425,   2.8557,   1.9645, 682.0000])\n",
      "output:tensor([223340.5469])\n",
      "Batch Average Reconstruciton Loss:2368131584.0\n",
      "input:tensor([  3.4093,   2.1730,   2.5110,   2.0910, 682.0000])\n",
      "output:tensor([223342.1875])\n",
      "Batch Average Reconstruciton Loss:4572980224.0\n",
      "input:tensor([  5.8657,   3.2660,   3.8376,   3.2050, 682.0000])\n",
      "output:tensor([223262.3438])\n",
      "Batch Average Reconstruciton Loss:2931393280.0\n",
      "input:tensor([  3.8720,   2.2655,   2.9452,   2.2215, 682.0000])\n",
      "output:tensor([223328.3750])\n",
      "Batch Average Reconstruciton Loss:1080412288.0\n",
      "input:tensor([  4.1770,   2.2965,   3.3075,   2.1095, 682.0000])\n",
      "output:tensor([223323.7344])\n",
      "Batch Average Reconstruciton Loss:200711408.0\n",
      "input:tensor([  3.5960,   2.4860,   2.5797,   2.3700, 682.0000])\n",
      "output:tensor([223329.1719])\n",
      "Batch Average Reconstruciton Loss:2759697920.0\n",
      "input:tensor([ 22.7167,   3.1550,  27.8644,   3.1020, 682.0000])\n",
      "output:tensor([222829.5312])\n",
      "Batch Average Reconstruciton Loss:32098854912.0\n",
      "input:tensor([  4.4933,   2.7365,   2.7914,   2.7315, 682.0000])\n",
      "output:tensor([223305.6250])\n",
      "Batch Average Reconstruciton Loss:6419255.5\n",
      "input:tensor([  4.7587,   3.1555,   3.4342,   3.1495, 682.0000])\n",
      "output:tensor([223280.9844])\n",
      "Batch Average Reconstruciton Loss:219602304.0\n",
      "input:tensor([  3.6173,   2.4880,   2.5926,   2.4210, 682.0000])\n",
      "output:tensor([223327.4844])\n",
      "Batch Average Reconstruciton Loss:2591575040.0\n",
      "input:tensor([  4.2650,   2.5600,   3.2071,   2.5250, 682.0000])\n",
      "output:tensor([223310.6719])\n",
      "Batch Average Reconstruciton Loss:86124488.0\n",
      "input:tensor([  3.6160,   1.9320,   2.9026,   1.8950, 682.0000])\n",
      "output:tensor([223343.2812])\n",
      "Batch Average Reconstruciton Loss:2600257280.0\n",
      "input:tensor([  5.0007,   4.2105,   3.6002,   4.2045, 682.0000])\n",
      "output:tensor([223238.9531])\n",
      "Batch Average Reconstruciton Loss:618265920.0\n",
      "input:tensor([  4.4753,   3.8040,   1.7006,   3.7480, 682.0000])\n",
      "output:tensor([223280.6719])\n",
      "Batch Average Reconstruciton Loss:2629819.75\n",
      "input:tensor([  3.8847,   2.4130,   2.8784,   2.3680, 682.0000])\n",
      "output:tensor([223323.7031])\n",
      "Batch Average Reconstruciton Loss:1026516544.0\n",
      "input:tensor([  4.3710,   3.0890,   3.1065,   3.0500, 682.0000])\n",
      "output:tensor([223291.8125])\n",
      "Batch Average Reconstruciton Loss:13382336.0\n",
      "input:tensor([  3.8913,   1.8765,   3.2652,   1.8485, 682.0000])\n",
      "output:tensor([223338.2344])\n",
      "Batch Average Reconstruciton Loss:997723776.0\n",
      "input:tensor([ 38.2313,   2.3475,  50.8748,   2.2725, 682.0000])\n",
      "output:tensor([222447.4531])\n",
      "Batch Average Reconstruciton Loss:38612426752.0\n",
      "input:tensor([  4.6830,   3.5970,   3.3075,   3.5630, 682.0000])\n",
      "output:tensor([223268.0781])\n",
      "Batch Average Reconstruciton Loss:130829632.0\n",
      "input:tensor([  9.0180,   2.6215,   9.3549,   2.5805, 682.0000])\n",
      "output:tensor([223192.2188])\n",
      "Batch Average Reconstruciton Loss:12812025856.0\n",
      "input:tensor([  3.5760,   1.9875,   2.7941,   1.9505, 682.0000])\n",
      "output:tensor([223342.9062])\n",
      "Batch Average Reconstruciton Loss:2922710016.0\n",
      "input:tensor([  8.0803,   6.4625,   2.9340,   6.3845, 682.0000])\n",
      "output:tensor([223134.7812])\n",
      "Batch Average Reconstruciton Loss:10073691136.0\n",
      "input:tensor([  4.4157,   3.1660,   3.1317,   3.1330, 682.0000])\n",
      "output:tensor([223288.1875])\n",
      "Batch Average Reconstruciton Loss:1868176.375\n",
      "input:tensor([  3.4897,   1.8215,   2.8529,   1.7195, 682.0000])\n",
      "output:tensor([223350.7500])\n",
      "Batch Average Reconstruciton Loss:3710911232.0\n",
      "input:tensor([  4.3907,   2.8680,   3.2210,   2.6810, 682.0000])\n",
      "output:tensor([223302.])\n",
      "Batch Average Reconstruciton Loss:6927424.0\n",
      "input:tensor([  3.4900,   1.7820,   2.8595,   1.7640, 682.0000])\n",
      "output:tensor([223349.9688])\n",
      "Batch Average Reconstruciton Loss:3707717632.0\n",
      "input:tensor([  3.7540,   2.1770,   2.8755,   2.1430, 682.0000])\n",
      "output:tensor([223333.2969])\n",
      "Batch Average Reconstruciton Loss:1674258432.0\n",
      "input:tensor([  3.5350,   1.8720,   2.8341,   1.8370, 682.0000])\n",
      "output:tensor([223346.9688])\n",
      "Batch Average Reconstruciton Loss:3280429312.0\n",
      "input:tensor([  4.9593,   2.9625,   3.2604,   2.8895, 682.0000])\n",
      "output:tensor([223289.2812])\n",
      "Batch Average Reconstruciton Loss:541133760.0\n",
      "input:tensor([  3.9150,   2.3985,   2.9121,   2.3595, 682.0000])\n",
      "output:tensor([223323.4062])\n",
      "Batch Average Reconstruciton Loss:903639296.0\n",
      "input:tensor([  8.8050,  10.4005,   8.7491,  10.3815, 682.0000])\n",
      "output:tensor([222922.6094])\n",
      "Batch Average Reconstruciton Loss:12157181952.0\n",
      "input:tensor([  3.4923,   1.7725,   2.8341,   1.7655, 682.0000])\n",
      "output:tensor([223350.2812])\n",
      "Batch Average Reconstruciton Loss:3684577280.0\n",
      "input:tensor([  4.1813,   2.3305,   3.2702,   2.3245, 682.0000])\n",
      "output:tensor([223318.3281])\n",
      "Batch Average Reconstruciton Loss:193952192.0\n",
      "input:tensor([  3.7990,   1.7245,   3.2844,   1.6905, 682.0000])\n",
      "output:tensor([223344.5938])\n",
      "Batch Average Reconstruciton Loss:1427056896.0\n",
      "input:tensor([  6.2140,   2.6100,   5.5516,   2.5490, 682.0000])\n",
      "output:tensor([223263.6875])\n",
      "Batch Average Reconstruciton Loss:4047973632.0\n",
      "input:tensor([  3.5197,   1.8085,   2.8610,   1.7735, 682.0000])\n",
      "output:tensor([223349.1094])\n",
      "Batch Average Reconstruciton Loss:3421769216.0\n",
      "input:tensor([  4.3513,   3.1155,   3.0835,   3.1105, 682.0000])\n",
      "output:tensor([223290.4688])\n",
      "Batch Average Reconstruciton Loss:21954204.0\n",
      "input:tensor([  4.2040,   2.8405,   3.0292,   2.7645, 682.0000])\n",
      "output:tensor([223304.2188])\n",
      "Batch Average Reconstruciton Loss:160320704.0\n",
      "input:tensor([ 25.3367,  19.5835,  13.9782,  19.4785, 682.0000])\n",
      "output:tensor([222365.1562])\n",
      "Batch Average Reconstruciton Loss:33566693376.0\n",
      "input:tensor([  4.0787,   2.4620,   3.0709,   2.4230, 682.0000])\n",
      "output:tensor([223317.6875])\n",
      "Batch Average Reconstruciton Loss:395982624.0\n",
      "input:tensor([ 19.6670,   2.9750,  23.7381,   2.9430, 682.0000])\n",
      "output:tensor([222912.0625])\n",
      "Batch Average Reconstruciton Loss:29746612224.0\n",
      "input:tensor([  3.5610,   2.3615,   2.5838,   2.2945, 682.0000])\n",
      "output:tensor([223332.7031])\n",
      "Batch Average Reconstruciton Loss:3051490304.0\n",
      "input:tensor([ 14.3933,   2.5725,  16.7468,   2.5155, 682.0000])\n",
      "output:tensor([223058.])\n",
      "Batch Average Reconstruciton Loss:23758215168.0\n",
      "input:tensor([  3.7617,   2.1525,   2.9003,   2.1115, 682.0000])\n",
      "output:tensor([223333.9844])\n",
      "Batch Average Reconstruciton Loss:1630464896.0\n",
      "input:tensor([  3.3127,   2.0350,   2.4769,   1.9240, 682.0000])\n",
      "output:tensor([223349.2656])\n",
      "Batch Average Reconstruciton Loss:5792387072.0\n",
      "input:tensor([  5.1283,   2.8240,   4.0148,   2.7890, 682.0000])\n",
      "output:tensor([223283.4062])\n",
      "Batch Average Reconstruciton Loss:890927360.0\n",
      "input:tensor([  5.0497,   3.5325,   2.3073,   3.5275, 682.0000])\n",
      "output:tensor([223276.4844])\n",
      "Batch Average Reconstruciton Loss:719713920.0\n",
      "input:tensor([  4.7903,   2.6885,   3.0663,   2.6285, 682.0000])\n",
      "output:tensor([223302.6406])\n",
      "Batch Average Reconstruciton Loss:263044304.0\n",
      "input:tensor([  5.7130,   3.0655,   4.5202,   3.0315, 682.0000])\n",
      "output:tensor([223263.1250])\n",
      "Batch Average Reconstruciton Loss:2462553856.0\n",
      "input:tensor([ 11.4787,   2.7470,  12.4610,   2.6520, 682.0000])\n",
      "output:tensor([223129.6562])\n",
      "Batch Average Reconstruciton Loss:18689257472.0\n",
      "input:tensor([  4.1763,   2.1975,   3.3433,   2.1805, 682.0000])\n",
      "output:tensor([223322.6250])\n",
      "Batch Average Reconstruciton Loss:201821088.0\n",
      "input:tensor([  4.6247,   3.0645,   3.3515,   3.0305, 682.0000])\n",
      "output:tensor([223287.2344])\n",
      "Batch Average Reconstruciton Loss:77180344.0\n",
      "input:tensor([  3.7467,   2.1535,   2.8905,   2.1175, 682.0000])\n",
      "output:tensor([223334.0781])\n",
      "Batch Average Reconstruciton Loss:1716852736.0\n",
      "input:tensor([  5.3277,   4.0130,   1.9917,   3.9510, 682.0000])\n",
      "output:tensor([223261.2031])\n",
      "Batch Average Reconstruciton Loss:1373681024.0\n",
      "input:tensor([  8.3970,   3.3310,   7.7255,   3.2510, 682.0000])\n",
      "output:tensor([223191.9219])\n",
      "Batch Average Reconstruciton Loss:11036536832.0\n",
      "input:tensor([  3.9547,   2.5185,   2.9080,   2.4805, 682.0000])\n",
      "output:tensor([223318.7344])\n",
      "Batch Average Reconstruciton Loss:757585216.0\n",
      "input:tensor([  3.5663,   2.4250,   2.5568,   2.3900, 682.0000])\n",
      "output:tensor([223329.8438])\n",
      "Batch Average Reconstruciton Loss:3006017024.0\n",
      "input:tensor([  3.8803,   2.3080,   2.9279,   2.2680, 682.0000])\n",
      "output:tensor([223326.8750])\n",
      "Batch Average Reconstruciton Loss:1044655104.0\n",
      "input:tensor([  3.9207,   2.4165,   2.9256,   2.3465, 682.0000])\n",
      "output:tensor([223323.3125])\n",
      "Batch Average Reconstruciton Loss:881774464.0\n",
      "input:tensor([  4.5267,   3.2930,   2.5149,   3.2580, 682.0000])\n",
      "output:tensor([223289.1094])\n",
      "Batch Average Reconstruciton Loss:17165356.0\n",
      "input:tensor([  4.0210,   2.0610,   3.2620,   2.0270, 682.0000])\n",
      "output:tensor([223330.4688])\n",
      "Batch Average Reconstruciton Loss:546368704.0\n",
      "input:tensor([  4.3513,   3.0220,   2.0254,   3.0170, 682.0000])\n",
      "output:tensor([223305.1406])\n",
      "Batch Average Reconstruciton Loss:21816928.0\n",
      "input:tensor([  3.9080,   2.9215,   2.7622,   2.8815, 682.0000])\n",
      "output:tensor([223306.4375])\n",
      "Batch Average Reconstruciton Loss:932176320.0\n",
      "input:tensor([  3.7813,   2.1875,   2.9164,   2.1425, 682.0000])\n",
      "output:tensor([223332.4688])\n",
      "Batch Average Reconstruciton Loss:1521665536.0\n",
      "input:tensor([  5.1007,   4.2465,   2.2026,   4.1645, 682.0000])\n",
      "output:tensor([223253.5000])\n",
      "Batch Average Reconstruciton Loss:827684160.0\n",
      "input:tensor([  4.6217,   2.4390,   3.6930,   2.4220, 682.0000])\n",
      "output:tensor([223305.5312])\n",
      "Batch Average Reconstruciton Loss:75074104.0\n",
      "input:tensor([  3.6337,   2.0605,   2.8190,   2.0015, 682.0000])\n",
      "output:tensor([223339.9688])\n",
      "Batch Average Reconstruciton Loss:2466317312.0\n",
      "input:tensor([  3.9280,   2.5260,   2.8686,   2.4920, 682.0000])\n",
      "output:tensor([223319.0469])\n",
      "Batch Average Reconstruciton Loss:854214784.0\n",
      "input:tensor([  3.4243,   2.1925,   2.5131,   2.1505, 682.0000])\n",
      "output:tensor([223340.3125])\n",
      "Batch Average Reconstruciton Loss:4402413568.0\n",
      "input:tensor([  3.7197,   2.5550,   2.6601,   2.5190, 682.0000])\n",
      "output:tensor([223322.5156])\n",
      "Batch Average Reconstruciton Loss:1880825472.0\n",
      "input:tensor([  4.6437,   3.0060,   3.3801,   2.9880, 682.0000])\n",
      "output:tensor([223288.4062])\n",
      "Batch Average Reconstruciton Loss:93400752.0\n",
      "input:tensor([  4.9253,   2.4375,   4.0658,   2.4025, 682.0000])\n",
      "output:tensor([223298.8125])\n",
      "Batch Average Reconstruciton Loss:479207680.0\n",
      "input:tensor([  3.9503,   2.3860,   2.9698,   2.3790, 682.0000])\n",
      "output:tensor([223322.0469])\n",
      "Batch Average Reconstruciton Loss:772615040.0\n",
      "input:tensor([  3.4227,   2.1395,   2.5414,   2.0725, 682.0000])\n",
      "output:tensor([223342.5625])\n",
      "Batch Average Reconstruciton Loss:4420845056.0\n",
      "input:tensor([  3.5150,   2.3055,   2.5531,   2.2605, 682.0000])\n",
      "output:tensor([223334.9688])\n",
      "Batch Average Reconstruciton Loss:3467329024.0\n",
      "input:tensor([  4.0713,   2.1575,   3.2619,   2.0875, 682.0000])\n",
      "output:tensor([223327.3750])\n",
      "Batch Average Reconstruciton Loss:413212352.0\n",
      "input:tensor([  4.7400,   2.8245,   3.5753,   2.7645, 682.0000])\n",
      "output:tensor([223292.8594])\n",
      "Batch Average Reconstruciton Loss:196276160.0\n",
      "input:tensor([  3.6823,   2.1250,   2.8172,   2.0920, 682.0000])\n",
      "output:tensor([223336.4844])\n",
      "Batch Average Reconstruciton Loss:2121294720.0\n",
      "input:tensor([ 10.4010,   8.1420,   7.3676,   8.1250, 682.0000])\n",
      "output:tensor([223001.0781])\n",
      "Batch Average Reconstruciton Loss:16288415744.0\n",
      "input:tensor([  3.2093,   1.8190,   2.4832,   1.8140, 682.0000])\n",
      "output:tensor([223355.3438])\n",
      "Batch Average Reconstruciton Loss:7351802880.0\n",
      "input:tensor([  3.7473,   2.6420,   2.6710,   2.5790, 682.0000])\n",
      "output:tensor([223319.6719])\n",
      "Batch Average Reconstruciton Loss:1714152832.0\n",
      "input:tensor([  3.7770,   2.1765,   2.9018,   2.1165, 682.0000])\n",
      "output:tensor([223333.4375])\n",
      "Batch Average Reconstruciton Loss:1545163136.0\n",
      "input:tensor([  3.9370,   2.3380,   2.9877,   2.2720, 682.0000])\n",
      "output:tensor([223325.2031])\n",
      "Batch Average Reconstruciton Loss:820467072.0\n",
      "input:tensor([  5.4517,   5.2360,   4.2609,   5.1740, 682.0000])\n",
      "output:tensor([223191.8594])\n",
      "Batch Average Reconstruciton Loss:1699818880.0\n",
      "input:tensor([  5.7180,   4.6225,   4.0660,   4.5795, 682.0000])\n",
      "output:tensor([223212.5625])\n",
      "Batch Average Reconstruciton Loss:2472631552.0\n",
      "input:tensor([  3.4433,   1.6660,   2.8583,   1.6300, 682.0000])\n",
      "output:tensor([223355.0469])\n",
      "Batch Average Reconstruciton Loss:4191002624.0\n",
      "input:tensor([  5.0707,   3.0920,   3.7799,   3.0570, 682.0000])\n",
      "output:tensor([223276.9688])\n",
      "Batch Average Reconstruciton Loss:764078464.0\n",
      "input:tensor([  4.0497,   2.1360,   3.2548,   2.0910, 682.0000])\n",
      "output:tensor([223327.8438])\n",
      "Batch Average Reconstruciton Loss:467863648.0\n",
      "input:tensor([  7.6890,   4.3455,   5.9208,   4.3285, 682.0000])\n",
      "output:tensor([223180.9688])\n",
      "Batch Average Reconstruciton Loss:8867229696.0\n",
      "input:tensor([  3.7947,   2.7230,   1.6203,   2.7180, 682.0000])\n",
      "output:tensor([223326.0938])\n",
      "Batch Average Reconstruciton Loss:1451145728.0\n",
      "input:tensor([  3.7373,   2.0850,   2.9295,   2.0670, 682.0000])\n",
      "output:tensor([223335.7812])\n",
      "Batch Average Reconstruciton Loss:1771923200.0\n",
      "input:tensor([  3.7163,   2.1335,   2.8700,   2.0305, 682.0000])\n",
      "output:tensor([223337.0469])\n",
      "Batch Average Reconstruciton Loss:1900345600.0\n",
      "input:tensor([  3.3127,   1.9270,   2.5340,   1.8920, 682.0000])\n",
      "output:tensor([223350.5938])\n",
      "Batch Average Reconstruciton Loss:5792184832.0\n",
      "input:tensor([  4.1660,   1.7865,   3.6948,   1.7515, 682.0000])\n",
      "output:tensor([223334.1250])\n",
      "Batch Average Reconstruciton Loss:218562960.0\n",
      "input:tensor([  4.6790,   3.4020,   2.0757,   3.3380, 682.0000])\n",
      "output:tensor([223289.0625])\n",
      "Batch Average Reconstruciton Loss:127194696.0\n",
      "input:tensor([ 22.2973,   3.8455,  26.3537,   3.7755, 682.0000])\n",
      "output:tensor([222825.9531])\n",
      "Batch Average Reconstruciton Loss:31803711488.0\n",
      "input:tensor([  4.9000,   4.2415,   3.5571,   4.1785, 682.0000])\n",
      "output:tensor([223240.8125])\n",
      "Batch Average Reconstruciton Loss:432299456.0\n",
      "input:tensor([  4.5903,   3.0375,   2.2713,   3.0185, 682.0000])\n",
      "output:tensor([223299.7812])\n",
      "Batch Average Reconstruciton Loss:51750488.0\n",
      "input:tensor([  3.9817,   2.5925,   2.8947,   2.5865, 682.0000])\n",
      "output:tensor([223315.1094])\n",
      "Batch Average Reconstruciton Loss:667028288.0\n",
      "input:tensor([  3.5303,   2.3485,   2.5603,   2.2735, 682.0000])\n",
      "output:tensor([223333.9375])\n",
      "Batch Average Reconstruciton Loss:3324567552.0\n",
      "input:tensor([  4.3307,   3.1650,   3.0688,   3.0860, 682.0000])\n",
      "output:tensor([223290.9375])\n",
      "Batch Average Reconstruciton Loss:33328250.0\n",
      "input:tensor([  4.9443,   3.3925,   2.1988,   3.3755, 682.0000])\n",
      "output:tensor([223284.0625])\n",
      "Batch Average Reconstruciton Loss:513025344.0\n",
      "input:tensor([  3.4950,   1.8440,   2.8475,   1.7400, 682.0000])\n",
      "output:tensor([223349.9844])\n",
      "Batch Average Reconstruciton Loss:3658316032.0\n",
      "input:tensor([  4.6943,   3.5630,   3.3182,   3.4960, 682.0000])\n",
      "output:tensor([223269.8750])\n",
      "Batch Average Reconstruciton Loss:142823408.0\n",
      "input:tensor([ 12.6197,   2.8080,  14.1469,   2.7010, 682.0000])\n",
      "output:tensor([223097.5781])\n",
      "Batch Average Reconstruciton Loss:20877527040.0\n",
      "input:tensor([  3.5463,   1.8850,   2.8501,   1.8450, 682.0000])\n",
      "output:tensor([223346.3438])\n",
      "Batch Average Reconstruciton Loss:3178665728.0\n",
      "input:tensor([  3.0290,   2.0765,   2.1707,   2.0345, 682.0000])\n",
      "output:tensor([223352.3438])\n",
      "Batch Average Reconstruciton Loss:10846942208.0\n",
      "input:tensor([  5.5733,   3.9285,   3.9902,   3.7405, 682.0000])\n",
      "output:tensor([223243.3125])\n",
      "Batch Average Reconstruciton Loss:2047862272.0\n",
      "input:tensor([  3.8317,   2.7665,   2.0711,   2.6645, 682.0000])\n",
      "output:tensor([223321.7500])\n",
      "Batch Average Reconstruciton Loss:1265456128.0\n",
      "input:tensor([  5.4267,   3.0885,   4.1705,   3.0715, 682.0000])\n",
      "output:tensor([223268.6719])\n",
      "Batch Average Reconstruciton Loss:1637632512.0\n",
      "input:tensor([  4.1027,   2.7270,   2.9672,   2.6920, 682.0000])\n",
      "output:tensor([223308.9688])\n",
      "Batch Average Reconstruciton Loss:341696384.0\n",
      "input:tensor([  5.9457,   3.0380,   4.8508,   2.9610, 682.0000])\n",
      "output:tensor([223259.1562])\n",
      "Batch Average Reconstruciton Loss:3182669824.0\n",
      "input:tensor([  5.7117,   3.7680,   4.1443,   3.7030, 682.0000])\n",
      "output:tensor([223242.8594])\n",
      "Batch Average Reconstruciton Loss:2456476928.0\n",
      "input:tensor([  3.5833,   1.9195,   2.8552,   1.8855, 682.0000])\n",
      "output:tensor([223344.5312])\n",
      "Batch Average Reconstruciton Loss:2861444096.0\n",
      "input:tensor([  4.3623,   2.4555,   3.3838,   2.4215, 682.0000])\n",
      "output:tensor([223311.4062])\n",
      "Batch Average Reconstruciton Loss:16724777.0\n",
      "input:tensor([  3.6840,   1.8665,   3.0470,   1.7625, 682.0000])\n",
      "output:tensor([223345.0625])\n",
      "Batch Average Reconstruciton Loss:2109375488.0\n",
      "input:tensor([  9.2460,   9.3395,   7.5571,   9.2355, 682.0000])\n",
      "output:tensor([222970.7188])\n",
      "Batch Average Reconstruciton Loss:13382028288.0\n",
      "input:tensor([ 16.2277,   4.5615,  17.0672,   4.3785, 682.0000])\n",
      "output:tensor([222967.2500])\n",
      "Batch Average Reconstruciton Loss:26191294464.0\n",
      "input:tensor([  4.6467,   2.3550,   3.7885,   2.3380, 682.0000])\n",
      "output:tensor([223307.2344])\n",
      "Batch Average Reconstruciton Loss:96456648.0\n",
      "input:tensor([  4.6243,   2.9700,   2.4884,   2.8800, 682.0000])\n",
      "output:tensor([223301.2812])\n",
      "Batch Average Reconstruciton Loss:77163600.0\n",
      "input:tensor([ 22.2257,   3.7745,  26.3809,   3.7145, 682.0000])\n",
      "output:tensor([222828.7031])\n",
      "Batch Average Reconstruciton Loss:31753709568.0\n",
      "input:tensor([  4.4620,   3.0330,   3.2106,   2.9660, 682.0000])\n",
      "output:tensor([223292.4375])\n",
      "Batch Average Reconstruciton Loss:941748.9375\n",
      "input:tensor([  3.6190,   2.4315,   2.6054,   2.3965, 682.0000])\n",
      "output:tensor([223328.5469])\n",
      "Batch Average Reconstruciton Loss:2578654464.0\n",
      "input:tensor([  3.5903,   1.8315,   2.9401,   1.7285, 682.0000])\n",
      "output:tensor([223348.4062])\n",
      "Batch Average Reconstruciton Loss:2803553536.0\n",
      "input:tensor([ 37.0033,   5.7570,  44.5316,   5.7410, 682.0000])\n",
      "output:tensor([222405.2344])\n",
      "Batch Average Reconstruciton Loss:38258278400.0\n",
      "input:tensor([  4.1077,   2.1750,   3.3053,   2.1110, 682.0000])\n",
      "output:tensor([223325.7344])\n",
      "Batch Average Reconstruciton Loss:330303936.0\n",
      "input:tensor([  3.3670,   2.0740,   2.5006,   2.0670, 682.0000])\n",
      "output:tensor([223344.4375])\n",
      "Batch Average Reconstruciton Loss:5080776192.0\n",
      "input:tensor([  4.8197,   3.7435,   3.4059,   3.7085, 682.0000])\n",
      "output:tensor([223260.3750])\n",
      "Batch Average Reconstruciton Loss:304062048.0\n",
      "input:tensor([  3.3720,   2.0960,   2.4924,   2.0910, 682.0000])\n",
      "output:tensor([223343.6094])\n",
      "Batch Average Reconstruciton Loss:5018785792.0\n",
      "input:tensor([  4.4437,   3.1845,   3.1564,   3.1175, 682.0000])\n",
      "output:tensor([223287.7969])\n",
      "Batch Average Reconstruciton Loss:2381.135009765625\n",
      "input:tensor([  3.3513,   2.0965,   2.4830,   2.0405, 682.0000])\n",
      "output:tensor([223345.2188])\n",
      "Batch Average Reconstruciton Loss:5279007744.0\n",
      "input:tensor([  3.8750,   2.3370,   2.9287,   2.2960, 682.0000])\n",
      "output:tensor([223325.9219])\n",
      "Batch Average Reconstruciton Loss:1067595392.0\n",
      "input:tensor([  3.3993,   2.3480,   2.4252,   2.3310, 682.0000])\n",
      "output:tensor([223335.3594])\n",
      "Batch Average Reconstruciton Loss:4690419712.0\n",
      "input:tensor([  3.8647,   2.3220,   2.9021,   2.3060, 682.0000])\n",
      "output:tensor([223326.1875])\n",
      "Batch Average Reconstruciton Loss:1112743680.0\n",
      "input:tensor([  3.3230,   1.9670,   2.5158,   1.9260, 682.0000])\n",
      "output:tensor([223349.3906])\n",
      "Batch Average Reconstruciton Loss:5651372032.0\n",
      "input:tensor([  3.6507,   2.4945,   2.6178,   2.4605, 682.0000])\n",
      "output:tensor([223325.7969])\n",
      "Batch Average Reconstruciton Loss:2343063808.0\n",
      "input:tensor([  3.7633,   2.1410,   2.9102,   2.0770, 682.0000])\n",
      "output:tensor([223334.8438])\n",
      "Batch Average Reconstruciton Loss:1620960640.0\n",
      "input:tensor([ 25.9613,  19.5395,  10.9427,  19.4775, 682.0000])\n",
      "output:tensor([222391.5625])\n",
      "Batch Average Reconstruciton Loss:33922480128.0\n",
      "input:tensor([  4.3860,   3.3825,   3.0990,   3.2865, 682.0000])\n",
      "output:tensor([223282.6719])\n",
      "Batch Average Reconstruciton Loss:8359778.5\n",
      "input:tensor([  3.5040,   2.5085,   2.4843,   2.4495, 682.0000])\n",
      "output:tensor([223328.9375])\n",
      "Batch Average Reconstruciton Loss:3573177600.0\n",
      "input:tensor([  5.7850,   4.5320,   4.0924,   4.4550, 682.0000])\n",
      "output:tensor([223215.6562])\n",
      "Batch Average Reconstruciton Loss:2676785152.0\n",
      "input:tensor([ 11.6273,   9.0525,   5.1895,   8.9415, 682.0000])\n",
      "output:tensor([222981.2500])\n",
      "Batch Average Reconstruciton Loss:18951720960.0\n",
      "input:tensor([  3.2947,   1.9505,   2.4953,   1.8905, 682.0000])\n",
      "output:tensor([223350.9844])\n",
      "Batch Average Reconstruciton Loss:6043821056.0\n",
      "input:tensor([ 22.7123,   2.2360,  28.9834,   2.0990, 682.0000])\n",
      "output:tensor([222852.5000])\n",
      "Batch Average Reconstruciton Loss:32103860224.0\n",
      "input:tensor([  4.9090,   2.0270,   4.4394,   1.9900, 682.0000])\n",
      "output:tensor([223309.6875])\n",
      "Batch Average Reconstruciton Loss:450784544.0\n",
      "input:tensor([  3.1260,   1.8455,   2.4098,   1.7415, 682.0000])\n",
      "output:tensor([223358.5625])\n",
      "Batch Average Reconstruciton Loss:8832135168.0\n",
      "input:tensor([ 15.3073,  11.4405,   6.6865,  11.4335, 682.0000])\n",
      "output:tensor([222838.2188])\n",
      "Batch Average Reconstruciton Loss:24974182400.0\n",
      "input:tensor([  3.4820,   1.7955,   2.8596,   1.6915, 682.0000])\n",
      "output:tensor([223351.7344])\n",
      "Batch Average Reconstruciton Loss:3787450368.0\n",
      "input:tensor([  5.0743,   3.6445,   3.5978,   3.6105, 682.0000])\n",
      "output:tensor([223259.1094])\n",
      "Batch Average Reconstruciton Loss:770901312.0\n",
      "input:tensor([  3.4617,   1.7565,   2.8520,   1.6895, 682.0000])\n",
      "output:tensor([223352.4844])\n",
      "Batch Average Reconstruciton Loss:3996075008.0\n",
      "input:tensor([  3.9460,   2.4605,   2.9182,   2.3345, 682.0000])\n",
      "output:tensor([223322.9844])\n",
      "Batch Average Reconstruciton Loss:787981888.0\n",
      "input:tensor([  4.8183,   2.7775,   3.7057,   2.6665, 682.0000])\n",
      "output:tensor([223293.5625])\n",
      "Batch Average Reconstruciton Loss:303232160.0\n",
      "input:tensor([  3.7223,   2.4385,   2.7232,   2.3345, 682.0000])\n",
      "output:tensor([223327.6719])\n",
      "Batch Average Reconstruciton Loss:1863849856.0\n",
      "input:tensor([  3.4770,   1.7840,   2.8456,   1.7040, 682.0000])\n",
      "output:tensor([223351.7344])\n",
      "Batch Average Reconstruciton Loss:3837959424.0\n",
      "input:tensor([  3.7303,   2.1220,   2.8688,   2.1160, 682.0000])\n",
      "output:tensor([223334.8594])\n",
      "Batch Average Reconstruciton Loss:1814175616.0\n",
      "input:tensor([  3.6170,   1.9820,   2.8783,   1.8700, 682.0000])\n",
      "output:tensor([223343.6562])\n",
      "Batch Average Reconstruciton Loss:2592474112.0\n",
      "input:tensor([  4.5583,   2.8570,   2.5204,   2.7620, 682.0000])\n",
      "output:tensor([223305.7969])\n",
      "Batch Average Reconstruciton Loss:32294180.0\n",
      "input:tensor([  3.9783,   2.4420,   2.9582,   2.4360, 682.0000])\n",
      "output:tensor([223319.8594])\n",
      "Batch Average Reconstruciton Loss:677620288.0\n",
      "input:tensor([  4.0297,   2.1125,   3.1358,   1.9525, 682.0000])\n",
      "output:tensor([223333.0312])\n",
      "Batch Average Reconstruciton Loss:521709856.0\n",
      "input:tensor([  3.9553,   2.5775,   2.8746,   2.5605, 682.0000])\n",
      "output:tensor([223316.4375])\n",
      "Batch Average Reconstruciton Loss:755401152.0\n",
      "input:tensor([  4.7390,   3.5060,   3.3492,   3.4630, 682.0000])\n",
      "output:tensor([223270.5000])\n",
      "Batch Average Reconstruciton Loss:194421200.0\n",
      "input:tensor([  4.8847,   2.3740,   4.0687,   2.3300, 682.0000])\n",
      "output:tensor([223301.7031])\n",
      "Batch Average Reconstruciton Loss:408755520.0\n",
      "input:tensor([  4.0470,   2.6945,   2.8143,   2.5485, 682.0000])\n",
      "output:tensor([223315.1562])\n",
      "Batch Average Reconstruciton Loss:475451200.0\n",
      "input:tensor([  4.4153,   3.5145,   3.1283,   3.4755, 682.0000])\n",
      "output:tensor([223275.9219])\n",
      "Batch Average Reconstruciton Loss:1949034.125\n",
      "input:tensor([  3.9050,   2.2530,   3.0138,   2.1920, 682.0000])\n",
      "output:tensor([223328.1719])\n",
      "Batch Average Reconstruciton Loss:942786496.0\n",
      "input:tensor([  3.9710,   2.5165,   2.9204,   2.4785, 682.0000])\n",
      "output:tensor([223318.5000])\n",
      "Batch Average Reconstruciton Loss:701852544.0\n",
      "input:tensor([ 20.3010,   2.4215,  25.3818,   2.3865, 682.0000])\n",
      "output:tensor([222907.5469])\n",
      "Batch Average Reconstruciton Loss:30290808832.0\n",
      "input:tensor([  5.1140,   2.9265,   3.2018,   2.8235, 682.0000])\n",
      "output:tensor([223290.3125])\n",
      "Batch Average Reconstruciton Loss:859270272.0\n",
      "input:tensor([  3.6390,   2.5165,   2.4344,   2.3625, 682.0000])\n",
      "output:tensor([223330.1250])\n",
      "Batch Average Reconstruciton Loss:2427717632.0\n",
      "input:tensor([  3.5347,   2.3880,   2.5575,   2.2850, 682.0000])\n",
      "output:tensor([223333.2188])\n",
      "Batch Average Reconstruciton Loss:3285098752.0\n",
      "input:tensor([  4.3473,   2.5760,   3.2922,   2.5090, 682.0000])\n",
      "output:tensor([223309.0938])\n",
      "Batch Average Reconstruciton Loss:23784214.0\n",
      "input:tensor([  3.8590,   2.3255,   2.9104,   2.3075, 682.0000])\n",
      "output:tensor([223326.1094])\n",
      "Batch Average Reconstruciton Loss:1138042880.0\n",
      "input:tensor([  4.3913,   3.1455,   2.9670,   3.0695, 682.0000])\n",
      "output:tensor([223291.9844])\n",
      "Batch Average Reconstruciton Loss:6796530.5\n",
      "input:tensor([  3.6387,   2.0515,   2.8513,   1.9115, 682.0000])\n",
      "output:tensor([223341.9219])\n",
      "Batch Average Reconstruciton Loss:2429018880.0\n",
      "input:tensor([  4.3007,   1.9990,   3.6656,   1.9650, 682.0000])\n",
      "output:tensor([223325.3594])\n",
      "Batch Average Reconstruciton Loss:53826296.0\n",
      "input:tensor([  3.8643,   2.9210,   2.7295,   2.8570, 682.0000])\n",
      "output:tensor([223307.8594])\n",
      "Batch Average Reconstruciton Loss:1115502592.0\n",
      "input:tensor([  3.6867,   2.5650,   2.6372,   2.5310, 682.0000])\n",
      "output:tensor([223322.7031])\n",
      "Batch Average Reconstruciton Loss:2093547136.0\n",
      "input:tensor([  3.5927,   1.8475,   2.9361,   1.7675, 682.0000])\n",
      "output:tensor([223347.2812])\n",
      "Batch Average Reconstruciton Loss:2784748800.0\n",
      "input:tensor([  3.6173,   2.4805,   2.5894,   2.4765, 682.0000])\n",
      "output:tensor([223326.2031])\n",
      "Batch Average Reconstruciton Loss:2591705600.0\n",
      "input:tensor([  4.5123,   2.1995,   3.7805,   2.1655, 682.0000])\n",
      "output:tensor([223314.7188])\n",
      "Batch Average Reconstruciton Loss:12059776.0\n",
      "input:tensor([  3.6940,   2.6980,   2.6157,   2.6590, 682.0000])\n",
      "output:tensor([223318.2500])\n",
      "Batch Average Reconstruciton Loss:2045368448.0\n",
      "input:tensor([  4.5423,   2.7500,   3.4109,   2.6830, 682.0000])\n",
      "output:tensor([223299.5469])\n",
      "Batch Average Reconstruciton Loss:24103650.0\n",
      "input:tensor([  4.4623,   3.2435,   3.1586,   3.1615, 682.0000])\n",
      "output:tensor([223285.8438])\n",
      "Batch Average Reconstruciton Loss:962054.4375\n",
      "input:tensor([  3.5190,   2.3370,   2.5466,   2.3020, 682.0000])\n",
      "output:tensor([223333.6250])\n",
      "Batch Average Reconstruciton Loss:3429786112.0\n",
      "input:tensor([  3.9010,   1.8340,   3.3113,   1.7990, 682.0000])\n",
      "output:tensor([223339.3281])\n",
      "Batch Average Reconstruciton Loss:958191680.0\n",
      "input:tensor([  4.1890,   1.8335,   3.7044,   1.7635, 682.0000])\n",
      "output:tensor([223332.9531])\n",
      "Batch Average Reconstruciton Loss:181657744.0\n",
      "input:tensor([  5.9763,   2.1435,   5.7140,   2.1035, 682.0000])\n",
      "output:tensor([223280.5938])\n",
      "Batch Average Reconstruciton Loss:3282441216.0\n",
      "input:tensor([  3.4337,   1.7085,   2.8625,   1.5965, 682.0000])\n",
      "output:tensor([223355.5000])\n",
      "Batch Average Reconstruciton Loss:4296605696.0\n",
      "input:tensor([  4.3443,   1.7050,   4.0402,   1.6400, 682.0000])\n",
      "output:tensor([223332.1719])\n",
      "Batch Average Reconstruciton Loss:25108398.0\n",
      "input:tensor([  3.9927,   2.5650,   2.7584,   2.4560, 682.0000])\n",
      "output:tensor([223320.0312])\n",
      "Batch Average Reconstruciton Loss:631816896.0\n",
      "input:tensor([  4.6790,   2.3125,   3.8693,   2.2175, 682.0000])\n",
      "output:tensor([223309.4844])\n",
      "Batch Average Reconstruciton Loss:127655752.0\n",
      "input:tensor([  4.0507,   2.5705,   2.9708,   2.5335, 682.0000])\n",
      "output:tensor([223315.1562])\n",
      "Batch Average Reconstruciton Loss:465819136.0\n",
      "input:tensor([  5.5387,   2.7425,   4.5712,   2.7025, 682.0000])\n",
      "output:tensor([223276.1094])\n",
      "Batch Average Reconstruciton Loss:1951175296.0\n",
      "input:tensor([  3.7647,   2.1650,   2.8809,   2.1470, 682.0000])\n",
      "output:tensor([223333.1562])\n",
      "Batch Average Reconstruciton Loss:1613616384.0\n",
      "input:tensor([  3.6840,   2.0710,   2.8671,   2.0640, 682.0000])\n",
      "output:tensor([223337.2188])\n",
      "Batch Average Reconstruciton Loss:2110096000.0\n",
      "input:tensor([  4.6590,   3.5735,   3.2912,   3.5085, 682.0000])\n",
      "output:tensor([223270.1250])\n",
      "Batch Average Reconstruciton Loss:107104392.0\n",
      "input:tensor([  3.5460,   1.7875,   2.9152,   1.7535, 682.0000])\n",
      "output:tensor([223348.9688])\n",
      "Batch Average Reconstruciton Loss:3181302016.0\n",
      "input:tensor([  4.1680,   3.1230,   2.9426,   3.1160, 682.0000])\n",
      "output:tensor([223293.7188])\n",
      "Batch Average Reconstruciton Loss:216392368.0\n",
      "input:tensor([  3.9767,   2.0240,   3.2563,   1.9580, 682.0000])\n",
      "output:tensor([223333.1094])\n",
      "Batch Average Reconstruciton Loss:682353152.0\n",
      "input:tensor([ 18.4557,  15.2160,  10.5295,  15.1180, 682.0000])\n",
      "output:tensor([222631.0469])\n",
      "Batch Average Reconstruciton Loss:28520808448.0\n",
      "input:tensor([  3.3510,   2.0995,   2.4883,   2.0655, 682.0000])\n",
      "output:tensor([223344.4844])\n",
      "Batch Average Reconstruciton Loss:5283329536.0\n",
      "input:tensor([  3.5060,   2.1030,   2.6523,   2.0690, 682.0000])\n",
      "output:tensor([223340.9375])\n",
      "Batch Average Reconstruciton Loss:3552405760.0\n",
      "input:tensor([ 16.8300,   3.3670,  19.1307,   3.2640, 682.0000])\n",
      "output:tensor([222979.3594])\n",
      "Batch Average Reconstruciton Loss:26908256256.0\n",
      "input:tensor([  3.9127,   2.3795,   2.9203,   2.3445, 682.0000])\n",
      "output:tensor([223323.9219])\n",
      "Batch Average Reconstruciton Loss:912769664.0\n",
      "input:tensor([  3.6443,   2.1330,   2.7610,   2.1280, 682.0000])\n",
      "output:tensor([223336.5312])\n",
      "Batch Average Reconstruciton Loss:2387931648.0\n",
      "input:tensor([  4.8367,   2.8675,   3.6758,   2.7925, 682.0000])\n",
      "output:tensor([223289.5938])\n",
      "Batch Average Reconstruciton Loss:330861312.0\n",
      "input:tensor([  3.6907,   2.0495,   2.8958,   2.0135, 682.0000])\n",
      "output:tensor([223338.3438])\n",
      "Batch Average Reconstruciton Loss:2065489408.0\n",
      "input:tensor([  3.6660,   2.5405,   2.6201,   2.5065, 682.0000])\n",
      "output:tensor([223323.9688])\n",
      "Batch Average Reconstruciton Loss:2234550272.0\n",
      "input:tensor([  5.3537,   4.0590,   2.4908,   3.9890, 682.0000])\n",
      "output:tensor([223254.1094])\n",
      "Batch Average Reconstruciton Loss:1440969856.0\n",
      "input:tensor([  3.4217,   2.2050,   2.5160,   2.1460, 682.0000])\n",
      "output:tensor([223340.3125])\n",
      "Batch Average Reconstruciton Loss:4432455168.0\n",
      "input:tensor([  4.0610,   3.1720,   2.8700,   3.1660, 682.0000])\n",
      "output:tensor([223293.8594])\n",
      "Batch Average Reconstruciton Loss:440208256.0\n",
      "input:tensor([  4.0513,   2.6085,   2.9577,   2.5745, 682.0000])\n",
      "output:tensor([223313.8438])\n",
      "Batch Average Reconstruciton Loss:464150656.0\n",
      "input:tensor([  4.2727,   2.0155,   3.6543,   1.9115, 682.0000])\n",
      "output:tensor([223326.9531])\n",
      "Batch Average Reconstruciton Loss:78252544.0\n",
      "input:tensor([  4.8463,   3.1055,   3.5571,   3.0715, 682.0000])\n",
      "output:tensor([223281.2188])\n",
      "Batch Average Reconstruciton Loss:345596224.0\n",
      "input:tensor([  4.1397,   3.3630,   2.9429,   3.3200, 682.0000])\n",
      "output:tensor([223286.3438])\n",
      "Batch Average Reconstruciton Loss:267213168.0\n",
      "input:tensor([  4.3077,   3.0015,   3.0801,   2.9215, 682.0000])\n",
      "output:tensor([223296.9375])\n",
      "Batch Average Reconstruciton Loss:48860972.0\n",
      "input:tensor([  7.3727,   4.5120,   5.4758,   4.4780, 682.0000])\n",
      "output:tensor([223183.5781])\n",
      "Batch Average Reconstruciton Loss:7855733760.0\n",
      "input:tensor([  4.3490,   3.8335,   3.1883,   3.7985, 682.0000])\n",
      "output:tensor([223264.4688])\n",
      "Batch Average Reconstruciton Loss:23363024.0\n",
      "input:tensor([  4.6397,   2.4720,   3.5634,   2.3450, 682.0000])\n",
      "output:tensor([223308.2969])\n",
      "Batch Average Reconstruciton Loss:90255640.0\n",
      "input:tensor([  8.2323,   6.0100,   3.5244,   6.0040, 682.0000])\n",
      "output:tensor([223141.1875])\n",
      "Batch Average Reconstruciton Loss:10535213056.0\n",
      "input:tensor([  3.4070,   2.1590,   2.5120,   2.0920, 682.0000])\n",
      "output:tensor([223342.3438])\n",
      "Batch Average Reconstruciton Loss:4599912448.0\n",
      "input:tensor([  3.9303,   2.9380,   2.7753,   2.9040, 682.0000])\n",
      "output:tensor([223305.2969])\n",
      "Batch Average Reconstruciton Loss:846268992.0\n",
      "input:tensor([  4.5217,   3.8205,   3.2524,   3.7225, 682.0000])\n",
      "output:tensor([223263.9844])\n",
      "Batch Average Reconstruciton Loss:15023255.0\n",
      "input:tensor([  3.8960,   2.4030,   2.9015,   2.3850, 682.0000])\n",
      "output:tensor([223323.0469])\n",
      "Batch Average Reconstruciton Loss:979499264.0\n",
      "input:tensor([  4.6400,   2.5345,   3.6446,   2.5295, 682.0000])\n",
      "output:tensor([223302.1250])\n",
      "Batch Average Reconstruciton Loss:90423456.0\n",
      "input:tensor([  4.3787,   3.0845,   3.1241,   3.0455, 682.0000])\n",
      "output:tensor([223291.7188])\n",
      "Batch Average Reconstruciton Loss:10635955.0\n",
      "input:tensor([  4.3577,   3.0920,   3.0978,   3.0580, 682.0000])\n",
      "output:tensor([223291.8281])\n",
      "Batch Average Reconstruciton Loss:18950106.0\n",
      "input:tensor([  3.8473,   2.2410,   2.9421,   2.1810, 682.0000])\n",
      "output:tensor([223329.9531])\n",
      "Batch Average Reconstruciton Loss:1191012352.0\n",
      "input:tensor([ 26.0130,  19.1335,  18.4042,  19.0925, 682.0000])\n",
      "output:tensor([222325.])\n",
      "Batch Average Reconstruciton Loss:33925955584.0\n",
      "input:tensor([  3.3587,   2.1185,   2.4879,   2.0415, 682.0000])\n",
      "output:tensor([223344.8125])\n",
      "Batch Average Reconstruciton Loss:5185466880.0\n",
      "input:tensor([  7.6207,   7.1650,   5.8487,   7.0540, 682.0000])\n",
      "output:tensor([223084.1406])\n",
      "Batch Average Reconstruciton Loss:8632666112.0\n",
      "input:tensor([  4.3927,   3.0910,   2.9715,   2.9980, 682.0000])\n",
      "output:tensor([223294.3125])\n",
      "Batch Average Reconstruciton Loss:6434783.5\n",
      "input:tensor([  5.2323,   3.8630,   3.7006,   3.8060, 682.0000])\n",
      "output:tensor([223249.0938])\n",
      "Batch Average Reconstruciton Loss:1132934656.0\n",
      "input:tensor([  4.0723,   2.6615,   2.7818,   2.6305, 682.0000])\n",
      "output:tensor([223313.5156])\n",
      "Batch Average Reconstruciton Loss:411338624.0\n",
      "input:tensor([  3.6447,   2.0875,   2.8322,   2.0445, 682.0000])\n",
      "output:tensor([223338.3281])\n",
      "Batch Average Reconstruciton Loss:2385411328.0\n",
      "input:tensor([  3.5073,   1.8420,   2.8388,   1.7860, 682.0000])\n",
      "output:tensor([223348.8125])\n",
      "Batch Average Reconstruciton Loss:3538725376.0\n",
      "input:tensor([  3.7183,   2.0685,   2.9034,   2.0035, 682.0000])\n",
      "output:tensor([223338.0312])\n",
      "Batch Average Reconstruciton Loss:1887725952.0\n",
      "input:tensor([  4.2163,   2.9415,   3.0004,   2.9065, 682.0000])\n",
      "output:tensor([223299.7656])\n",
      "Batch Average Reconstruciton Loss:143430192.0\n",
      "input:tensor([  3.3797,   2.0595,   2.5186,   2.0425, 682.0000])\n",
      "output:tensor([223344.8438])\n",
      "Batch Average Reconstruciton Loss:4924552704.0\n",
      "input:tensor([  3.4663,   1.7380,   2.8637,   1.6470, 682.0000])\n",
      "output:tensor([223353.5781])\n",
      "Batch Average Reconstruciton Loss:3947284992.0\n",
      "input:tensor([  3.9077,   2.5170,   2.8597,   2.5000, 682.0000])\n",
      "output:tensor([223319.2656])\n",
      "Batch Average Reconstruciton Loss:932736448.0\n",
      "input:tensor([  3.9920,   2.5190,   2.9342,   2.5020, 682.0000])\n",
      "output:tensor([223317.5000])\n",
      "Batch Average Reconstruciton Loss:634007232.0\n",
      "input:tensor([  4.6870,   3.0150,   3.4386,   2.9810, 682.0000])\n",
      "output:tensor([223287.4062])\n",
      "Batch Average Reconstruciton Loss:135452496.0\n",
      "input:tensor([  5.4763,   4.3015,   3.8776,   4.2845, 682.0000])\n",
      "output:tensor([223227.9688])\n",
      "Batch Average Reconstruciton Loss:1771144576.0\n",
      "input:tensor([  4.1023,   3.0145,   2.9013,   2.9805, 682.0000])\n",
      "output:tensor([223299.3906])\n",
      "Batch Average Reconstruciton Loss:342790752.0\n",
      "input:tensor([  3.4820,   2.1835,   2.5735,   2.1405, 682.0000])\n",
      "output:tensor([223339.3906])\n",
      "Batch Average Reconstruciton Loss:3788969984.0\n",
      "input:tensor([  3.8090,   2.2595,   2.8835,   2.2255, 682.0000])\n",
      "output:tensor([223329.6719])\n",
      "Batch Average Reconstruciton Loss:1376879616.0\n",
      "input:tensor([  3.5947,   2.4885,   2.5694,   2.4465, 682.0000])\n",
      "output:tensor([223327.3281])\n",
      "Batch Average Reconstruciton Loss:2770619136.0\n",
      "input:tensor([  3.9170,   2.4540,   2.8925,   2.4440, 682.0000])\n",
      "output:tensor([223320.8906])\n",
      "Batch Average Reconstruciton Loss:896050880.0\n",
      "input:tensor([  3.4997,   1.7255,   2.8954,   1.7185, 682.0000])\n",
      "output:tensor([223351.2344])\n",
      "Batch Average Reconstruciton Loss:3612582912.0\n",
      "input:tensor([  4.4807,   2.7795,   3.3216,   2.7445, 682.0000])\n",
      "output:tensor([223299.2969])\n",
      "Batch Average Reconstruciton Loss:3622539.0\n",
      "input:tensor([  3.9530,   2.9470,   2.7932,   2.9410, 682.0000])\n",
      "output:tensor([223303.8438])\n",
      "Batch Average Reconstruciton Loss:764254656.0\n",
      "input:tensor([  3.6030,   2.5345,   2.5709,   2.4955, 682.0000])\n",
      "output:tensor([223325.5156])\n",
      "Batch Average Reconstruciton Loss:2704050432.0\n",
      "input:tensor([ 16.0267,  12.5685,   8.0613,  12.5645, 682.0000])\n",
      "output:tensor([222775.4844])\n",
      "Batch Average Reconstruciton Loss:25881886720.0\n",
      "input:tensor([  3.7450,   2.6880,   2.6616,   2.6110, 682.0000])\n",
      "output:tensor([223318.5000])\n",
      "Batch Average Reconstruciton Loss:1727940224.0\n",
      "input:tensor([  3.2527,   1.8720,   2.4892,   1.8370, 682.0000])\n",
      "output:tensor([223353.6875])\n",
      "Batch Average Reconstruciton Loss:6663017984.0\n",
      "input:tensor([  3.9470,   2.9360,   2.7882,   2.9310, 682.0000])\n",
      "output:tensor([223304.3281])\n",
      "Batch Average Reconstruciton Loss:785438272.0\n",
      "input:tensor([  4.3027,   2.6950,   3.1764,   2.6600, 682.0000])\n",
      "output:tensor([223305.7656])\n",
      "Batch Average Reconstruciton Loss:52551400.0\n",
      "input:tensor([  4.8433,   3.7880,   3.4272,   3.7700, 682.0000])\n",
      "output:tensor([223257.8750])\n",
      "Batch Average Reconstruciton Loss:340028992.0\n",
      "input:tensor([  3.9437,   2.4465,   2.9234,   2.4115, 682.0000])\n",
      "output:tensor([223321.1562])\n",
      "Batch Average Reconstruciton Loss:796472448.0\n",
      "input:tensor([  3.6053,   1.8805,   2.9108,   1.7775, 682.0000])\n",
      "output:tensor([223346.7969])\n",
      "Batch Average Reconstruciton Loss:2683364608.0\n",
      "input:tensor([  3.4267,   1.6510,   2.8806,   1.6170, 682.0000])\n",
      "output:tensor([223355.5000])\n",
      "Batch Average Reconstruciton Loss:4374301184.0\n",
      "input:tensor([  3.9490,   2.4850,   2.9227,   2.3830, 682.0000])\n",
      "output:tensor([223321.4219])\n",
      "Batch Average Reconstruciton Loss:777382400.0\n",
      "input:tensor([  4.9640,   3.8860,   3.5102,   3.8270, 682.0000])\n",
      "output:tensor([223253.2188])\n",
      "Batch Average Reconstruciton Loss:548225664.0\n",
      "input:tensor([ 36.0690,   2.5335,  47.5539,   2.4975, 682.0000])\n",
      "output:tensor([222498.3906])\n",
      "Batch Average Reconstruciton Loss:38023200768.0\n",
      "input:tensor([  3.9903,   2.5555,   2.9298,   2.4885, 682.0000])\n",
      "output:tensor([223317.5156])\n",
      "Batch Average Reconstruciton Loss:639254592.0\n",
      "input:tensor([  5.1767,   3.1450,   3.8701,   3.1060, 682.0000])\n",
      "output:tensor([223273.0625])\n",
      "Batch Average Reconstruciton Loss:1001346688.0\n",
      "input:tensor([  3.3773,   2.1275,   2.5010,   2.0685, 682.0000])\n",
      "output:tensor([223343.7031])\n",
      "Batch Average Reconstruciton Loss:4953245184.0\n",
      "input:tensor([  4.5173,   2.3095,   3.6727,   2.2745, 682.0000])\n",
      "output:tensor([223311.9375])\n",
      "Batch Average Reconstruciton Loss:13785905.0\n",
      "input:tensor([  4.3183,   2.5520,   3.2819,   2.4830, 682.0000])\n",
      "output:tensor([223310.4219])\n",
      "Batch Average Reconstruciton Loss:41057056.0\n",
      "input:tensor([  4.4137,   2.6690,   3.3131,   2.6350, 682.0000])\n",
      "output:tensor([223304.0156])\n",
      "Batch Average Reconstruciton Loss:2108258.75\n",
      "input:tensor([  4.5570,   3.3525,   3.2215,   3.3135, 682.0000])\n",
      "output:tensor([223279.2031])\n",
      "Batch Average Reconstruciton Loss:31272736.0\n",
      "input:tensor([  5.0543,   3.5470,   3.5982,   3.5120, 682.0000])\n",
      "output:tensor([223262.8281])\n",
      "Batch Average Reconstruciton Loss:728774720.0\n",
      "input:tensor([  3.8363,   1.7885,   3.2878,   1.7545, 682.0000])\n",
      "output:tensor([223341.8594])\n",
      "Batch Average Reconstruciton Loss:1241726592.0\n",
      "input:tensor([  3.4327,   2.2210,   2.5210,   2.1210, 682.0000])\n",
      "output:tensor([223340.6094])\n",
      "Batch Average Reconstruciton Loss:4309579776.0\n",
      "input:tensor([  4.3880,   2.7435,   3.2857,   2.5945, 682.0000])\n",
      "output:tensor([223304.8125])\n",
      "Batch Average Reconstruciton Loss:7651793.5\n",
      "input:tensor([  4.0107,   2.5380,   2.9504,   2.4990, 682.0000])\n",
      "output:tensor([223317.])\n",
      "Batch Average Reconstruciton Loss:577104512.0\n",
      "input:tensor([  3.9263,   1.9175,   3.2709,   1.9125, 682.0000])\n",
      "output:tensor([223335.7500])\n",
      "Batch Average Reconstruciton Loss:859501120.0\n",
      "input:tensor([  4.5540,   3.8585,   1.2357,   3.7975, 682.0000])\n",
      "output:tensor([223283.])\n",
      "Batch Average Reconstruciton Loss:29735208.0\n",
      "input:tensor([  4.6740,   3.1250,   3.3847,   3.0450, 682.0000])\n",
      "output:tensor([223285.3594])\n",
      "Batch Average Reconstruciton Loss:122044152.0\n",
      "input:tensor([  7.6877,   7.4860,   6.0656,   7.4180, 682.0000])\n",
      "output:tensor([223068.5625])\n",
      "Batch Average Reconstruciton Loss:8841746432.0\n",
      "input:tensor([  3.7507,   2.1145,   2.9101,   2.0795, 682.0000])\n",
      "output:tensor([223335.2344])\n",
      "Batch Average Reconstruciton Loss:1693385472.0\n",
      "input:tensor([  3.1787,   1.8085,   2.4523,   1.7745, 682.0000])\n",
      "output:tensor([223357.0938])\n",
      "Batch Average Reconstruciton Loss:7871931392.0\n",
      "input:tensor([  4.8080,   2.8370,   3.5184,   2.7180, 682.0000])\n",
      "output:tensor([223293.7656])\n",
      "Batch Average Reconstruciton Loss:288006880.0\n",
      "input:tensor([  4.6957,   2.1595,   3.7020,   2.1545, 682.0000])\n",
      "output:tensor([223314.3281])\n",
      "Batch Average Reconstruciton Loss:145330944.0\n",
      "input:tensor([  4.1477,   1.9990,   3.4673,   1.9810, 682.0000])\n",
      "output:tensor([223328.7188])\n",
      "Batch Average Reconstruciton Loss:250977872.0\n",
      "input:tensor([  4.4050,   2.1710,   3.6722,   2.1110, 682.0000])\n",
      "output:tensor([223318.7031])\n",
      "Batch Average Reconstruciton Loss:3535516.25\n",
      "input:tensor([  3.9637,   2.4700,   2.9375,   2.4100, 682.0000])\n",
      "output:tensor([223320.5938])\n",
      "Batch Average Reconstruciton Loss:726432192.0\n",
      "input:tensor([  5.2340,   3.2695,   3.8828,   3.2035, 682.0000])\n",
      "output:tensor([223268.5469])\n",
      "Batch Average Reconstruciton Loss:1138289536.0\n",
      "input:tensor([  4.4233,   2.4105,   3.4893,   2.3725, 682.0000])\n",
      "output:tensor([223311.3594])\n",
      "Batch Average Reconstruciton Loss:909430.4375\n",
      "input:tensor([  4.0580,   3.1475,   2.8656,   3.1065, 682.0000])\n",
      "output:tensor([223295.6875])\n",
      "Batch Average Reconstruciton Loss:447716512.0\n",
      "input:tensor([  4.4010,   2.6565,   3.3242,   2.5655, 682.0000])\n",
      "output:tensor([223305.9219])\n",
      "Batch Average Reconstruciton Loss:4397736.5\n",
      "input:tensor([  3.6130,   1.9295,   2.8465,   1.8885, 682.0000])\n",
      "output:tensor([223344.1250])\n",
      "Batch Average Reconstruciton Loss:2623475712.0\n",
      "input:tensor([  3.6313,   2.4990,   2.6035,   2.4350, 682.0000])\n",
      "output:tensor([223326.7500])\n",
      "Batch Average Reconstruciton Loss:2485147136.0\n",
      "input:tensor([  3.6603,   2.0400,   2.8589,   2.0060, 682.0000])\n",
      "output:tensor([223339.3594])\n",
      "Batch Average Reconstruciton Loss:2272871424.0\n",
      "input:tensor([  5.5873,   3.0000,   4.4524,   2.9230, 682.0000])\n",
      "output:tensor([223268.6094])\n",
      "Batch Average Reconstruciton Loss:2090739840.0\n",
      "input:tensor([  3.9507,   2.4720,   2.9128,   2.4380, 682.0000])\n",
      "output:tensor([223320.2500])\n",
      "Batch Average Reconstruciton Loss:771547840.0\n",
      "input:tensor([  3.9013,   2.4420,   2.9069,   2.3380, 682.0000])\n",
      "output:tensor([223323.6875])\n",
      "Batch Average Reconstruciton Loss:957798016.0\n",
      "input:tensor([ 12.3740,   2.3650,  14.2376,   2.2690, 682.0000])\n",
      "output:tensor([223114.7500])\n",
      "Batch Average Reconstruciton Loss:20433772544.0\n",
      "input:tensor([ 17.7493,   4.3055,  19.3660,   4.2715, 682.0000])\n",
      "output:tensor([222931.8125])\n",
      "Batch Average Reconstruciton Loss:27903301632.0\n",
      "input:tensor([  6.2393,   2.6590,   5.5916,   2.5380, 682.0000])\n",
      "output:tensor([223262.7344])\n",
      "Batch Average Reconstruciton Loss:4130855936.0\n",
      "input:tensor([ 18.6780,   2.5145,  23.0391,   2.4115, 682.0000])\n",
      "output:tensor([222948.2656])\n",
      "Batch Average Reconstruciton Loss:28844697600.0\n",
      "input:tensor([  3.9287,   2.4695,   2.7230,   2.3545, 682.0000])\n",
      "output:tensor([223324.6562])\n",
      "Batch Average Reconstruciton Loss:851375744.0\n",
      "input:tensor([  4.5837,   2.5485,   3.5660,   2.5305, 682.0000])\n",
      "output:tensor([223303.4062])\n",
      "Batch Average Reconstruciton Loss:47367516.0\n",
      "input:tensor([  3.3067,   2.0505,   2.4681,   2.0155, 682.0000])\n",
      "output:tensor([223346.9688])\n",
      "Batch Average Reconstruciton Loss:5875687424.0\n",
      "input:tensor([  3.7963,   2.2510,   2.8785,   2.1450, 682.0000])\n",
      "output:tensor([223331.9688])\n",
      "Batch Average Reconstruciton Loss:1441951104.0\n",
      "input:tensor([  4.8007,   3.1775,   3.4739,   3.1425, 682.0000])\n",
      "output:tensor([223280.0469])\n",
      "Batch Average Reconstruciton Loss:276957728.0\n",
      "input:tensor([ 31.3430,  24.0280,  22.1729,  23.9880, 682.0000])\n",
      "output:tensor([222053.1562])\n",
      "Batch Average Reconstruciton Loss:36253360128.0\n",
      "input:tensor([  4.6347,   2.4940,   3.6668,   2.4600, 682.0000])\n",
      "output:tensor([223304.1250])\n",
      "Batch Average Reconstruciton Loss:85842544.0\n",
      "input:tensor([  4.7347,   3.5580,   3.3433,   3.5210, 682.0000])\n",
      "output:tensor([223268.6406])\n",
      "Batch Average Reconstruciton Loss:189080112.0\n",
      "input:tensor([  3.4327,   2.2925,   2.4786,   2.2585, 682.0000])\n",
      "output:tensor([223336.8281])\n",
      "Batch Average Reconstruciton Loss:4310076416.0\n",
      "input:tensor([  3.6753,   2.5895,   2.6188,   2.5215, 682.0000])\n",
      "output:tensor([223323.])\n",
      "Batch Average Reconstruciton Loss:2170162176.0\n",
      "input:tensor([  5.6930,   4.9840,   4.1700,   4.9390, 682.0000])\n",
      "output:tensor([223198.8594])\n",
      "Batch Average Reconstruciton Loss:2396088832.0\n",
      "input:tensor([  4.1473,   2.7420,   2.9978,   2.7350, 682.0000])\n",
      "output:tensor([223306.9531])\n",
      "Batch Average Reconstruciton Loss:252271184.0\n",
      "input:tensor([  3.4083,   2.0660,   2.5659,   1.9950, 682.0000])\n",
      "output:tensor([223345.1562])\n",
      "Batch Average Reconstruciton Loss:4584081408.0\n",
      "input:tensor([  3.4997,   2.2190,   2.5697,   2.2140, 682.0000])\n",
      "output:tensor([223337.0312])\n",
      "Batch Average Reconstruciton Loss:3614290432.0\n",
      "input:tensor([  4.9280,   3.0685,   3.6451,   3.0345, 682.0000])\n",
      "output:tensor([223280.7500])\n",
      "Batch Average Reconstruciton Loss:483197344.0\n",
      "input:tensor([  3.8480,   2.3750,   2.8874,   2.2870, 682.0000])\n",
      "output:tensor([223326.4375])\n",
      "Batch Average Reconstruciton Loss:1188150784.0\n",
      "input:tensor([  3.4743,   2.2705,   2.5454,   2.1945, 682.0000])\n",
      "output:tensor([223337.5000])\n",
      "Batch Average Reconstruciton Loss:3866912000.0\n",
      "input:tensor([  4.4983,   3.2535,   2.0686,   3.2465, 682.0000])\n",
      "output:tensor([223294.8906])\n",
      "Batch Average Reconstruciton Loss:7666755.5\n",
      "input:tensor([  4.0913,   2.2020,   2.8495,   2.1420, 682.0000])\n",
      "output:tensor([223329.7344])\n",
      "Batch Average Reconstruciton Loss:366120128.0\n",
      "input:tensor([  4.8873,   4.2220,   3.5420,   4.1610, 682.0000])\n",
      "output:tensor([223241.7656])\n",
      "Batch Average Reconstruciton Loss:410782336.0\n",
      "input:tensor([  8.9137,   6.7525,   3.9033,   6.7425, 682.0000])\n",
      "output:tensor([223103.4688])\n",
      "Batch Average Reconstruciton Loss:12502251520.0\n",
      "input:tensor([  3.8643,   2.3580,   2.8878,   2.3230, 682.0000])\n",
      "output:tensor([223325.5312])\n",
      "Batch Average Reconstruciton Loss:1114322432.0\n",
      "input:tensor([  4.8307,   3.8170,   3.4187,   3.7740, 682.0000])\n",
      "output:tensor([223257.7031])\n",
      "Batch Average Reconstruciton Loss:320506784.0\n",
      "input:tensor([  4.2070,   3.2070,   2.9706,   3.1720, 682.0000])\n",
      "output:tensor([223290.7031])\n",
      "Batch Average Reconstruciton Loss:156407456.0\n",
      "input:tensor([  3.2297,   1.8995,   2.4657,   1.8305, 682.0000])\n",
      "output:tensor([223354.0312])\n",
      "Batch Average Reconstruciton Loss:7022099456.0\n",
      "input:tensor([  3.9667,   2.5560,   2.9127,   2.4910, 682.0000])\n",
      "output:tensor([223317.8750])\n",
      "Batch Average Reconstruciton Loss:716425472.0\n",
      "input:tensor([  3.5093,   2.3195,   2.5534,   2.2845, 682.0000])\n",
      "output:tensor([223334.2656])\n",
      "Batch Average Reconstruciton Loss:3521322752.0\n",
      "input:tensor([ 35.3170,  26.4190,  24.9702,  26.3600, 682.0000])\n",
      "output:tensor([221896.0625])\n",
      "Batch Average Reconstruciton Loss:37561565184.0\n",
      "input:tensor([  4.2097,   2.6135,   3.1263,   2.5965, 682.0000])\n",
      "output:tensor([223309.7188])\n",
      "Batch Average Reconstruciton Loss:152233184.0\n",
      "input:tensor([  4.0470,   2.0370,   3.3335,   2.0200, 682.0000])\n",
      "output:tensor([223329.8594])\n",
      "Batch Average Reconstruciton Loss:474810240.0\n",
      "input:tensor([  4.4460,   3.7565,   3.2003,   3.7225, 682.0000])\n",
      "output:tensor([223266.0312])\n",
      "Batch Average Reconstruciton Loss:20745.0\n",
      "input:tensor([  5.0947,   3.1805,   3.7649,   3.1455, 682.0000])\n",
      "output:tensor([223273.6875])\n",
      "Batch Average Reconstruciton Loss:815712896.0\n",
      "input:tensor([  4.0060,   2.0475,   3.2771,   2.0125, 682.0000])\n",
      "output:tensor([223330.9531])\n",
      "Batch Average Reconstruciton Loss:590395072.0\n",
      "input:tensor([  3.1803,   1.8325,   2.4585,   1.7965, 682.0000])\n",
      "output:tensor([223356.2031])\n",
      "Batch Average Reconstruciton Loss:7843014656.0\n",
      "input:tensor([  3.9587,   2.4855,   2.9205,   2.4495, 682.0000])\n",
      "output:tensor([223319.6719])\n",
      "Batch Average Reconstruciton Loss:743616256.0\n",
      "input:tensor([  4.1787,   2.8235,   3.0032,   2.7875, 682.0000])\n",
      "output:tensor([223304.3594])\n",
      "Batch Average Reconstruciton Loss:198574336.0\n",
      "input:tensor([  4.2213,   2.1220,   3.4530,   2.0870, 682.0000])\n",
      "output:tensor([223324.1406])\n",
      "Batch Average Reconstruciton Loss:136255648.0\n",
      "input:tensor([ 22.2390,   1.6015,  29.2452,   1.5615, 682.0000])\n",
      "output:tensor([222874.9375])\n",
      "Batch Average Reconstruciton Loss:31779813376.0\n",
      "input:tensor([  3.6627,   2.0170,   2.8660,   2.0000, 682.0000])\n",
      "output:tensor([223339.6406])\n",
      "Batch Average Reconstruciton Loss:2256379136.0\n",
      "input:tensor([  4.0427,   2.7355,   2.9022,   2.7195, 682.0000])\n",
      "output:tensor([223309.5312])\n",
      "Batch Average Reconstruciton Loss:487238016.0\n",
      "input:tensor([  9.3993,   3.6605,   8.3031,   3.6555, 682.0000])\n",
      "output:tensor([223161.4375])\n",
      "Batch Average Reconstruciton Loss:13835037696.0\n",
      "input:tensor([  3.1647,   1.8130,   2.4499,   1.7960, 682.0000])\n",
      "output:tensor([223356.6875])\n",
      "Batch Average Reconstruciton Loss:8118787072.0\n",
      "input:tensor([ 11.5677,   1.8870,  13.8711,   1.7650, 682.0000])\n",
      "output:tensor([223144.9531])\n",
      "Batch Average Reconstruciton Loss:18875723776.0\n",
      "input:tensor([  4.2927,   3.0085,   3.0653,   2.9525, 682.0000])\n",
      "output:tensor([223296.3750])\n",
      "Batch Average Reconstruciton Loss:60771768.0\n",
      "input:tensor([  3.8293,   2.8370,   2.5429,   2.7430, 682.0000])\n",
      "output:tensor([223313.9844])\n",
      "Batch Average Reconstruciton Loss:1277277184.0\n",
      "input:tensor([  2.7837,   1.7620,   2.0590,   1.7020, 682.0000])\n",
      "output:tensor([223367.8125])\n",
      "Batch Average Reconstruciton Loss:17688252416.0\n",
      "input:tensor([  4.4977,   2.3685,   3.6049,   2.3335, 682.0000])\n",
      "output:tensor([223310.7344])\n",
      "Batch Average Reconstruciton Loss:7572042.0\n",
      "input:tensor([  3.8907,   2.6795,   2.7811,   2.6425, 682.0000])\n",
      "output:tensor([223314.9844])\n",
      "Batch Average Reconstruciton Loss:1001976704.0\n",
      "input:tensor([  9.6543,   2.6750,  10.1537,   2.6410, 682.0000])\n",
      "output:tensor([223174.8125])\n",
      "Batch Average Reconstruciton Loss:14501653504.0\n",
      "input:tensor([  4.7343,   1.7850,   4.4669,   1.7810, 682.0000])\n",
      "output:tensor([223319.0625])\n",
      "Batch Average Reconstruciton Loss:190055520.0\n",
      "input:tensor([  3.4867,   1.7505,   2.7070,   1.6755, 682.0000])\n",
      "output:tensor([223354.1875])\n",
      "Batch Average Reconstruciton Loss:3740278016.0\n",
      "input:tensor([  3.7760,   2.1970,   2.8807,   2.1800, 682.0000])\n",
      "output:tensor([223331.8594])\n",
      "Batch Average Reconstruciton Loss:1550795520.0\n",
      "input:tensor([  3.4353,   1.6995,   2.8604,   1.6645, 682.0000])\n",
      "output:tensor([223353.9062])\n",
      "Batch Average Reconstruciton Loss:4278480384.0\n",
      "input:tensor([  4.6307,   3.5000,   3.2718,   3.4430, 682.0000])\n",
      "output:tensor([223273.0469])\n",
      "Batch Average Reconstruciton Loss:81885248.0\n",
      "input:tensor([  3.4273,   1.7865,   2.7843,   1.7085, 682.0000])\n",
      "output:tensor([223352.7812])\n",
      "Batch Average Reconstruciton Loss:4367256064.0\n",
      "input:tensor([  3.7627,   2.1790,   2.9013,   2.1130, 682.0000])\n",
      "output:tensor([223333.6562])\n",
      "Batch Average Reconstruciton Loss:1624843136.0\n",
      "input:tensor([  4.0547,   2.6270,   2.9609,   2.5470, 682.0000])\n",
      "output:tensor([223314.2656])\n",
      "Batch Average Reconstruciton Loss:455469632.0\n",
      "input:tensor([  4.3350,   2.9715,   3.1171,   2.8575, 682.0000])\n",
      "output:tensor([223298.1719])\n",
      "Batch Average Reconstruciton Loss:30656466.0\n",
      "input:tensor([  3.5803,   2.3565,   2.5902,   2.3395, 682.0000])\n",
      "output:tensor([223331.3594])\n",
      "Batch Average Reconstruciton Loss:2887734016.0\n",
      "input:tensor([  6.0707,   3.2100,   4.8399,   3.1930, 682.0000])\n",
      "output:tensor([223250.2969])\n",
      "Batch Average Reconstruciton Loss:3580980736.0\n",
      "input:tensor([  3.5717,   1.9720,   2.8256,   1.9050, 682.0000])\n",
      "output:tensor([223343.8906])\n",
      "Batch Average Reconstruciton Loss:2959045632.0\n",
      "input:tensor([  4.1017,   2.4240,   3.1202,   2.3560, 682.0000])\n",
      "output:tensor([223319.0156])\n",
      "Batch Average Reconstruciton Loss:343508576.0\n",
      "input:tensor([ 19.8787,   3.3175,  23.4398,   3.3115, 682.0000])\n",
      "output:tensor([222900.1250])\n",
      "Batch Average Reconstruciton Loss:29928005632.0\n",
      "input:tensor([  3.5457,   2.3725,   2.5646,   2.3035, 682.0000])\n",
      "output:tensor([223332.7344])\n",
      "Batch Average Reconstruciton Loss:3186067968.0\n",
      "input:tensor([ 10.3487,   7.0510,   7.2760,   6.9310, 682.0000])\n",
      "output:tensor([223044.1562])\n",
      "Batch Average Reconstruciton Loss:16176318464.0\n",
      "input:tensor([  4.7227,   3.1385,   3.4111,   3.1035, 682.0000])\n",
      "output:tensor([223282.9375])\n",
      "Batch Average Reconstruciton Loss:175084176.0\n",
      "input:tensor([  3.9870,   2.0800,   3.2525,   1.9760, 682.0000])\n",
      "output:tensor([223332.])\n",
      "Batch Average Reconstruciton Loss:649077504.0\n",
      "input:tensor([  4.8310,   4.2460,   3.5419,   4.1760, 682.0000])\n",
      "output:tensor([223241.7188])\n",
      "Batch Average Reconstruciton Loss:320435744.0\n",
      "input:tensor([ 34.4213,   3.9265,  43.2995,   3.8925, 682.0000])\n",
      "output:tensor([222511.6875])\n",
      "Batch Average Reconstruciton Loss:37516857344.0\n",
      "input:tensor([  4.0290,   3.3535,   2.8848,   3.3495, 682.0000])\n",
      "output:tensor([223287.5000])\n",
      "Batch Average Reconstruciton Loss:525670272.0\n",
      "input:tensor([  3.4057,   2.1540,   2.5278,   2.0160, 682.0000])\n",
      "output:tensor([223344.1406])\n",
      "Batch Average Reconstruciton Loss:4615144960.0\n",
      "input:tensor([  3.6737,   2.4840,   2.6352,   2.4510, 682.0000])\n",
      "output:tensor([223325.7188])\n",
      "Batch Average Reconstruciton Loss:2181289984.0\n",
      "input:tensor([  3.5397,   2.3315,   2.5741,   2.2665, 682.0000])\n",
      "output:tensor([223334.0469])\n",
      "Batch Average Reconstruciton Loss:3239653376.0\n",
      "input:tensor([  3.8800,   1.8540,   3.2695,   1.7800, 682.0000])\n",
      "output:tensor([223340.2656])\n",
      "Batch Average Reconstruciton Loss:1045211712.0\n",
      "input:tensor([  3.7413,   2.6810,   2.6602,   2.5990, 682.0000])\n",
      "output:tensor([223318.9219])\n",
      "Batch Average Reconstruciton Loss:1749504512.0\n",
      "input:tensor([  3.8937,   2.3500,   2.9246,   2.2790, 682.0000])\n",
      "output:tensor([223326.0156])\n",
      "Batch Average Reconstruciton Loss:988912832.0\n",
      "input:tensor([  4.1717,   1.9045,   3.5827,   1.8695, 682.0000])\n",
      "output:tensor([223331.0312])\n",
      "Batch Average Reconstruciton Loss:209206400.0\n",
      "input:tensor([  3.4573,   2.2075,   2.5523,   2.1385, 682.0000])\n",
      "output:tensor([223339.7031])\n",
      "Batch Average Reconstruciton Loss:4043217152.0\n",
      "input:tensor([  3.8070,   1.7435,   3.2641,   1.7255, 682.0000])\n",
      "output:tensor([223343.6406])\n",
      "Batch Average Reconstruciton Loss:1386025216.0\n",
      "input:tensor([  3.7530,   2.1600,   2.8792,   2.1260, 682.0000])\n",
      "output:tensor([223333.8750])\n",
      "Batch Average Reconstruciton Loss:1680026368.0\n",
      "input:tensor([  4.0747,   2.6295,   2.9847,   2.5945, 682.0000])\n",
      "output:tensor([223312.5781])\n",
      "Batch Average Reconstruciton Loss:405757440.0\n",
      "input:tensor([ 25.6593,  19.1630,  15.6270,  19.0570, 682.0000])\n",
      "output:tensor([222359.1250])\n",
      "Batch Average Reconstruciton Loss:33745369088.0\n",
      "input:tensor([  8.3023,   7.9640,   6.4874,   7.9300, 682.0000])\n",
      "output:tensor([223039.5938])\n",
      "Batch Average Reconstruciton Loss:10723761152.0\n",
      "input:tensor([  5.0200,   3.1330,   3.7071,   3.0890, 682.0000])\n",
      "output:tensor([223277.0312])\n",
      "Batch Average Reconstruciton Loss:658796480.0\n",
      "input:tensor([  3.5243,   1.8715,   2.8283,   1.8075, 682.0000])\n",
      "output:tensor([223347.8906])\n",
      "Batch Average Reconstruciton Loss:3378412032.0\n",
      "input:tensor([  3.5210,   2.4865,   2.5128,   2.4815, 682.0000])\n",
      "output:tensor([223327.8594])\n",
      "Batch Average Reconstruciton Loss:3411744512.0\n",
      "input:tensor([  4.4487,   2.7300,   3.3233,   2.6690, 682.0000])\n",
      "output:tensor([223302.0469])\n",
      "Batch Average Reconstruciton Loss:98625.4375\n",
      "input:tensor([ 19.4157,   2.1155,  24.5890,   2.1085, 682.0000])\n",
      "output:tensor([222935.6719])\n",
      "Batch Average Reconstruciton Loss:29529903104.0\n",
      "input:tensor([  3.3310,   1.9825,   2.5172,   1.9415, 682.0000])\n",
      "output:tensor([223348.7500])\n",
      "Batch Average Reconstruciton Loss:5544179712.0\n",
      "input:tensor([  3.3557,   2.0770,   2.4897,   2.0710, 682.0000])\n",
      "output:tensor([223344.5312])\n",
      "Batch Average Reconstruciton Loss:5223598592.0\n",
      "input:tensor([  4.0533,   2.6420,   2.9529,   2.5750, 682.0000])\n",
      "output:tensor([223313.5156])\n",
      "Batch Average Reconstruciton Loss:458965696.0\n",
      "input:tensor([  3.9877,   2.4635,   2.9528,   2.4295, 682.0000])\n",
      "output:tensor([223319.7500])\n",
      "Batch Average Reconstruciton Loss:647562560.0\n",
      "input:tensor([  3.1900,   1.8315,   2.4539,   1.7965, 682.0000])\n",
      "output:tensor([223356.1562])\n",
      "Batch Average Reconstruciton Loss:7676536320.0\n",
      "input:tensor([  5.1087,   4.0840,   3.6265,   4.0490, 682.0000])\n",
      "output:tensor([223242.7812])\n",
      "Batch Average Reconstruciton Loss:844645248.0\n",
      "input:tensor([  3.3237,   2.0335,   2.4884,   1.9965, 682.0000])\n",
      "output:tensor([223347.2031])\n",
      "Batch Average Reconstruciton Loss:5642833408.0\n",
      "input:tensor([  4.1657,   2.7555,   3.0117,   2.7205, 682.0000])\n",
      "output:tensor([223306.8125])\n",
      "Batch Average Reconstruciton Loss:219934464.0\n",
      "input:tensor([  4.0240,   2.6070,   2.0827,   2.5720, 682.0000])\n",
      "output:tensor([223323.5781])\n",
      "Batch Average Reconstruciton Loss:538120384.0\n",
      "input:tensor([  3.9277,   2.4365,   2.9147,   2.4015, 682.0000])\n",
      "output:tensor([223321.7656])\n",
      "Batch Average Reconstruciton Loss:855283712.0\n",
      "input:tensor([ 12.5120,   9.3375,   5.5936,   9.3345, 682.0000])\n",
      "output:tensor([222954.6250])\n",
      "Batch Average Reconstruciton Loss:20641249280.0\n",
      "input:tensor([  6.1683,   4.1530,   4.3818,   4.0500, 682.0000])\n",
      "output:tensor([223222.6719])\n",
      "Batch Average Reconstruciton Loss:3893968640.0\n",
      "input:tensor([  3.6247,   2.4800,   2.6002,   2.4410, 682.0000])\n",
      "output:tensor([223326.9219])\n",
      "Batch Average Reconstruciton Loss:2535432448.0\n",
      "input:tensor([  7.4613,   2.5200,   7.3130,   2.4860, 682.0000])\n",
      "output:tensor([223234.0938])\n",
      "Batch Average Reconstruciton Loss:8150856704.0\n",
      "input:tensor([  3.8813,   2.3345,   2.9199,   2.3005, 682.0000])\n",
      "output:tensor([223325.8438])\n",
      "Batch Average Reconstruciton Loss:1040459648.0\n",
      "input:tensor([  3.4920,   2.2640,   2.5455,   2.2300, 682.0000])\n",
      "output:tensor([223336.5000])\n",
      "Batch Average Reconstruciton Loss:3689529856.0\n",
      "input:tensor([  3.6297,   2.4880,   2.6069,   2.4110, 682.0000])\n",
      "output:tensor([223327.4531])\n",
      "Batch Average Reconstruciton Loss:2497555200.0\n",
      "input:tensor([  3.4237,   2.1880,   2.5123,   2.1540, 682.0000])\n",
      "output:tensor([223340.2969])\n",
      "Batch Average Reconstruciton Loss:4409982976.0\n",
      "input:tensor([  4.8833,   2.8860,   3.6918,   2.8500, 682.0000])\n",
      "output:tensor([223287.2812])\n",
      "Batch Average Reconstruciton Loss:405912928.0\n",
      "input:tensor([  4.3640,   2.6720,   3.1022,   2.5790, 682.0000])\n",
      "output:tensor([223308.1875])\n",
      "Batch Average Reconstruciton Loss:16046534.0\n",
      "input:tensor([  3.7167,   2.5975,   2.6507,   2.5545, 682.0000])\n",
      "output:tensor([223321.3125])\n",
      "Batch Average Reconstruciton Loss:1899624960.0\n",
      "input:tensor([  4.9090,   3.3750,   2.4423,   3.3690, 682.0000])\n",
      "output:tensor([223282.1875])\n",
      "Batch Average Reconstruciton Loss:449617568.0\n",
      "input:tensor([  3.7777,   2.7500,   2.5393,   2.6460, 682.0000])\n",
      "output:tensor([223317.9219])\n",
      "Batch Average Reconstruciton Loss:1542767360.0\n",
      "input:tensor([  4.2760,   2.4685,   3.2707,   2.4615, 682.0000])\n",
      "output:tensor([223312.4219])\n",
      "Batch Average Reconstruciton Loss:75352440.0\n",
      "input:tensor([  4.6483,   2.5550,   3.6636,   2.4960, 682.0000])\n",
      "output:tensor([223302.4688])\n",
      "Batch Average Reconstruciton Loss:97860936.0\n",
      "input:tensor([  3.3783,   2.2190,   2.4609,   2.2010, 682.0000])\n",
      "output:tensor([223339.8281])\n",
      "Batch Average Reconstruciton Loss:4941551616.0\n",
      "input:tensor([  5.2443,   3.8380,   2.4879,   3.7600, 682.0000])\n",
      "output:tensor([223263.3906])\n",
      "Batch Average Reconstruciton Loss:1163245824.0\n",
      "input:tensor([  4.2780,   2.4845,   3.1895,   2.2935, 682.0000])\n",
      "output:tensor([223317.3438])\n",
      "Batch Average Reconstruciton Loss:73387600.0\n",
      "input:tensor([  4.2297,   2.9075,   3.0339,   2.8425, 682.0000])\n",
      "output:tensor([223301.2344])\n",
      "Batch Average Reconstruciton Loss:126175024.0\n",
      "input:tensor([  3.4953,   1.8000,   2.8439,   1.7640, 682.0000])\n",
      "output:tensor([223349.9062])\n",
      "Batch Average Reconstruciton Loss:3655060224.0\n",
      "input:tensor([  3.6137,   2.3805,   2.6240,   2.3185, 682.0000])\n",
      "output:tensor([223330.9219])\n",
      "Batch Average Reconstruciton Loss:2619605248.0\n",
      "input:tensor([  5.0893,   1.9580,   4.7550,   1.9230, 682.0000])\n",
      "output:tensor([223306.7969])\n",
      "Batch Average Reconstruciton Loss:805980544.0\n",
      "input:tensor([  5.3117,   2.5175,   4.4946,   2.4755, 682.0000])\n",
      "output:tensor([223287.4219])\n",
      "Batch Average Reconstruciton Loss:1334325632.0\n",
      "input:tensor([  4.3150,   2.9990,   3.0910,   2.8920, 682.0000])\n",
      "output:tensor([223297.5000])\n",
      "Batch Average Reconstruciton Loss:43540204.0\n",
      "input:tensor([124.7707, 167.8330, 149.9295, 167.8270, 682.0000])\n",
      "output:tensor([214554.7344])\n",
      "Batch Average Reconstruciton Loss:42685104128.0\n",
      "input:tensor([  3.9490,   2.4710,   2.9109,   2.4670, 682.0000])\n",
      "output:tensor([223319.5938])\n",
      "Batch Average Reconstruciton Loss:777484352.0\n",
      "input:tensor([  4.7350,   3.1385,   3.2312,   3.0405, 682.0000])\n",
      "output:tensor([223286.3125])\n",
      "Batch Average Reconstruciton Loss:189952144.0\n",
      "input:tensor([  3.7213,   2.1560,   2.8610,   2.0450, 682.0000])\n",
      "output:tensor([223336.4688])\n",
      "Batch Average Reconstruciton Loss:1869224704.0\n",
      "input:tensor([  5.0863,   2.0780,   4.6146,   2.0600, 682.0000])\n",
      "output:tensor([223303.6406])\n",
      "Batch Average Reconstruciton Loss:799285632.0\n",
      "input:tensor([  3.6027,   1.9400,   2.8799,   1.9050, 682.0000])\n",
      "output:tensor([223343.3281])\n",
      "Batch Average Reconstruciton Loss:2704901888.0\n",
      "input:tensor([  3.1827,   1.8435,   2.4501,   1.8255, 682.0000])\n",
      "output:tensor([223355.4219])\n",
      "Batch Average Reconstruciton Loss:7802644480.0\n",
      "input:tensor([  3.6753,   2.0365,   2.8823,   1.9965, 682.0000])\n",
      "output:tensor([223339.2188])\n",
      "Batch Average Reconstruciton Loss:2168651264.0\n",
      "input:tensor([  3.5653,   2.3865,   2.5704,   2.3525, 682.0000])\n",
      "output:tensor([223331.0781])\n",
      "Batch Average Reconstruciton Loss:3014440704.0\n",
      "input:tensor([  3.5843,   2.4655,   2.5716,   2.4315, 682.0000])\n",
      "output:tensor([223328.0469])\n",
      "Batch Average Reconstruciton Loss:2854973696.0\n",
      "input:tensor([  3.9903,   2.0105,   3.2640,   1.9765, 682.0000])\n",
      "output:tensor([223332.5625])\n",
      "Batch Average Reconstruciton Loss:638493952.0\n",
      "input:tensor([  5.2177,   2.8335,   3.4263,   2.8265, 682.0000])\n",
      "output:tensor([223287.7031])\n",
      "Batch Average Reconstruciton Loss:1099897472.0\n",
      "input:tensor([ 16.5930,   3.2150,  19.1630,   3.1430, 682.0000])\n",
      "output:tensor([222986.1719])\n",
      "Batch Average Reconstruciton Loss:26634948608.0\n",
      "input:tensor([  3.9727,   2.9810,   2.8047,   2.9460, 682.0000])\n",
      "output:tensor([223303.0312])\n",
      "Batch Average Reconstruciton Loss:697116736.0\n",
      "input:tensor([  3.7260,   2.5645,   2.6786,   2.4865, 682.0000])\n",
      "output:tensor([223322.9688])\n",
      "Batch Average Reconstruciton Loss:1841614080.0\n",
      "input:tensor([  3.8743,   2.3500,   2.9076,   2.3090, 682.0000])\n",
      "output:tensor([223325.6562])\n",
      "Batch Average Reconstruciton Loss:1070490048.0\n",
      "input:tensor([  3.6787,   2.5575,   2.6228,   2.5145, 682.0000])\n",
      "output:tensor([223323.4375])\n",
      "Batch Average Reconstruciton Loss:2147355008.0\n",
      "input:tensor([  3.7910,   1.7760,   3.2257,   1.7340, 682.0000])\n",
      "output:tensor([223343.6562])\n",
      "Batch Average Reconstruciton Loss:1469061888.0\n",
      "input:tensor([  4.6240,   2.9405,   3.3949,   2.9015, 682.0000])\n",
      "output:tensor([223291.3281])\n",
      "Batch Average Reconstruciton Loss:76708312.0\n",
      "input:tensor([  4.2867,   2.4535,   3.2971,   2.4095, 682.0000])\n",
      "output:tensor([223313.4688])\n",
      "Batch Average Reconstruciton Loss:65634808.0\n",
      "input:tensor([  3.8890,   2.3775,   2.9075,   2.3435, 682.0000])\n",
      "output:tensor([223324.3438])\n",
      "Batch Average Reconstruciton Loss:1008294656.0\n",
      "input:tensor([  4.7540,   3.6510,   1.6255,   3.5880, 682.0000])\n",
      "output:tensor([223284.1562])\n",
      "Batch Average Reconstruciton Loss:213690496.0\n",
      "input:tensor([  3.7037,   2.0940,   2.8662,   2.0590, 682.0000])\n",
      "output:tensor([223336.9062])\n",
      "Batch Average Reconstruciton Loss:1980792320.0\n",
      "input:tensor([  3.3177,   2.0045,   2.4896,   1.9665, 682.0000])\n",
      "output:tensor([223348.3281])\n",
      "Batch Average Reconstruciton Loss:5723932160.0\n",
      "input:tensor([  4.0280,   3.1075,   2.8463,   3.0895, 682.0000])\n",
      "output:tensor([223297.0625])\n",
      "Batch Average Reconstruciton Loss:528031584.0\n",
      "input:tensor([  4.0463,   3.1275,   2.8580,   3.0925, 682.0000])\n",
      "output:tensor([223296.4531])\n",
      "Batch Average Reconstruciton Loss:478014688.0\n",
      "input:tensor([  4.5097,   2.4105,   3.6334,   2.2795, 682.0000])\n",
      "output:tensor([223311.2344])\n",
      "Batch Average Reconstruciton Loss:11150486.0\n",
      "input:tensor([  4.4997,   2.7890,   2.5174,   2.6930, 682.0000])\n",
      "output:tensor([223308.9062])\n",
      "Batch Average Reconstruciton Loss:8110570.0\n",
      "input:tensor([  3.7573,   2.2080,   2.8808,   2.1300, 682.0000])\n",
      "output:tensor([223333.1875])\n",
      "Batch Average Reconstruciton Loss:1655172608.0\n",
      "input:tensor([  4.8690,   2.4055,   4.0473,   2.3305, 682.0000])\n",
      "output:tensor([223301.7500])\n",
      "Batch Average Reconstruciton Loss:382740320.0\n",
      "input:tensor([  4.0270,   2.0860,   3.2694,   2.0160, 682.0000])\n",
      "output:tensor([223330.3125])\n",
      "Batch Average Reconstruciton Loss:529307680.0\n",
      "input:tensor([  4.0207,   2.5620,   2.9635,   2.4550, 682.0000])\n",
      "output:tensor([223317.5938])\n",
      "Batch Average Reconstruciton Loss:547906688.0\n",
      "input:tensor([  4.5373,   2.9110,   3.3322,   2.8510, 682.0000])\n",
      "output:tensor([223294.5312])\n",
      "Batch Average Reconstruciton Loss:21748524.0\n",
      "input:tensor([  6.4930,   1.7295,   6.9252,   1.6955, 682.0000])\n",
      "output:tensor([223276.7656])\n",
      "Batch Average Reconstruciton Loss:4969794048.0\n",
      "input:tensor([  9.4907,   1.6775,  11.1804,   1.6595, 682.0000])\n",
      "output:tensor([223200.7656])\n",
      "Batch Average Reconstruciton Loss:14084174848.0\n",
      "input:tensor([  6.5397,   4.0365,   4.8446,   4.0175, 682.0000])\n",
      "output:tensor([223215.7812])\n",
      "Batch Average Reconstruciton Loss:5115937280.0\n",
      "input:tensor([  3.4590,   1.7615,   2.6813,   1.6645, 682.0000])\n",
      "output:tensor([223354.9219])\n",
      "Batch Average Reconstruciton Loss:4023755520.0\n",
      "input:tensor([  3.9880,   2.4875,   2.9571,   2.4265, 682.0000])\n",
      "output:tensor([223319.5312])\n",
      "Batch Average Reconstruciton Loss:646505344.0\n",
      "input:tensor([  4.3190,   2.5140,   3.2986,   2.4740, 682.0000])\n",
      "output:tensor([223310.8594])\n",
      "Batch Average Reconstruciton Loss:40604176.0\n",
      "input:tensor([  4.1223,   3.4060,   2.9368,   3.2960, 682.0000])\n",
      "output:tensor([223286.7188])\n",
      "Batch Average Reconstruciton Loss:301136384.0\n",
      "input:tensor([  6.7867,   7.5935,   6.2630,   7.5595, 682.0000])\n",
      "output:tensor([223071.3281])\n",
      "Batch Average Reconstruciton Loss:5913968128.0\n",
      "input:tensor([  4.2017,   3.2950,   1.6827,   3.2880, 682.0000])\n",
      "output:tensor([223300.7188])\n",
      "Batch Average Reconstruciton Loss:163744816.0\n",
      "input:tensor([  4.2343,   2.3330,   3.3184,   2.2980, 682.0000])\n",
      "output:tensor([223317.9062])\n",
      "Batch Average Reconstruciton Loss:120057904.0\n",
      "input:tensor([  3.1320,   1.7230,   2.4593,   1.6810, 682.0000])\n",
      "output:tensor([223360.7500])\n",
      "Batch Average Reconstruciton Loss:8718003200.0\n",
      "input:tensor([  3.1760,   2.9910,   2.4163,   2.9570, 682.0000])\n",
      "output:tensor([223315.2812])\n",
      "Batch Average Reconstruciton Loss:7925934592.0\n",
      "input:tensor([  3.7873,   2.2485,   2.8673,   2.2135, 682.0000])\n",
      "output:tensor([223330.5000])\n",
      "Batch Average Reconstruciton Loss:1489612672.0\n",
      "input:tensor([  4.7440,   2.4165,   3.8829,   2.3805, 682.0000])\n",
      "output:tensor([223303.4688])\n",
      "Batch Average Reconstruciton Loss:201568112.0\n",
      "input:tensor([  4.1977,   2.2975,   3.2976,   2.2535, 682.0000])\n",
      "output:tensor([223320.])\n",
      "Batch Average Reconstruciton Loss:169052000.0\n",
      "input:tensor([  4.2810,   2.3250,   2.9818,   2.2210, 682.0000])\n",
      "output:tensor([223323.0156])\n",
      "Batch Average Reconstruciton Loss:70542936.0\n",
      "input:tensor([  3.1320,   1.7780,   2.4446,   1.7600, 682.0000])\n",
      "output:tensor([223358.3438])\n",
      "Batch Average Reconstruciton Loss:8718452736.0\n",
      "input:tensor([  3.5253,   1.8565,   2.8475,   1.8205, 682.0000])\n",
      "output:tensor([223347.5312])\n",
      "Batch Average Reconstruciton Loss:3369160448.0\n",
      "input:tensor([  4.4217,   3.1165,   2.2076,   3.0985, 682.0000])\n",
      "output:tensor([223299.4062])\n",
      "Batch Average Reconstruciton Loss:1103747.25\n",
      "input:tensor([  4.6303,   3.0000,   3.3808,   2.9660, 682.0000])\n",
      "output:tensor([223289.1719])\n",
      "Batch Average Reconstruciton Loss:81905608.0\n",
      "input:tensor([  4.7560,   4.2110,   3.4764,   4.1050, 682.0000])\n",
      "output:tensor([223245.3906])\n",
      "Batch Average Reconstruciton Loss:215103008.0\n",
      "input:tensor([  3.7113,   2.1305,   2.8654,   2.0535, 682.0000])\n",
      "output:tensor([223336.5938])\n",
      "Batch Average Reconstruciton Loss:1931814016.0\n",
      "input:tensor([  4.0987,   2.1615,   3.2820,   2.1225, 682.0000])\n",
      "output:tensor([223325.9375])\n",
      "Batch Average Reconstruciton Loss:349841952.0\n",
      "input:tensor([  4.3300,   1.9115,   3.8034,   1.9045, 682.0000])\n",
      "output:tensor([223326.0312])\n",
      "Batch Average Reconstruciton Loss:33327168.0\n",
      "input:tensor([  3.6970,   2.1205,   2.8650,   2.0435, 682.0000])\n",
      "output:tensor([223337.1094])\n",
      "Batch Average Reconstruciton Loss:2024000256.0\n",
      "input:tensor([ 22.1103,   1.9130,  28.7139,   1.8080, 682.0000])\n",
      "output:tensor([222872.5312])\n",
      "Batch Average Reconstruciton Loss:31686324224.0\n",
      "input:tensor([  6.3773,   2.7905,   5.6151,   2.7105, 682.0000])\n",
      "output:tensor([223255.2812])\n",
      "Batch Average Reconstruciton Loss:4583869952.0\n",
      "input:tensor([  4.9993,   3.5410,   3.5524,   3.5240, 682.0000])\n",
      "output:tensor([223263.6562])\n",
      "Batch Average Reconstruciton Loss:616909184.0\n",
      "input:tensor([ 14.4490,   3.1740,  16.2467,   3.1380, 682.0000])\n",
      "output:tensor([223040.7812])\n",
      "Batch Average Reconstruciton Loss:23834970112.0\n",
      "input:tensor([  3.9023,   2.5100,   2.6730,   2.4280, 682.0000])\n",
      "output:tensor([223323.1875])\n",
      "Batch Average Reconstruciton Loss:953809856.0\n",
      "input:tensor([  3.6493,   2.4845,   2.6134,   2.4665, 682.0000])\n",
      "output:tensor([223325.8281])\n",
      "Batch Average Reconstruciton Loss:2352654592.0\n",
      "input:tensor([  3.7717,   2.2295,   2.8745,   2.1765, 682.0000])\n",
      "output:tensor([223331.7188])\n",
      "Batch Average Reconstruciton Loss:1574683392.0\n",
      "input:tensor([  4.1257,   2.3065,   2.5932,   2.3015, 682.0000])\n",
      "output:tensor([223327.])\n",
      "Batch Average Reconstruciton Loss:293060160.0\n",
      "input:tensor([  4.3553,   3.0595,   3.0981,   3.0405, 682.0000])\n",
      "output:tensor([223292.6250])\n",
      "Batch Average Reconstruciton Loss:20020032.0\n",
      "input:tensor([  4.8240,   2.4515,   3.9355,   2.4165, 682.0000])\n",
      "output:tensor([223300.7812])\n",
      "Batch Average Reconstruciton Loss:311973856.0\n",
      "input:tensor([ 11.6030,   2.2570,  13.4053,   2.1930, 682.0000])\n",
      "output:tensor([223134.9219])\n",
      "Batch Average Reconstruciton Loss:18944747520.0\n",
      "input:tensor([  3.5353,   2.3450,   2.5569,   2.3110, 682.0000])\n",
      "output:tensor([223333.0312])\n",
      "Batch Average Reconstruciton Loss:3279047680.0\n",
      "input:tensor([  3.9677,   2.4605,   2.9348,   2.4435, 682.0000])\n",
      "output:tensor([223319.8125])\n",
      "Batch Average Reconstruciton Loss:712953408.0\n",
      "input:tensor([  3.9707,   2.4455,   2.9529,   2.4035, 682.0000])\n",
      "output:tensor([223320.7812])\n",
      "Batch Average Reconstruciton Loss:702844736.0\n",
      "input:tensor([  3.6053,   1.9420,   2.8507,   1.9230, 682.0000])\n",
      "output:tensor([223343.1406])\n",
      "Batch Average Reconstruciton Loss:2683743488.0\n",
      "input:tensor([ 28.8767,  21.9395,  20.4177,  21.8435, 682.0000])\n",
      "output:tensor([222174.1562])\n",
      "Batch Average Reconstruciton Loss:35276787712.0\n",
      "input:tensor([  4.2790,   3.8145,   3.1237,   3.7025, 682.0000])\n",
      "output:tensor([223268.5312])\n",
      "Batch Average Reconstruciton Loss:73298744.0\n",
      "input:tensor([  4.3070,   2.6705,   3.1881,   2.6285, 682.0000])\n",
      "output:tensor([223306.6250])\n",
      "Batch Average Reconstruciton Loss:49229520.0\n",
      "input:tensor([ 19.4503,   2.5735,  24.0001,   2.5345, 682.0000])\n",
      "output:tensor([222926.0781])\n",
      "Batch Average Reconstruciton Loss:29557889024.0\n",
      "input:tensor([  4.1990,   2.3590,   3.2776,   2.2840, 682.0000])\n",
      "output:tensor([223318.7812])\n",
      "Batch Average Reconstruciton Loss:167138848.0\n",
      "input:tensor([  3.8973,   2.4100,   2.9069,   2.3320, 682.0000])\n",
      "output:tensor([223324.2188])\n",
      "Batch Average Reconstruciton Loss:973988032.0\n",
      "input:tensor([  4.5510,   3.9640,   3.3272,   3.9290, 682.0000])\n",
      "output:tensor([223256.2031])\n",
      "Batch Average Reconstruciton Loss:27901670.0\n",
      "input:tensor([  4.0553,   2.1330,   3.2664,   2.0630, 682.0000])\n",
      "output:tensor([223328.3906])\n",
      "Batch Average Reconstruciton Loss:453162304.0\n",
      "input:tensor([  3.4133,   2.2060,   2.3306,   2.0590, 682.0000])\n",
      "output:tensor([223344.5625])\n",
      "Batch Average Reconstruciton Loss:4526657024.0\n",
      "input:tensor([  3.6737,   2.3330,   2.7017,   2.3150, 682.0000])\n",
      "output:tensor([223330.0312])\n",
      "Batch Average Reconstruciton Loss:2180887040.0\n",
      "input:tensor([  4.1433,   2.2995,   3.2559,   2.2375, 682.0000])\n",
      "output:tensor([223321.3906])\n",
      "Batch Average Reconstruciton Loss:259197424.0\n",
      "input:tensor([  4.2193,   2.8500,   2.0342,   2.8340, 682.0000])\n",
      "output:tensor([223312.8750])\n",
      "Batch Average Reconstruciton Loss:139124976.0\n",
      "input:tensor([  3.9270,   2.4050,   2.9115,   2.3610, 682.0000])\n",
      "output:tensor([223323.1562])\n",
      "Batch Average Reconstruciton Loss:857719232.0\n",
      "input:tensor([  3.3673,   2.0960,   2.4966,   2.0610, 682.0000])\n",
      "output:tensor([223344.3750])\n",
      "Batch Average Reconstruciton Loss:5076651520.0\n",
      "input:tensor([  5.0490,   1.7780,   4.9014,   1.7360, 682.0000])\n",
      "output:tensor([223312.2656])\n",
      "Batch Average Reconstruciton Loss:720238848.0\n",
      "input:tensor([  4.8517,   2.7510,   3.7278,   2.7470, 682.0000])\n",
      "output:tensor([223291.2344])\n",
      "Batch Average Reconstruciton Loss:354389440.0\n",
      "input:tensor([  3.5490,   2.3540,   2.5669,   2.3500, 682.0000])\n",
      "output:tensor([223331.7031])\n",
      "Batch Average Reconstruciton Loss:3156562944.0\n",
      "input:tensor([  4.7087,   2.1470,   3.9171,   2.0470, 682.0000])\n",
      "output:tensor([223314.7031])\n",
      "Batch Average Reconstruciton Loss:159762096.0\n",
      "input:tensor([  4.0597,   1.7830,   3.5896,   1.7080, 682.0000])\n",
      "output:tensor([223337.4688])\n",
      "Batch Average Reconstruciton Loss:441736608.0\n",
      "input:tensor([  4.7310,   3.1425,   3.4159,   3.1075, 682.0000])\n",
      "output:tensor([223282.6719])\n",
      "Batch Average Reconstruciton Loss:185005472.0\n",
      "input:tensor([  3.3560,   2.0745,   2.4990,   2.0325, 682.0000])\n",
      "output:tensor([223345.4219])\n",
      "Batch Average Reconstruciton Loss:5219278848.0\n",
      "input:tensor([  3.8137,   2.1050,   2.9808,   2.0630, 682.0000])\n",
      "output:tensor([223334.2969])\n",
      "Batch Average Reconstruciton Loss:1352967296.0\n",
      "input:tensor([  3.7750,   2.7625,   2.6710,   2.7215, 682.0000])\n",
      "output:tensor([223314.5312])\n",
      "Batch Average Reconstruciton Loss:1557602176.0\n",
      "input:tensor([  3.4510,   1.7235,   2.8498,   1.6845, 682.0000])\n",
      "output:tensor([223353.0938])\n",
      "Batch Average Reconstruciton Loss:4108797952.0\n",
      "input:tensor([  4.3167,   2.0120,   3.6726,   1.9680, 682.0000])\n",
      "output:tensor([223324.9062])\n",
      "Batch Average Reconstruciton Loss:42017540.0\n",
      "input:tensor([  4.3770,   2.5765,   2.6168,   2.4705, 682.0000])\n",
      "output:tensor([223317.])\n",
      "Batch Average Reconstruciton Loss:11035684.0\n",
      "input:tensor([  6.4207,   5.7140,   4.7320,   5.6340, 682.0000])\n",
      "output:tensor([223159.8906])\n",
      "Batch Average Reconstruciton Loss:4714043392.0\n",
      "input:tensor([  3.5590,   1.9255,   2.8162,   1.8905, 682.0000])\n",
      "output:tensor([223345.0156])\n",
      "Batch Average Reconstruciton Loss:3067496448.0\n",
      "input:tensor([  3.9860,   2.5215,   2.9322,   2.4765, 682.0000])\n",
      "output:tensor([223318.1875])\n",
      "Batch Average Reconstruciton Loss:652946240.0\n",
      "input:tensor([  3.6423,   2.5630,   2.6023,   2.4590, 682.0000])\n",
      "output:tensor([223325.3750])\n",
      "Batch Average Reconstruciton Loss:2403707904.0\n",
      "input:tensor([  3.5567,   2.4360,   2.5571,   2.4030, 682.0000])\n",
      "output:tensor([223329.5312])\n",
      "Batch Average Reconstruciton Loss:3089521920.0\n",
      "input:tensor([  4.9013,   3.3940,   3.4977,   3.3600, 682.0000])\n",
      "output:tensor([223270.9688])\n",
      "Batch Average Reconstruciton Loss:435847840.0\n",
      "input:tensor([  4.1377,   2.9215,   2.6373,   2.8105, 682.0000])\n",
      "output:tensor([223307.1250])\n",
      "Batch Average Reconstruciton Loss:270335264.0\n",
      "input:tensor([  3.9180,   2.3265,   2.2629,   2.2495, 682.0000])\n",
      "output:tensor([223333.8750])\n",
      "Batch Average Reconstruciton Loss:891388224.0\n",
      "input:tensor([  4.5910,   2.9170,   3.3658,   2.8990, 682.0000])\n",
      "output:tensor([223292.3125])\n",
      "Batch Average Reconstruciton Loss:52089600.0\n",
      "input:tensor([ 32.2697,  23.8290,  22.8246,  23.7870, 682.0000])\n",
      "output:tensor([222043.4844])\n",
      "Batch Average Reconstruciton Loss:36596641792.0\n",
      "input:tensor([  7.5040,   7.0365,   2.0501,   7.0305, 682.0000])\n",
      "output:tensor([223128.0625])\n",
      "Batch Average Reconstruciton Loss:8268639744.0\n",
      "input:tensor([  3.8253,   1.7930,   3.2644,   1.7550, 682.0000])\n",
      "output:tensor([223342.1719])\n",
      "Batch Average Reconstruciton Loss:1294691968.0\n",
      "input:tensor([  3.3780,   2.2655,   2.2404,   2.1285, 682.0000])\n",
      "output:tensor([223343.5156])\n",
      "Batch Average Reconstruciton Loss:4945111040.0\n",
      "input:tensor([  3.6347,   2.5430,   2.5906,   2.5380, 682.0000])\n",
      "output:tensor([223323.8125])\n",
      "Batch Average Reconstruciton Loss:2460476160.0\n",
      "input:tensor([  3.9180,   2.3855,   2.9189,   2.3695, 682.0000])\n",
      "output:tensor([223323.1719])\n",
      "Batch Average Reconstruciton Loss:892027392.0\n",
      "input:tensor([  3.8600,   2.3890,   2.8756,   2.2840, 682.0000])\n",
      "output:tensor([223326.3750])\n",
      "Batch Average Reconstruciton Loss:1133576320.0\n",
      "input:tensor([ 20.9010,   2.2215,  26.5634,   2.2025, 682.0000])\n",
      "output:tensor([222895.2500])\n",
      "Batch Average Reconstruciton Loss:30776825856.0\n",
      "input:tensor([  4.8247,   2.4765,   3.9266,   2.4065, 682.0000])\n",
      "output:tensor([223300.8750])\n",
      "Batch Average Reconstruciton Loss:312967072.0\n",
      "input:tensor([  3.8563,   2.8220,   2.7277,   2.8050, 682.0000])\n",
      "output:tensor([223310.3281])\n",
      "Batch Average Reconstruciton Loss:1151154816.0\n",
      "input:tensor([  3.8257,   2.5245,   2.7791,   2.4645, 682.0000])\n",
      "output:tensor([223321.8125])\n",
      "Batch Average Reconstruciton Loss:1294501888.0\n",
      "input:tensor([  4.0170,   2.0925,   3.2584,   2.0735, 682.0000])\n",
      "output:tensor([223329.0469])\n",
      "Batch Average Reconstruciton Loss:557949440.0\n",
      "input:tensor([  3.8153,   2.7030,   2.7119,   2.6600, 682.0000])\n",
      "output:tensor([223315.8438])\n",
      "Batch Average Reconstruciton Loss:1345947392.0\n",
      "input:tensor([  4.7010,   2.5885,   3.6798,   2.5315, 682.0000])\n",
      "output:tensor([223300.4844])\n",
      "Batch Average Reconstruciton Loss:150834864.0\n",
      "input:tensor([  4.4890,   2.7300,   3.3600,   2.6700, 682.0000])\n",
      "output:tensor([223301.1875])\n",
      "Batch Average Reconstruciton Loss:5364724.5\n",
      "input:tensor([  3.9957,   2.5475,   2.9331,   2.5125, 682.0000])\n",
      "output:tensor([223316.9062])\n",
      "Batch Average Reconstruciton Loss:622606976.0\n",
      "input:tensor([  9.1517,   1.7140,  10.6351,   1.7080, 682.0000])\n",
      "output:tensor([223208.5938])\n",
      "Batch Average Reconstruciton Loss:13181931520.0\n",
      "input:tensor([  3.2663,   1.7565,   2.6073,   1.7175, 682.0000])\n",
      "output:tensor([223356.5000])\n",
      "Batch Average Reconstruciton Loss:6455720960.0\n",
      "input:tensor([  6.9480,   2.4270,   6.8134,   2.3060, 682.0000])\n",
      "output:tensor([223250.4062])\n",
      "Batch Average Reconstruciton Loss:6476291072.0\n",
      "input:tensor([  4.0127,   2.0860,   3.2595,   2.0270, 682.0000])\n",
      "output:tensor([223330.2969])\n",
      "Batch Average Reconstruciton Loss:570574592.0\n",
      "input:tensor([  4.4473,   2.6785,   3.3335,   2.6435, 682.0000])\n",
      "output:tensor([223303.1250])\n",
      "Batch Average Reconstruciton Loss:61566.015625\n",
      "input:tensor([  3.5463,   1.8645,   2.8500,   1.8305, 682.0000])\n",
      "output:tensor([223346.9219])\n",
      "Batch Average Reconstruciton Loss:3178600448.0\n",
      "input:tensor([  4.6120,   3.1560,   3.2987,   3.1380, 682.0000])\n",
      "output:tensor([223284.2656])\n",
      "Batch Average Reconstruciton Loss:67129600.0\n",
      "input:tensor([  3.8510,   2.3190,   2.8931,   2.3140, 682.0000])\n",
      "output:tensor([223326.2656])\n",
      "Batch Average Reconstruciton Loss:1174346112.0\n",
      "input:tensor([  4.1693,   2.3375,   3.2371,   2.3025, 682.0000])\n",
      "output:tensor([223319.2969])\n",
      "Batch Average Reconstruciton Loss:213414208.0\n",
      "input:tensor([  4.1510,   3.2070,   1.6723,   3.1120, 682.0000])\n",
      "output:tensor([223306.7344])\n",
      "Batch Average Reconstruciton Loss:245619904.0\n",
      "input:tensor([  4.1913,   2.8165,   3.0173,   2.7805, 682.0000])\n",
      "output:tensor([223304.3281])\n",
      "Batch Average Reconstruciton Loss:178881840.0\n",
      "input:tensor([  4.3357,   3.0890,   3.0770,   3.0720, 682.0000])\n",
      "output:tensor([223291.9531])\n",
      "Batch Average Reconstruciton Loss:30338580.0\n",
      "input:tensor([  3.7350,   2.1405,   2.8689,   2.0985, 682.0000])\n",
      "output:tensor([223335.0625])\n",
      "Batch Average Reconstruciton Loss:1785986816.0\n",
      "input:tensor([  3.5933,   2.4395,   2.5868,   2.4215, 682.0000])\n",
      "output:tensor([223328.3125])\n",
      "Batch Average Reconstruciton Loss:2781369088.0\n",
      "input:tensor([  4.2827,   2.4890,   3.2752,   2.4500, 682.0000])\n",
      "output:tensor([223312.3594])\n",
      "Batch Average Reconstruciton Loss:69199784.0\n",
      "input:tensor([  4.0677,   2.1675,   3.2452,   2.1315, 682.0000])\n",
      "output:tensor([223326.3594])\n",
      "Batch Average Reconstruciton Loss:422205536.0\n",
      "input:tensor([  3.9513,   2.4990,   2.7855,   2.3270, 682.0000])\n",
      "output:tensor([223324.1250])\n",
      "Batch Average Reconstruciton Loss:768945984.0\n",
      "input:tensor([  4.1547,   2.7875,   2.9998,   2.7105, 682.0000])\n",
      "output:tensor([223306.9844])\n",
      "Batch Average Reconstruciton Loss:239043008.0\n",
      "input:tensor([  4.0437,   2.1195,   3.2856,   2.0785, 682.0000])\n",
      "output:tensor([223328.0469])\n",
      "Batch Average Reconstruciton Loss:483733984.0\n",
      "input:tensor([  6.9913,   3.0200,   6.1603,   2.9830, 682.0000])\n",
      "output:tensor([223233.6562])\n",
      "Batch Average Reconstruciton Loss:6616790528.0\n",
      "input:tensor([ 36.6497,   2.4850,  48.3792,   2.4500, 682.0000])\n",
      "output:tensor([222485.0938])\n",
      "Batch Average Reconstruciton Loss:38188232704.0\n",
      "input:tensor([  4.4937,   2.7865,   3.3355,   2.7465, 682.0000])\n",
      "output:tensor([223298.8906])\n",
      "Batch Average Reconstruciton Loss:6471379.5\n",
      "input:tensor([  4.3417,   2.1005,   3.7176,   1.8875, 682.0000])\n",
      "output:tensor([223325.2344])\n",
      "Batch Average Reconstruciton Loss:26612862.0\n",
      "input:tensor([  3.4513,   2.2465,   2.5247,   2.2115, 682.0000])\n",
      "output:tensor([223337.7969])\n",
      "Batch Average Reconstruciton Loss:4107169536.0\n",
      "input:tensor([  4.4657,   4.2760,   3.4365,   4.1970, 682.0000])\n",
      "output:tensor([223245.8906])\n",
      "Batch Average Reconstruciton Loss:1225206.875\n",
      "input:tensor([ 25.7300,  18.7380,  18.2151,  18.7030, 682.0000])\n",
      "output:tensor([222344.])\n",
      "Batch Average Reconstruciton Loss:33778763776.0\n",
      "input:tensor([  4.4740,   2.7525,   3.3244,   2.7175, 682.0000])\n",
      "output:tensor([223300.3125])\n",
      "Batch Average Reconstruciton Loss:2478459.75\n",
      "input:tensor([  3.1457,   1.8135,   2.4278,   1.7525, 682.0000])\n",
      "output:tensor([223358.2188])\n",
      "Batch Average Reconstruciton Loss:8463223808.0\n",
      "input:tensor([  4.1913,   2.8450,   3.0048,   2.8100, 682.0000])\n",
      "output:tensor([223303.4219])\n",
      "Batch Average Reconstruciton Loss:178906096.0\n",
      "input:tensor([  3.8587,   2.3665,   2.8792,   2.3065, 682.0000])\n",
      "output:tensor([223326.])\n",
      "Batch Average Reconstruciton Loss:1139602560.0\n",
      "input:tensor([  4.4203,   1.8195,   3.9905,   1.8015, 682.0000])\n",
      "output:tensor([223326.6094])\n",
      "Batch Average Reconstruciton Loss:1188951.75\n",
      "input:tensor([  3.2317,   1.8910,   2.4522,   1.8570, 682.0000])\n",
      "output:tensor([223353.5781])\n",
      "Batch Average Reconstruciton Loss:6990368256.0\n",
      "input:tensor([  5.1033,   4.3040,   3.6764,   4.2690, 682.0000])\n",
      "output:tensor([223234.4375])\n",
      "Batch Average Reconstruciton Loss:832405440.0\n",
      "input:tensor([ 16.5767,   2.1080,  20.6706,   1.9860, 682.0000])\n",
      "output:tensor([223011.])\n",
      "Batch Average Reconstruciton Loss:26623795200.0\n",
      "input:tensor([  4.9167,   2.4235,   4.0674,   2.3875, 682.0000])\n",
      "output:tensor([223299.4062])\n",
      "Batch Average Reconstruciton Loss:463816800.0\n",
      "input:tensor([  3.7983,   2.2980,   2.8403,   2.2800, 682.0000])\n",
      "output:tensor([223328.4688])\n",
      "Batch Average Reconstruciton Loss:1431754496.0\n",
      "input:tensor([  7.5890,   2.3740,   7.6587,   2.3300, 682.0000])\n",
      "output:tensor([223234.4844])\n",
      "Batch Average Reconstruciton Loss:8559669760.0\n",
      "input:tensor([  3.5453,   2.2845,   2.5979,   2.2235, 682.0000])\n",
      "output:tensor([223335.3125])\n",
      "Batch Average Reconstruciton Loss:3188712704.0\n",
      "input:tensor([  3.6620,   2.5170,   2.6221,   2.4750, 682.0000])\n",
      "output:tensor([223325.0312])\n",
      "Batch Average Reconstruciton Loss:2262426368.0\n",
      "input:tensor([  3.7480,   2.1170,   2.9204,   2.0830, 682.0000])\n",
      "output:tensor([223335.0156])\n",
      "Batch Average Reconstruciton Loss:1708994304.0\n",
      "input:tensor([ 14.6570,  10.6550,  10.2443,  10.4850, 682.0000])\n",
      "output:tensor([222839.1406])\n",
      "Batch Average Reconstruciton Loss:24074049536.0\n",
      "input:tensor([  6.9020,   5.0960,   4.7455,   5.0220, 682.0000])\n",
      "output:tensor([223176.5625])\n",
      "Batch Average Reconstruciton Loss:6312391680.0\n",
      "input:tensor([  4.3680,   2.5880,   3.3010,   2.5540, 682.0000])\n",
      "output:tensor([223307.5156])\n",
      "Batch Average Reconstruciton Loss:14428484.0\n",
      "input:tensor([  3.8740,   3.4095,   2.8330,   3.3325, 682.0000])\n",
      "output:tensor([223289.5312])\n",
      "Batch Average Reconstruciton Loss:1074296960.0\n",
      "input:tensor([  5.7293,   4.0990,   4.0652,   4.0650, 682.0000])\n",
      "output:tensor([223230.9219])\n",
      "Batch Average Reconstruciton Loss:2508699648.0\n",
      "input:tensor([  3.5703,   2.1495,   2.6827,   2.1135, 682.0000])\n",
      "output:tensor([223338.3438])\n",
      "Batch Average Reconstruciton Loss:2970975488.0\n",
      "input:tensor([  3.4893,   2.7285,   2.4661,   2.6935, 682.0000])\n",
      "output:tensor([223320.8281])\n",
      "Batch Average Reconstruciton Loss:3717849600.0\n",
      "input:tensor([  3.6133,   2.0685,   2.7997,   2.0345, 682.0000])\n",
      "output:tensor([223339.4688])\n",
      "Batch Average Reconstruciton Loss:2621392128.0\n",
      "input:tensor([  3.6460,   2.5255,   2.6153,   2.4445, 682.0000])\n",
      "output:tensor([223325.9688])\n",
      "Batch Average Reconstruciton Loss:2376858112.0\n",
      "input:tensor([  3.8920,   2.3235,   2.9497,   2.2555, 682.0000])\n",
      "output:tensor([223326.6406])\n",
      "Batch Average Reconstruciton Loss:995740736.0\n",
      "input:tensor([  4.5700,   3.6495,   3.2389,   3.5905, 682.0000])\n",
      "output:tensor([223268.7656])\n",
      "Batch Average Reconstruciton Loss:38449496.0\n",
      "input:tensor([  3.6403,   2.5645,   2.4511,   2.5005, 682.0000])\n",
      "output:tensor([223325.9688])\n",
      "Batch Average Reconstruciton Loss:2418380288.0\n",
      "input:tensor([  4.1213,   2.7600,   2.9784,   2.7000, 682.0000])\n",
      "output:tensor([223308.1094])\n",
      "Batch Average Reconstruciton Loss:302443072.0\n",
      "input:tensor([  3.5923,   1.8760,   2.9106,   1.8040, 682.0000])\n",
      "output:tensor([223346.3281])\n",
      "Batch Average Reconstruciton Loss:2787594240.0\n",
      "input:tensor([ 15.3373,  11.6660,  10.8419,  11.5560, 682.0000])\n",
      "output:tensor([222787.8750])\n",
      "Batch Average Reconstruciton Loss:24998416384.0\n",
      "input:tensor([  4.1527,   2.7800,   2.9952,   2.6770, 682.0000])\n",
      "output:tensor([223307.9688])\n",
      "Batch Average Reconstruciton Loss:242581600.0\n",
      "input:tensor([  4.9643,   2.0475,   4.4991,   1.9685, 682.0000])\n",
      "output:tensor([223308.8125])\n",
      "Batch Average Reconstruciton Loss:551489472.0\n",
      "input:tensor([ 77.8795,  69.8317, 129.8893,  95.4189, 802.0000])\n",
      "output:tensor([257446.9375])\n",
      "Batch Average Reconstruciton Loss:60525318144.0\n",
      "input:tensor([  3.7400,   2.0720,   2.9284,   2.0330, 682.0000])\n",
      "output:tensor([223336.7500])\n",
      "Batch Average Reconstruciton Loss:1755966208.0\n",
      "input:tensor([  3.9310,   2.4820,   2.9149,   2.3730, 682.0000])\n",
      "output:tensor([223321.9688])\n",
      "Batch Average Reconstruciton Loss:842800768.0\n",
      "input:tensor([  3.8410,   2.8215,   2.7161,   2.7865, 682.0000])\n",
      "output:tensor([223311.0781])\n",
      "Batch Average Reconstruciton Loss:1221846528.0\n",
      "input:tensor([  4.3227,   3.0395,   3.0873,   2.9985, 682.0000])\n",
      "output:tensor([223294.3438])\n",
      "Batch Average Reconstruciton Loss:38361376.0\n",
      "input:tensor([  6.2877,   1.8970,   6.4442,   1.8630, 682.0000])\n",
      "output:tensor([223278.1094])\n",
      "Batch Average Reconstruciton Loss:4291443456.0\n",
      "input:tensor([  3.6740,   2.0630,   2.8510,   2.0280, 682.0000])\n",
      "output:tensor([223338.4844])\n",
      "Batch Average Reconstruciton Loss:2177763584.0\n",
      "input:tensor([  4.4380,   2.7410,   3.1866,   2.5210, 682.0000])\n",
      "output:tensor([223307.2031])\n",
      "Batch Average Reconstruciton Loss:47000.88671875\n",
      "input:tensor([  3.9160,   1.9090,   3.2621,   1.8730, 682.0000])\n",
      "output:tensor([223337.0625])\n",
      "Batch Average Reconstruciton Loss:898976512.0\n",
      "input:tensor([  3.0923,   1.7665,   2.4027,   1.6685, 682.0000])\n",
      "output:tensor([223361.6562])\n",
      "Batch Average Reconstruciton Loss:9492867072.0\n",
      "input:tensor([  4.3493,   2.5950,   3.2992,   2.5250, 682.0000])\n",
      "output:tensor([223308.3906])\n",
      "Batch Average Reconstruciton Loss:22777800.0\n",
      "input:tensor([  3.5080,   1.8200,   2.8647,   1.7520, 682.0000])\n",
      "output:tensor([223349.6250])\n",
      "Batch Average Reconstruciton Loss:3532207104.0\n",
      "input:tensor([  4.1450,   1.7755,   3.6747,   1.7305, 682.0000])\n",
      "output:tensor([223335.1719])\n",
      "Batch Average Reconstruciton Loss:255642624.0\n",
      "input:tensor([  5.4723,   4.7725,   3.9960,   4.7025, 682.0000])\n",
      "output:tensor([223211.2500])\n",
      "Batch Average Reconstruciton Loss:1758649088.0\n",
      "input:tensor([  4.9067,   3.2080,   2.5946,   3.1480, 682.0000])\n",
      "output:tensor([223287.8594])\n",
      "Batch Average Reconstruciton Loss:445795072.0\n",
      "input:tensor([  4.9330,   3.6840,   3.4877,   3.6010, 682.0000])\n",
      "output:tensor([223261.6250])\n",
      "Batch Average Reconstruciton Loss:491359264.0\n",
      "input:tensor([  3.4523,   1.7495,   2.8181,   1.7315, 682.0000])\n",
      "output:tensor([223351.9844])\n",
      "Batch Average Reconstruciton Loss:4094722048.0\n",
      "input:tensor([  3.6177,   2.0090,   2.8422,   1.9420, 682.0000])\n",
      "output:tensor([223341.9219])\n",
      "Batch Average Reconstruciton Loss:2587561472.0\n",
      "input:tensor([  3.8200,   1.8050,   3.2656,   1.7390, 682.0000])\n",
      "output:tensor([223342.4844])\n",
      "Batch Average Reconstruciton Loss:1320851072.0\n",
      "input:tensor([  3.5327,   1.8660,   2.8343,   1.8300, 682.0000])\n",
      "output:tensor([223347.2500])\n",
      "Batch Average Reconstruciton Loss:3301737728.0\n",
      "input:tensor([  3.0453,   2.1730,   2.1694,   2.0980, 682.0000])\n",
      "output:tensor([223349.5625])\n",
      "Batch Average Reconstruciton Loss:10484621312.0\n",
      "input:tensor([  3.3183,   2.0305,   2.4833,   1.9955, 682.0000])\n",
      "output:tensor([223347.3750])\n",
      "Batch Average Reconstruciton Loss:5715000832.0\n",
      "input:tensor([ 33.9940,   3.2035,  43.6920,   3.0925, 682.0000])\n",
      "output:tensor([222539.7656])\n",
      "Batch Average Reconstruciton Loss:37387227136.0\n",
      "input:tensor([  4.0010,   3.2075,   2.8368,   3.1375, 682.0000])\n",
      "output:tensor([223295.1875])\n",
      "Batch Average Reconstruciton Loss:607268224.0\n",
      "input:tensor([  4.2007,   3.5860,   3.0357,   3.5520, 682.0000])\n",
      "output:tensor([223276.5156])\n",
      "Batch Average Reconstruciton Loss:165803856.0\n",
      "input:tensor([  4.3663,   3.0930,   3.1029,   3.0590, 682.0000])\n",
      "output:tensor([223291.6406])\n",
      "Batch Average Reconstruciton Loss:15220605.0\n",
      "input:tensor([  4.6477,   2.5050,   3.6801,   2.4710, 682.0000])\n",
      "output:tensor([223303.4688])\n",
      "Batch Average Reconstruciton Loss:97288016.0\n",
      "input:tensor([  4.2300,   2.8845,   3.0308,   2.8675, 682.0000])\n",
      "output:tensor([223300.8594])\n",
      "Batch Average Reconstruciton Loss:125756952.0\n",
      "input:tensor([  4.2297,   2.5155,   3.0247,   2.3745, 682.0000])\n",
      "output:tensor([223317.2188])\n",
      "Batch Average Reconstruciton Loss:125816184.0\n",
      "input:tensor([  4.7923,   1.9075,   4.2813,   1.7725, 682.0000])\n",
      "output:tensor([223319.3438])\n",
      "Batch Average Reconstruciton Loss:266418912.0\n",
      "input:tensor([  4.4567,   3.2105,   3.1581,   3.1925, 682.0000])\n",
      "output:tensor([223285.4688])\n",
      "Batch Average Reconstruciton Loss:486462.65625\n",
      "input:tensor([  5.3030,   3.1025,   4.0131,   3.0685, 682.0000])\n",
      "output:tensor([223271.5938])\n",
      "Batch Average Reconstruciton Loss:1310989824.0\n",
      "input:tensor([  5.4753,   3.7265,   2.8353,   3.7205, 682.0000])\n",
      "output:tensor([223259.4062])\n",
      "Batch Average Reconstruciton Loss:1771013120.0\n",
      "input:tensor([  4.3203,   3.0235,   3.0796,   2.9785, 682.0000])\n",
      "output:tensor([223295.1250])\n",
      "Batch Average Reconstruciton Loss:39902908.0\n",
      "input:tensor([ 17.3313,  12.6765,  12.2681,  12.6065, 682.0000])\n",
      "output:tensor([222714.3125])\n",
      "Batch Average Reconstruciton Loss:27382740992.0\n",
      "input:tensor([  3.5700,   2.4360,   2.5715,   2.3790, 682.0000])\n",
      "output:tensor([223329.8281])\n",
      "Batch Average Reconstruciton Loss:2974739456.0\n",
      "input:tensor([  4.3400,   2.5835,   3.2843,   2.4755, 682.0000])\n",
      "output:tensor([223310.0312])\n",
      "Batch Average Reconstruciton Loss:27677792.0\n",
      "input:tensor([  3.8183,   2.2395,   2.8950,   2.2045, 682.0000])\n",
      "output:tensor([223330.1875])\n",
      "Batch Average Reconstruciton Loss:1329974272.0\n",
      "input:tensor([  4.3493,   3.1720,   3.0774,   3.1330, 682.0000])\n",
      "output:tensor([223289.3906])\n",
      "Batch Average Reconstruciton Loss:22959520.0\n",
      "input:tensor([  4.2223,   2.8975,   3.0295,   2.8285, 682.0000])\n",
      "output:tensor([223301.8125])\n",
      "Batch Average Reconstruciton Loss:135470688.0\n",
      "input:tensor([  3.5760,   2.3955,   2.5859,   2.3615, 682.0000])\n",
      "output:tensor([223330.4688])\n",
      "Batch Average Reconstruciton Loss:2924055040.0\n",
      "input:tensor([  3.7557,   2.1905,   2.8726,   2.1305, 682.0000])\n",
      "output:tensor([223333.4688])\n",
      "Batch Average Reconstruciton Loss:1664683392.0\n",
      "input:tensor([  3.5970,   2.4525,   2.5814,   2.3575, 682.0000])\n",
      "output:tensor([223329.8125])\n",
      "Batch Average Reconstruciton Loss:2751546624.0\n",
      "input:tensor([  3.8883,   2.3860,   2.9071,   2.3420, 682.0000])\n",
      "output:tensor([223324.3125])\n",
      "Batch Average Reconstruciton Loss:1011092928.0\n",
      "input:tensor([  5.1050,   3.7815,   2.4020,   3.7365, 682.0000])\n",
      "output:tensor([223267.])\n",
      "Batch Average Reconstruciton Loss:837986688.0\n",
      "input:tensor([ 26.7500,  20.1895,  18.9110,  20.1725, 682.0000])\n",
      "output:tensor([222273.4375])\n",
      "Batch Average Reconstruciton Loss:34295128064.0\n",
      "input:tensor([  4.5087,   2.7760,   2.5947,   2.7620, 682.0000])\n",
      "output:tensor([223306.3750])\n",
      "Batch Average Reconstruciton Loss:10793689.0\n",
      "input:tensor([  3.7843,   1.7315,   3.2769,   1.7125, 682.0000])\n",
      "output:tensor([223344.2031])\n",
      "Batch Average Reconstruciton Loss:1504570752.0\n",
      "input:tensor([  4.3587,   3.0360,   3.1167,   2.9890, 682.0000])\n",
      "output:tensor([223293.9375])\n",
      "Batch Average Reconstruciton Loss:18481938.0\n",
      "input:tensor([  3.9253,   2.4595,   2.7275,   2.3645, 682.0000])\n",
      "output:tensor([223324.5000])\n",
      "Batch Average Reconstruciton Loss:863919040.0\n",
      "input:tensor([  3.8427,   2.2540,   2.9160,   2.2430, 682.0000])\n",
      "output:tensor([223328.5781])\n",
      "Batch Average Reconstruciton Loss:1212809984.0\n",
      "input:tensor([  3.6420,   2.5270,   2.6070,   2.4460, 682.0000])\n",
      "output:tensor([223326.0312])\n",
      "Batch Average Reconstruciton Loss:2406095616.0\n",
      "input:tensor([  3.6103,   2.4340,   2.5985,   2.4000, 682.0000])\n",
      "output:tensor([223328.6094])\n",
      "Batch Average Reconstruciton Loss:2645907968.0\n",
      "input:tensor([ 34.6067,   3.3330,  44.2928,   3.2980, 682.0000])\n",
      "output:tensor([222520.2969])\n",
      "Batch Average Reconstruciton Loss:37579874304.0\n",
      "input:tensor([  3.7637,   2.6785,   2.6717,   2.6445, 682.0000])\n",
      "output:tensor([223317.4688])\n",
      "Batch Average Reconstruciton Loss:1620507776.0\n",
      "input:tensor([  3.3647,   2.1130,   2.4934,   2.0540, 682.0000])\n",
      "output:tensor([223344.4375])\n",
      "Batch Average Reconstruciton Loss:5110042624.0\n",
      "input:tensor([  3.6017,   2.4440,   2.5919,   2.4020, 682.0000])\n",
      "output:tensor([223328.6250])\n",
      "Batch Average Reconstruciton Loss:2714344960.0\n",
      "input:tensor([  4.0293,   2.7965,   2.8997,   2.6305, 682.0000])\n",
      "output:tensor([223311.2969])\n",
      "Batch Average Reconstruciton Loss:523663872.0\n",
      "input:tensor([  3.9907,   2.0785,   3.2359,   1.9775, 682.0000])\n",
      "output:tensor([223332.1094])\n",
      "Batch Average Reconstruciton Loss:637456000.0\n",
      "input:tensor([  3.7530,   2.7205,   2.6611,   2.6615, 682.0000])\n",
      "output:tensor([223316.8125])\n",
      "Batch Average Reconstruciton Loss:1681425408.0\n",
      "input:tensor([  3.1607,   1.8205,   2.4423,   1.7575, 682.0000])\n",
      "output:tensor([223357.7188])\n",
      "Batch Average Reconstruciton Loss:8190300672.0\n",
      "input:tensor([  3.9770,   2.4225,   2.9850,   2.3185, 682.0000])\n",
      "output:tensor([223322.7188])\n",
      "Batch Average Reconstruciton Loss:681799040.0\n",
      "input:tensor([  4.0023,   2.4945,   2.7720,   2.4165, 682.0000])\n",
      "output:tensor([223321.5312])\n",
      "Batch Average Reconstruciton Loss:601891072.0\n",
      "input:tensor([ 33.8430,   1.9835,  45.1335,   1.9495, 682.0000])\n",
      "output:tensor([222567.5781])\n",
      "Batch Average Reconstruciton Loss:37347717120.0\n",
      "input:tensor([  4.1213,   1.7350,   3.7068,   1.6680, 682.0000])\n",
      "output:tensor([223337.0781])\n",
      "Batch Average Reconstruciton Loss:301436320.0\n",
      "input:tensor([  4.3203,   2.5445,   3.2800,   2.5025, 682.0000])\n",
      "output:tensor([223310.])\n",
      "Batch Average Reconstruciton Loss:39715204.0\n",
      "input:tensor([ 28.9143,   2.2590,  37.8312,   2.1810, 682.0000])\n",
      "output:tensor([222689.4844])\n",
      "Batch Average Reconstruciton Loss:35487584256.0\n",
      "input:tensor([  4.6827,   3.0740,   3.2380,   2.9960, 682.0000])\n",
      "output:tensor([223288.6094])\n",
      "Batch Average Reconstruciton Loss:130956192.0\n",
      "input:tensor([  3.2040,   1.8605,   2.4473,   1.8545, 682.0000])\n",
      "output:tensor([223354.3281])\n",
      "Batch Average Reconstruciton Loss:7440558592.0\n",
      "input:tensor([  3.9623,   2.4480,   2.9513,   2.3830, 682.0000])\n",
      "output:tensor([223321.3750])\n",
      "Batch Average Reconstruciton Loss:730979072.0\n",
      "input:tensor([  3.8880,   1.8645,   3.2487,   1.8295, 682.0000])\n",
      "output:tensor([223339.0312])\n",
      "Batch Average Reconstruciton Loss:1011556032.0\n",
      "input:tensor([  4.7270,   3.6390,   3.1958,   3.4770, 682.0000])\n",
      "output:tensor([223270.5156])\n",
      "Batch Average Reconstruciton Loss:179895568.0\n",
      "input:tensor([  3.8360,   2.2645,   2.9015,   2.2305, 682.0000])\n",
      "output:tensor([223329.0312])\n",
      "Batch Average Reconstruciton Loss:1244252928.0\n",
      "input:tensor([  4.4317,   2.9920,   2.8419,   2.8310, 682.0000])\n",
      "output:tensor([223300.5312])\n",
      "Batch Average Reconstruciton Loss:295358.28125\n",
      "input:tensor([  3.4977,   2.3545,   2.5185,   2.3375, 682.0000])\n",
      "output:tensor([223333.0625])\n",
      "Batch Average Reconstruciton Loss:3634273792.0\n",
      "input:tensor([  3.7500,   2.1725,   2.8694,   2.1385, 682.0000])\n",
      "output:tensor([223333.5469])\n",
      "Batch Average Reconstruciton Loss:1697394944.0\n",
      "input:tensor([  3.1820,   1.8290,   2.4528,   1.7890, 682.0000])\n",
      "output:tensor([223356.4531])\n",
      "Batch Average Reconstruciton Loss:7814126080.0\n",
      "input:tensor([  3.3487,   1.9910,   2.5301,   1.9870, 682.0000])\n",
      "output:tensor([223347.1719])\n",
      "Batch Average Reconstruciton Loss:5312927232.0\n",
      "input:tensor([  8.8420,   6.5615,   3.9802,   6.4665, 682.0000])\n",
      "output:tensor([223112.3438])\n",
      "Batch Average Reconstruciton Loss:12303323136.0\n",
      "input:tensor([  4.9910,   3.2355,   3.6386,   3.1965, 682.0000])\n",
      "output:tensor([223274.2812])\n",
      "Batch Average Reconstruciton Loss:601048064.0\n",
      "input:tensor([  4.4667,   2.0810,   3.8341,   2.0130, 682.0000])\n",
      "output:tensor([223319.7344])\n",
      "Batch Average Reconstruciton Loss:1512246.625\n",
      "input:tensor([  3.9597,   2.4725,   2.9240,   2.4385, 682.0000])\n",
      "output:tensor([223320.0312])\n",
      "Batch Average Reconstruciton Loss:740164736.0\n",
      "input:tensor([ 37.2333,   2.7920,  48.8382,   2.7120, 682.0000])\n",
      "output:tensor([222464.1250])\n",
      "Batch Average Reconstruciton Loss:38345912320.0\n",
      "input:tensor([  7.6240,   2.2330,   7.8787,   2.1990, 682.0000])\n",
      "output:tensor([223236.5469])\n",
      "Batch Average Reconstruciton Loss:8671622144.0\n",
      "input:tensor([  3.8500,   2.3045,   2.8992,   2.2705, 682.0000])\n",
      "output:tensor([223327.4531])\n",
      "Batch Average Reconstruciton Loss:1178861056.0\n",
      "input:tensor([  4.3437,   2.6275,   3.2753,   2.5525, 682.0000])\n",
      "output:tensor([223307.6719])\n",
      "Batch Average Reconstruciton Loss:25708228.0\n",
      "input:tensor([  3.6733,   2.6270,   2.6072,   2.5940, 682.0000])\n",
      "output:tensor([223320.9375])\n",
      "Batch Average Reconstruciton Loss:2183979008.0\n",
      "input:tensor([  4.1397,   3.2585,   1.6405,   3.1045, 682.0000])\n",
      "output:tensor([223306.8281])\n",
      "Batch Average Reconstruciton Loss:266543888.0\n",
      "input:tensor([  4.0830,   2.1915,   3.2597,   2.1575, 682.0000])\n",
      "output:tensor([223325.1719])\n",
      "Batch Average Reconstruciton Loss:385487200.0\n",
      "input:tensor([  3.8033,   2.6440,   2.7276,   2.5400, 682.0000])\n",
      "output:tensor([223319.4219])\n",
      "Batch Average Reconstruciton Loss:1406593408.0\n",
      "input:tensor([  3.9947,   2.5405,   2.9363,   2.4805, 682.0000])\n",
      "output:tensor([223317.7500])\n",
      "Batch Average Reconstruciton Loss:625662656.0\n",
      "input:tensor([  5.5617,   3.9240,   3.9598,   3.8890, 682.0000])\n",
      "output:tensor([223240.0938])\n",
      "Batch Average Reconstruciton Loss:2013863808.0\n",
      "input:tensor([  3.6157,   2.4925,   2.5887,   2.4315, 682.0000])\n",
      "output:tensor([223327.2188])\n",
      "Batch Average Reconstruciton Loss:2604548864.0\n",
      "input:tensor([  3.5467,   1.8335,   2.9068,   1.7565, 682.0000])\n",
      "output:tensor([223348.5000])\n",
      "Batch Average Reconstruciton Loss:3175378944.0\n",
      "input:tensor([  4.4643,   3.7255,   1.1948,   3.7195, 682.0000])\n",
      "output:tensor([223287.7656])\n",
      "Batch Average Reconstruciton Loss:1170216.875\n",
      "input:tensor([  4.5847,   2.5255,   3.5852,   2.5085, 682.0000])\n",
      "output:tensor([223303.9844])\n",
      "Batch Average Reconstruciton Loss:48038544.0\n",
      "input:tensor([  4.8210,   2.5025,   3.9120,   2.4855, 682.0000])\n",
      "output:tensor([223298.7812])\n",
      "Batch Average Reconstruciton Loss:307398432.0\n",
      "input:tensor([  4.2117,   3.0115,   2.6977,   2.9165, 682.0000])\n",
      "output:tensor([223302.0625])\n",
      "Batch Average Reconstruciton Loss:149669232.0\n",
      "input:tensor([  3.7607,   2.7335,   2.6739,   2.6555, 682.0000])\n",
      "output:tensor([223316.5938])\n",
      "Batch Average Reconstruciton Loss:1637529984.0\n",
      "input:tensor([  3.7467,   2.6565,   2.6677,   2.5925, 682.0000])\n",
      "output:tensor([223319.2188])\n",
      "Batch Average Reconstruciton Loss:1718084352.0\n",
      "input:tensor([  9.9057,   6.7705,   7.0919,   6.7355, 682.0000])\n",
      "output:tensor([223058.7344])\n",
      "Batch Average Reconstruciton Loss:15107785728.0\n",
      "input:tensor([  4.2450,   2.4395,   3.2845,   2.3365, 682.0000])\n",
      "output:tensor([223316.0625])\n",
      "Batch Average Reconstruciton Loss:107556344.0\n",
      "input:tensor([ 13.7403,   2.2060,  16.4553,   2.1210, 682.0000])\n",
      "output:tensor([223081.8750])\n",
      "Batch Average Reconstruciton Loss:22766546944.0\n",
      "input:tensor([  4.2720,   2.3705,   3.3335,   2.3365, 682.0000])\n",
      "output:tensor([223315.9688])\n",
      "Batch Average Reconstruciton Loss:79103792.0\n",
      "input:tensor([  4.3060,   3.7720,   3.1580,   3.7550, 682.0000])\n",
      "output:tensor([223266.9844])\n",
      "Batch Average Reconstruciton Loss:50538104.0\n",
      "input:tensor([  3.7147,   2.6000,   2.6469,   2.5400, 682.0000])\n",
      "output:tensor([223321.7188])\n",
      "Batch Average Reconstruciton Loss:1912162560.0\n",
      "input:tensor([ 36.3963,   3.7935,  46.2747,   3.7865, 682.0000])\n",
      "output:tensor([222462.8750])\n",
      "Batch Average Reconstruciton Loss:38106116096.0\n",
      "input:tensor([  3.3103,   1.9920,   2.5038,   1.9130, 682.0000])\n",
      "output:tensor([223349.7344])\n",
      "Batch Average Reconstruciton Loss:5824477696.0\n",
      "input:tensor([  3.9930,   2.5370,   2.9353,   2.4980, 682.0000])\n",
      "output:tensor([223317.3750])\n",
      "Batch Average Reconstruciton Loss:630895104.0\n",
      "input:tensor([  4.4980,   2.7930,   3.3330,   2.7590, 682.0000])\n",
      "output:tensor([223298.4688])\n",
      "Batch Average Reconstruciton Loss:7598120.0\n",
      "input:tensor([  2.9697,   2.0795,   2.1247,   1.9995, 682.0000])\n",
      "output:tensor([223354.3125])\n",
      "Batch Average Reconstruciton Loss:12252207104.0\n",
      "input:tensor([  4.0203,   2.5530,   2.9558,   2.4890, 682.0000])\n",
      "output:tensor([223316.9375])\n",
      "Batch Average Reconstruciton Loss:548920960.0\n",
      "input:tensor([  3.8403,   2.3730,   2.8945,   2.1840, 682.0000])\n",
      "output:tensor([223329.0625])\n",
      "Batch Average Reconstruciton Loss:1223735936.0\n",
      "input:tensor([  4.0537,   2.1470,   3.2384,   2.1300, 682.0000])\n",
      "output:tensor([223326.8438])\n",
      "Batch Average Reconstruciton Loss:457538784.0\n",
      "input:tensor([  3.1727,   1.8125,   2.4479,   1.7785, 682.0000])\n",
      "output:tensor([223357.0625])\n",
      "Batch Average Reconstruciton Loss:7976979456.0\n",
      "input:tensor([  4.0287,   3.0750,   2.8448,   3.0580, 682.0000])\n",
      "output:tensor([223298.1875])\n",
      "Batch Average Reconstruciton Loss:526097376.0\n",
      "input:tensor([  3.2067,   1.8290,   2.4878,   1.7840, 682.0000])\n",
      "output:tensor([223355.9375])\n",
      "Batch Average Reconstruciton Loss:7396010496.0\n",
      "input:tensor([  5.9540,   5.5150,   4.4880,   5.4210, 682.0000])\n",
      "output:tensor([223174.9219])\n",
      "Batch Average Reconstruciton Loss:3199477248.0\n",
      "input:tensor([  3.5607,   2.4030,   2.5746,   2.3250, 682.0000])\n",
      "output:tensor([223331.5938])\n",
      "Batch Average Reconstruciton Loss:3054596608.0\n",
      "input:tensor([  8.3927,   4.3155,   6.8075,   4.2375, 682.0000])\n",
      "output:tensor([223166.5938])\n",
      "Batch Average Reconstruciton Loss:11018405888.0\n",
      "input:tensor([  5.7240,   5.4585,   0.7800,   5.4415, 682.0000])\n",
      "output:tensor([223217.2031])\n",
      "Batch Average Reconstruciton Loss:2491227904.0\n",
      "input:tensor([  4.2823,   2.5235,   3.2467,   2.5035, 682.0000])\n",
      "output:tensor([223310.9688])\n",
      "Batch Average Reconstruciton Loss:69522768.0\n",
      "input:tensor([  3.2120,   1.9115,   2.4374,   1.8455, 682.0000])\n",
      "output:tensor([223354.0312])\n",
      "Batch Average Reconstruciton Loss:7308192768.0\n",
      "input:tensor([  3.4133,   2.1300,   2.5411,   2.0920, 682.0000])\n",
      "output:tensor([223342.2656])\n",
      "Batch Average Reconstruciton Loss:4526966272.0\n",
      "input:tensor([ 18.7003,   2.3690,  23.2636,   2.3620, 682.0000])\n",
      "output:tensor([222948.4062])\n",
      "Batch Average Reconstruciton Loss:28866488320.0\n",
      "input:tensor([  4.5900,   3.3910,   3.2444,   3.3560, 682.0000])\n",
      "output:tensor([223277.1406])\n",
      "Batch Average Reconstruciton Loss:51196036.0\n",
      "input:tensor([  6.0417,   5.0955,   4.3586,   5.0785, 682.0000])\n",
      "output:tensor([223188.4531])\n",
      "Batch Average Reconstruciton Loss:3480463616.0\n",
      "input:tensor([  3.9387,   2.4935,   2.9055,   2.4295, 682.0000])\n",
      "output:tensor([223320.4375])\n",
      "Batch Average Reconstruciton Loss:814620800.0\n",
      "input:tensor([  4.1200,   1.7550,   3.6911,   1.6920, 682.0000])\n",
      "output:tensor([223336.4375])\n",
      "Batch Average Reconstruciton Loss:304173216.0\n",
      "input:tensor([  4.1677,   3.2975,   1.6477,   3.1895, 682.0000])\n",
      "output:tensor([223303.9062])\n",
      "Batch Average Reconstruciton Loss:216651728.0\n",
      "input:tensor([  3.9580,   2.4960,   2.7538,   2.3980, 682.0000])\n",
      "output:tensor([223322.6406])\n",
      "Batch Average Reconstruciton Loss:745801088.0\n",
      "input:tensor([  3.4433,   2.2265,   2.5157,   2.1915, 682.0000])\n",
      "output:tensor([223338.7031])\n",
      "Batch Average Reconstruciton Loss:4193118976.0\n",
      "input:tensor([  4.3293,   2.6445,   3.2385,   2.5685, 682.0000])\n",
      "output:tensor([223307.6562])\n",
      "Batch Average Reconstruciton Loss:33957936.0\n",
      "input:tensor([  3.9700,   2.4230,   2.9623,   2.3880, 682.0000])\n",
      "output:tensor([223321.2969])\n",
      "Batch Average Reconstruciton Loss:705046016.0\n",
      "input:tensor([  4.4147,   2.6095,   3.3600,   2.5505, 682.0000])\n",
      "output:tensor([223306.2812])\n",
      "Batch Average Reconstruciton Loss:1959212.625\n",
      "input:tensor([  5.3450,   2.6100,   4.4690,   2.5410, 682.0000])\n",
      "output:tensor([223284.7188])\n",
      "Batch Average Reconstruciton Loss:1420590336.0\n",
      "input:tensor([  3.1710,   1.8275,   2.4387,   1.7925, 682.0000])\n",
      "output:tensor([223356.6875])\n",
      "Batch Average Reconstruciton Loss:8006368256.0\n",
      "input:tensor([  3.6323,   2.4510,   2.6202,   2.3900, 682.0000])\n",
      "output:tensor([223328.2031])\n",
      "Batch Average Reconstruciton Loss:2477530368.0\n",
      "input:tensor([  4.1013,   2.6985,   2.9733,   2.6535, 682.0000])\n",
      "output:tensor([223310.2188])\n",
      "Batch Average Reconstruciton Loss:344576832.0\n",
      "input:tensor([  3.8447,   2.2260,   2.9411,   2.2100, 682.0000])\n",
      "output:tensor([223329.4219])\n",
      "Batch Average Reconstruciton Loss:1203436160.0\n",
      "input:tensor([  9.7060,   3.0125,   9.8262,   2.9775, 682.0000])\n",
      "output:tensor([223165.7500])\n",
      "Batch Average Reconstruciton Loss:14631502848.0\n",
      "input:tensor([  3.6227,   2.5325,   2.5921,   2.4915, 682.0000])\n",
      "output:tensor([223325.1875])\n",
      "Batch Average Reconstruciton Loss:2550836992.0\n",
      "input:tensor([  6.9990,   4.0185,   5.0773,   3.9105, 682.0000])\n",
      "output:tensor([223211.3125])\n",
      "Batch Average Reconstruciton Loss:6638389248.0\n",
      "input:tensor([  4.1143,   2.7650,   2.9828,   2.6620, 682.0000])\n",
      "output:tensor([223309.0469])\n",
      "Batch Average Reconstruciton Loss:316802720.0\n",
      "input:tensor([  3.4363,   1.6990,   2.8786,   1.6290, 682.0000])\n",
      "output:tensor([223354.5938])\n",
      "Batch Average Reconstruciton Loss:4267408640.0\n",
      "input:tensor([  4.5290,   2.8350,   3.3401,   2.8180, 682.0000])\n",
      "output:tensor([223296.1562])\n",
      "Batch Average Reconstruciton Loss:18174502.0\n",
      "input:tensor([  3.7200,   2.6385,   1.6457,   2.5605, 682.0000])\n",
      "output:tensor([223331.4531])\n",
      "Batch Average Reconstruciton Loss:1877969664.0\n",
      "input:tensor([  3.9857,   3.0565,   2.8148,   2.9535, 682.0000])\n",
      "output:tensor([223301.8125])\n",
      "Batch Average Reconstruciton Loss:654857728.0\n",
      "input:tensor([  3.4673,   2.3245,   2.5191,   2.2135, 682.0000])\n",
      "output:tensor([223336.8125])\n",
      "Batch Average Reconstruciton Loss:3939092224.0\n",
      "input:tensor([  3.5147,   2.8370,   2.4956,   2.8000, 682.0000])\n",
      "output:tensor([223316.4219])\n",
      "Batch Average Reconstruciton Loss:3472695296.0\n",
      "input:tensor([  4.4713,   2.3775,   3.5711,   2.3005, 682.0000])\n",
      "output:tensor([223312.1562])\n",
      "Batch Average Reconstruciton Loss:2114570.5\n",
      "input:tensor([  3.9563,   3.0135,   2.7936,   2.9805, 682.0000])\n",
      "output:tensor([223302.1094])\n",
      "Batch Average Reconstruciton Loss:752673216.0\n",
      "input:tensor([  5.4657,   2.7370,   4.5150,   2.6520, 682.0000])\n",
      "output:tensor([223278.8125])\n",
      "Batch Average Reconstruciton Loss:1745719808.0\n",
      "input:tensor([  5.2173,   2.9075,   4.1019,   2.7525, 682.0000])\n",
      "output:tensor([223281.5312])\n",
      "Batch Average Reconstruciton Loss:1098692480.0\n",
      "input:tensor([  4.3367,   2.6365,   3.0710,   2.4985, 682.0000])\n",
      "output:tensor([223311.2031])\n",
      "Batch Average Reconstruciton Loss:29547888.0\n",
      "input:tensor([  4.2923,   2.5295,   3.2841,   2.4265, 682.0000])\n",
      "output:tensor([223312.3594])\n",
      "Batch Average Reconstruciton Loss:60803200.0\n",
      "input:tensor([  4.3567,   2.4220,   3.2687,   2.2360, 682.0000])\n",
      "output:tensor([223317.7500])\n",
      "Batch Average Reconstruciton Loss:19177830.0\n",
      "input:tensor([  3.7247,   2.6565,   2.6495,   2.6295, 682.0000])\n",
      "output:tensor([223318.7344])\n",
      "Batch Average Reconstruciton Loss:1850227072.0\n",
      "input:tensor([ 13.4347,   2.0890,  16.1588,   2.0540, 682.0000])\n",
      "output:tensor([223091.2031])\n",
      "Batch Average Reconstruciton Loss:22276220928.0\n",
      "input:tensor([  3.8557,   1.8280,   3.1030,   1.7230, 682.0000])\n",
      "output:tensor([223344.0156])\n",
      "Batch Average Reconstruciton Loss:1151922560.0\n",
      "input:tensor([  3.4113,   2.2475,   2.4866,   2.2135, 682.0000])\n",
      "output:tensor([223338.5781])\n",
      "Batch Average Reconstruciton Loss:4550368768.0\n",
      "input:tensor([ 11.9667,   2.8415,  13.1766,   2.8075, 682.0000])\n",
      "output:tensor([223111.8750])\n",
      "Batch Average Reconstruciton Loss:19660210176.0\n",
      "input:tensor([  4.1940,   2.8740,   3.0120,   2.8390, 682.0000])\n",
      "output:tensor([223302.2812])\n",
      "Batch Average Reconstruciton Loss:174919632.0\n",
      "input:tensor([  4.9420,   4.4165,   1.3504,   4.3895, 682.0000])\n",
      "output:tensor([223256.8750])\n",
      "Batch Average Reconstruciton Loss:507550208.0\n",
      "input:tensor([  3.9003,   3.3630,   2.8248,   3.3560, 682.0000])\n",
      "output:tensor([223289.2344])\n",
      "Batch Average Reconstruciton Loss:963963776.0\n",
      "input:tensor([  3.9843,   2.5260,   2.9508,   2.4220, 682.0000])\n",
      "output:tensor([223319.3281])\n",
      "Batch Average Reconstruciton Loss:658213504.0\n",
      "input:tensor([  4.9933,   3.0175,   2.9369,   2.9585, 682.0000])\n",
      "output:tensor([223290.0781])\n",
      "Batch Average Reconstruciton Loss:606394496.0\n",
      "input:tensor([  4.1043,   2.1735,   3.2720,   2.1565, 682.0000])\n",
      "output:tensor([223325.0312])\n",
      "Batch Average Reconstruciton Loss:337492480.0\n",
      "input:tensor([  4.6047,   2.4360,   3.6803,   2.4020, 682.0000])\n",
      "output:tensor([223306.4062])\n",
      "Batch Average Reconstruciton Loss:61974780.0\n",
      "input:tensor([ 40.2937,   2.9570,  52.8872,   2.9220, 682.0000])\n",
      "output:tensor([222381.1875])\n",
      "Batch Average Reconstruciton Loss:39109881856.0\n",
      "input:tensor([  4.1603,   2.2690,   3.3102,   2.1650, 682.0000])\n",
      "output:tensor([223322.7812])\n",
      "Batch Average Reconstruciton Loss:228590768.0\n",
      "input:tensor([  4.0807,   2.1620,   3.2604,   2.1280, 682.0000])\n",
      "output:tensor([223326.2344])\n",
      "Batch Average Reconstruciton Loss:390922720.0\n",
      "input:tensor([  3.7687,   2.2230,   2.8823,   2.1190, 682.0000])\n",
      "output:tensor([223333.1719])\n",
      "Batch Average Reconstruciton Loss:1591198336.0\n",
      "input:tensor([  3.2020,   1.8435,   2.4525,   1.8065, 682.0000])\n",
      "output:tensor([223355.6719])\n",
      "Batch Average Reconstruciton Loss:7473659392.0\n",
      "input:tensor([  4.3450,   3.0635,   3.0917,   3.0295, 682.0000])\n",
      "output:tensor([223293.0156])\n",
      "Batch Average Reconstruciton Loss:25150068.0\n",
      "input:tensor([  5.4440,   1.9095,   5.2649,   1.8765, 682.0000])\n",
      "output:tensor([223299.2500])\n",
      "Batch Average Reconstruciton Loss:1687586944.0\n",
      "input:tensor([ 17.4867,  12.3385,  12.4389,  12.2595, 682.0000])\n",
      "output:tensor([222723.1250])\n",
      "Batch Average Reconstruciton Loss:27554050048.0\n",
      "input:tensor([  4.0077,   2.5780,   2.9358,   2.5390, 682.0000])\n",
      "output:tensor([223315.7500])\n",
      "Batch Average Reconstruciton Loss:586136192.0\n",
      "input:tensor([  3.6330,   1.9290,   2.8923,   1.9220, 682.0000])\n",
      "output:tensor([223342.5625])\n",
      "Batch Average Reconstruciton Loss:2471127552.0\n",
      "input:tensor([  4.1003,   2.6260,   2.9891,   2.6080, 682.0000])\n",
      "output:tensor([223311.9219])\n",
      "Batch Average Reconstruciton Loss:346707296.0\n",
      "input:tensor([  5.3890,   3.7940,   3.8429,   3.7320, 682.0000])\n",
      "output:tensor([223248.5312])\n",
      "Batch Average Reconstruciton Loss:1534252160.0\n",
      "input:tensor([  3.4930,   2.3040,   2.5368,   2.2600, 682.0000])\n",
      "output:tensor([223335.3906])\n",
      "Batch Average Reconstruciton Loss:3679830784.0\n",
      "input:tensor([  3.7010,   2.0830,   2.8668,   2.0410, 682.0000])\n",
      "output:tensor([223337.5000])\n",
      "Batch Average Reconstruciton Loss:1997955840.0\n",
      "input:tensor([  4.4207,   3.2040,   3.1338,   3.1700, 682.0000])\n",
      "output:tensor([223286.7812])\n",
      "Batch Average Reconstruciton Loss:1241483.375\n",
      "input:tensor([  5.2480,   3.3560,   3.8494,   3.3390, 682.0000])\n",
      "output:tensor([223264.4531])\n",
      "Batch Average Reconstruciton Loss:1172408576.0\n",
      "input:tensor([  3.7137,   2.0755,   2.8662,   2.0695, 682.0000])\n",
      "output:tensor([223336.7500])\n",
      "Batch Average Reconstruciton Loss:1917060608.0\n",
      "input:tensor([  4.3827,   3.1340,   2.3967,   3.0600, 682.0000])\n",
      "output:tensor([223298.5625])\n",
      "Batch Average Reconstruciton Loss:9286875.0\n",
      "input:tensor([  3.4630,   1.7675,   2.8218,   1.7335, 682.0000])\n",
      "output:tensor([223351.5625])\n",
      "Batch Average Reconstruciton Loss:3982296320.0\n",
      "input:tensor([  5.0993,   3.0125,   3.0758,   2.9175, 682.0000])\n",
      "output:tensor([223288.5312])\n",
      "Batch Average Reconstruciton Loss:826765568.0\n",
      "input:tensor([  3.6497,   2.6440,   2.5001,   2.4960, 682.0000])\n",
      "output:tensor([223324.5938])\n",
      "Batch Average Reconstruciton Loss:2350446848.0\n",
      "input:tensor([  4.0593,   2.6570,   2.9576,   2.5950, 682.0000])\n",
      "output:tensor([223312.7188])\n",
      "Batch Average Reconstruciton Loss:443619680.0\n",
      "input:tensor([ 18.9177,   1.7740,  24.3574,   1.7100, 682.0000])\n",
      "output:tensor([222957.0781])\n",
      "Batch Average Reconstruciton Loss:29076756480.0\n",
      "input:tensor([  4.2643,   2.4300,   3.2872,   2.3960, 682.0000])\n",
      "output:tensor([223314.4219])\n",
      "Batch Average Reconstruciton Loss:86724112.0\n",
      "input:tensor([  8.2777,   4.0010,   6.9145,   3.9400, 682.0000])\n",
      "output:tensor([223177.4688])\n",
      "Batch Average Reconstruciton Loss:10678425600.0\n",
      "input:tensor([  3.1377,   1.7940,   2.4320,   1.7760, 682.0000])\n",
      "output:tensor([223357.8750])\n",
      "Batch Average Reconstruciton Loss:8612048896.0\n",
      "input:tensor([  5.3933,   3.6260,   2.8228,   3.6210, 682.0000])\n",
      "output:tensor([223263.9688])\n",
      "Batch Average Reconstruciton Loss:1547082368.0\n",
      "input:tensor([  3.7247,   2.2710,   2.7808,   2.2270, 682.0000])\n",
      "output:tensor([223331.5156])\n",
      "Batch Average Reconstruciton Loss:1849127680.0\n",
      "input:tensor([  5.0983,   4.7030,   3.8300,   4.5960, 682.0000])\n",
      "output:tensor([223220.3906])\n",
      "Batch Average Reconstruciton Loss:820672960.0\n",
      "input:tensor([ 14.5747,  10.9330,   6.6199,  10.9240, 682.0000])\n",
      "output:tensor([222864.8906])\n",
      "Batch Average Reconstruciton Loss:23963625472.0\n",
      "input:tensor([  3.1650,   1.7730,   2.4518,   1.7580, 682.0000])\n",
      "output:tensor([223358.0312])\n",
      "Batch Average Reconstruciton Loss:8112599040.0\n",
      "input:tensor([  3.8283,   1.7680,   3.2821,   1.7260, 682.0000])\n",
      "output:tensor([223342.9375])\n",
      "Batch Average Reconstruciton Loss:1280069760.0\n",
      "input:tensor([  4.7183,   3.5765,   2.1064,   3.5035, 682.0000])\n",
      "output:tensor([223282.2812])\n",
      "Batch Average Reconstruciton Loss:169996784.0\n",
      "input:tensor([  4.2490,   2.8670,   2.0820,   2.7700, 682.0000])\n",
      "output:tensor([223313.5000])\n",
      "Batch Average Reconstruciton Loss:103093560.0\n",
      "input:tensor([  4.1930,   2.8585,   3.0160,   2.7815, 682.0000])\n",
      "output:tensor([223303.8750])\n",
      "Batch Average Reconstruciton Loss:176388288.0\n",
      "input:tensor([  3.5187,   1.8320,   2.6851,   1.7370, 682.0000])\n",
      "output:tensor([223351.6875])\n",
      "Batch Average Reconstruciton Loss:3430832896.0\n",
      "input:tensor([  4.8963,   4.1425,   3.5309,   4.1055, 682.0000])\n",
      "output:tensor([223244.])\n",
      "Batch Average Reconstruciton Loss:426133440.0\n",
      "input:tensor([  4.1867,   2.7750,   3.0285,   2.7330, 682.0000])\n",
      "output:tensor([223305.8906])\n",
      "Batch Average Reconstruciton Loss:185970752.0\n",
      "input:tensor([  3.4477,   2.1405,   2.4192,   2.0265, 682.0000])\n",
      "output:tensor([223344.7500])\n",
      "Batch Average Reconstruciton Loss:4145589248.0\n",
      "input:tensor([  4.0547,   3.2510,   2.8762,   3.1830, 682.0000])\n",
      "output:tensor([223292.5781])\n",
      "Batch Average Reconstruciton Loss:456395808.0\n",
      "input:tensor([  4.1720,   2.8390,   3.0004,   2.7940, 682.0000])\n",
      "output:tensor([223304.1406])\n",
      "Batch Average Reconstruciton Loss:209434720.0\n",
      "input:tensor([  3.3113,   2.0590,   2.4655,   2.0000, 682.0000])\n",
      "output:tensor([223347.2031])\n",
      "Batch Average Reconstruciton Loss:5810981888.0\n",
      "input:tensor([ 13.0133,  10.0530,   5.4212,   9.9930, 682.0000])\n",
      "output:tensor([222927.])\n",
      "Batch Average Reconstruciton Loss:21520009216.0\n",
      "input:tensor([  4.0477,   3.1170,   2.8585,   3.0830, 682.0000])\n",
      "output:tensor([223296.7812])\n",
      "Batch Average Reconstruciton Loss:474465056.0\n",
      "input:tensor([  3.8537,   2.8385,   2.7263,   2.8215, 682.0000])\n",
      "output:tensor([223309.7656])\n",
      "Batch Average Reconstruciton Loss:1163303424.0\n",
      "input:tensor([  3.6023,   2.4520,   2.5906,   2.3860, 682.0000])\n",
      "output:tensor([223328.9375])\n",
      "Batch Average Reconstruciton Loss:2709000704.0\n",
      "input:tensor([  3.8587,   1.8320,   3.2608,   1.8270, 682.0000])\n",
      "output:tensor([223339.6406])\n",
      "Batch Average Reconstruciton Loss:1138681728.0\n",
      "input:tensor([  3.9040,   2.4250,   2.9043,   2.4080, 682.0000])\n",
      "output:tensor([223322.1094])\n",
      "Batch Average Reconstruciton Loss:947155456.0\n",
      "input:tensor([  3.9973,   2.4235,   3.0056,   2.3795, 682.0000])\n",
      "output:tensor([223320.7500])\n",
      "Batch Average Reconstruciton Loss:617236736.0\n",
      "input:tensor([  6.6437,   7.0155,   5.6861,   6.9505, 682.0000])\n",
      "output:tensor([223100.4375])\n",
      "Batch Average Reconstruciton Loss:5444290560.0\n",
      "input:tensor([  4.4177,   2.2120,   3.6545,   2.1680, 682.0000])\n",
      "output:tensor([223316.8906])\n",
      "Batch Average Reconstruciton Loss:1527966.375\n",
      "input:tensor([  7.2343,   2.5735,   6.9642,   2.5695, 682.0000])\n",
      "output:tensor([223237.5781])\n",
      "Batch Average Reconstruciton Loss:7415548416.0\n",
      "input:tensor([ 14.9993,   2.4945,  17.6481,   2.4805, 682.0000])\n",
      "output:tensor([223043.6250])\n",
      "Batch Average Reconstruciton Loss:24620003328.0\n",
      "input:tensor([  4.1637,   2.7175,   3.0246,   2.6755, 682.0000])\n",
      "output:tensor([223308.2344])\n",
      "Batch Average Reconstruciton Loss:223316128.0\n",
      "input:tensor([  3.9770,   2.0280,   3.2621,   1.9510, 682.0000])\n",
      "output:tensor([223333.1719])\n",
      "Batch Average Reconstruciton Loss:681253248.0\n",
      "input:tensor([  3.3433,   1.8985,   2.5884,   1.8385, 682.0000])\n",
      "output:tensor([223351.3438])\n",
      "Batch Average Reconstruciton Loss:5381492224.0\n",
      "input:tensor([ 25.3890,  19.1570,  14.6252,  19.1510, 682.0000])\n",
      "output:tensor([222370.4375])\n",
      "Batch Average Reconstruciton Loss:33598316544.0\n",
      "input:tensor([  3.6097,   2.5605,   2.5759,   2.4495, 682.0000])\n",
      "output:tensor([223326.2656])\n",
      "Batch Average Reconstruciton Loss:2651398656.0\n",
      "input:tensor([  4.2413,   2.9410,   3.0333,   2.9080, 682.0000])\n",
      "output:tensor([223299.1094])\n",
      "Batch Average Reconstruciton Loss:112145784.0\n",
      "input:tensor([  3.2043,   1.8625,   2.4586,   1.7835, 682.0000])\n",
      "output:tensor([223355.9531])\n",
      "Batch Average Reconstruciton Loss:7434758656.0\n",
      "input:tensor([  3.5347,   1.7725,   2.8992,   1.7555, 682.0000])\n",
      "output:tensor([223349.3750])\n",
      "Batch Average Reconstruciton Loss:3283247104.0\n",
      "input:tensor([  4.5910,   2.7495,   3.4726,   2.6735, 682.0000])\n",
      "output:tensor([223298.6094])\n",
      "Batch Average Reconstruciton Loss:52180532.0\n",
      "input:tensor([  3.6847,   2.0645,   2.8563,   2.0465, 682.0000])\n",
      "output:tensor([223337.8281])\n",
      "Batch Average Reconstruciton Loss:2105540736.0\n",
      "input:tensor([  5.8633,   1.9520,   5.8184,   1.8110, 682.0000])\n",
      "output:tensor([223290.0625])\n",
      "Batch Average Reconstruciton Loss:2927141376.0\n",
      "input:tensor([  3.0927,   1.7325,   2.4262,   1.6665, 682.0000])\n",
      "output:tensor([223361.7969])\n",
      "Batch Average Reconstruciton Loss:9486215168.0\n",
      "input:tensor([  3.6387,   1.9895,   2.8818,   1.9725, 682.0000])\n",
      "output:tensor([223340.7188])\n",
      "Batch Average Reconstruciton Loss:2429137408.0\n",
      "input:tensor([  3.9690,   2.4970,   2.9285,   2.4630, 682.0000])\n",
      "output:tensor([223319.0156])\n",
      "Batch Average Reconstruciton Loss:708517120.0\n",
      "input:tensor([  3.2383,   1.8960,   2.4785,   1.8310, 682.0000])\n",
      "output:tensor([223353.8438])\n",
      "Batch Average Reconstruciton Loss:6885042688.0\n",
      "input:tensor([  3.7930,   2.4800,   2.7522,   2.4620, 682.0000])\n",
      "output:tensor([223322.9844])\n",
      "Batch Average Reconstruciton Loss:1460081664.0\n",
      "input:tensor([  3.7567,   2.7155,   2.6663,   2.6555, 682.0000])\n",
      "output:tensor([223316.9375])\n",
      "Batch Average Reconstruciton Loss:1660323072.0\n",
      "input:tensor([  3.9667,   2.6290,   2.8684,   2.5880, 682.0000])\n",
      "output:tensor([223315.1250])\n",
      "Batch Average Reconstruciton Loss:716572672.0\n",
      "input:tensor([  3.7283,   2.6410,   2.6493,   2.6070, 682.0000])\n",
      "output:tensor([223319.4219])\n",
      "Batch Average Reconstruciton Loss:1827697408.0\n",
      "input:tensor([  4.1297,   2.2495,   3.2423,   2.2325, 682.0000])\n",
      "output:tensor([223322.3594])\n",
      "Batch Average Reconstruciton Loss:285293728.0\n",
      "input:tensor([  4.1913,   2.8105,   3.0265,   2.7455, 682.0000])\n",
      "output:tensor([223305.1875])\n",
      "Batch Average Reconstruciton Loss:178858864.0\n",
      "input:tensor([  5.0023,   3.4890,   2.5830,   3.4840, 682.0000])\n",
      "output:tensor([223275.5938])\n",
      "Batch Average Reconstruciton Loss:623430656.0\n",
      "input:tensor([  3.4593,   1.7640,   2.8350,   1.7450, 682.0000])\n",
      "output:tensor([223351.2344])\n",
      "Batch Average Reconstruciton Loss:4020671488.0\n",
      "input:tensor([  3.5290,   2.3345,   2.5530,   2.2745, 682.0000])\n",
      "output:tensor([223334.1719])\n",
      "Batch Average Reconstruciton Loss:3336775424.0\n",
      "input:tensor([  4.1273,   2.7325,   2.1592,   2.6635, 682.0000])\n",
      "output:tensor([223318.0312])\n",
      "Batch Average Reconstruciton Loss:290053888.0\n",
      "input:tensor([  4.3727,   3.0035,   3.1378,   2.9855, 682.0000])\n",
      "output:tensor([223293.9688])\n",
      "Batch Average Reconstruciton Loss:12745123.0\n",
      "input:tensor([ 30.2337,  24.0140,  21.4757,  23.9110, 682.0000])\n",
      "output:tensor([222074.5156])\n",
      "Batch Average Reconstruciton Loss:35820679168.0\n",
      "input:tensor([  3.8863,   2.3870,   2.9047,   2.3800, 682.0000])\n",
      "output:tensor([223323.3906])\n",
      "Batch Average Reconstruciton Loss:1019499968.0\n",
      "input:tensor([ 14.5060,   2.2220,  17.5051,   2.1880, 682.0000])\n",
      "output:tensor([223060.6562])\n",
      "Batch Average Reconstruciton Loss:23924557824.0\n",
      "input:tensor([  3.7177,   2.1245,   2.8432,   2.0845, 682.0000])\n",
      "output:tensor([223336.0469])\n",
      "Batch Average Reconstruciton Loss:1892071936.0\n",
      "input:tensor([  3.9033,   2.4380,   2.9026,   2.3310, 682.0000])\n",
      "output:tensor([223323.9375])\n",
      "Batch Average Reconstruciton Loss:949752960.0\n",
      "input:tensor([  3.9173,   2.4000,   2.9130,   2.3640, 682.0000])\n",
      "output:tensor([223323.2500])\n",
      "Batch Average Reconstruciton Loss:894593152.0\n",
      "input:tensor([  3.2093,   2.3945,   2.2687,   2.3165, 682.0000])\n",
      "output:tensor([223338.9219])\n",
      "Batch Average Reconstruciton Loss:7354619392.0\n",
      "input:tensor([  3.5440,   2.3950,   2.3948,   2.3010, 682.0000])\n",
      "output:tensor([223334.4062])\n",
      "Batch Average Reconstruciton Loss:3200797696.0\n",
      "input:tensor([  3.8477,   1.8170,   3.2932,   1.7490, 682.0000])\n",
      "output:tensor([223341.5312])\n",
      "Batch Average Reconstruciton Loss:1188695808.0\n",
      "input:tensor([ 19.1907,   1.5620,  24.9781,   1.5270, 682.0000])\n",
      "output:tensor([222954.3594])\n",
      "Batch Average Reconstruciton Loss:29330796544.0\n",
      "input:tensor([  4.1297,   2.2675,   3.2627,   2.1635, 682.0000])\n",
      "output:tensor([223323.6875])\n",
      "Batch Average Reconstruciton Loss:285248864.0\n",
      "input:tensor([  3.9393,   1.9655,   3.2503,   1.8945, 682.0000])\n",
      "output:tensor([223335.7812])\n",
      "Batch Average Reconstruciton Loss:811293760.0\n",
      "input:tensor([  4.3610,   2.4730,   3.3926,   2.4310, 682.0000])\n",
      "output:tensor([223310.9062])\n",
      "Batch Average Reconstruciton Loss:17306380.0\n",
      "input:tensor([  3.5657,   2.3945,   2.5770,   2.3355, 682.0000])\n",
      "output:tensor([223331.3438])\n",
      "Batch Average Reconstruciton Loss:3011557120.0\n",
      "input:tensor([  3.2040,   1.8385,   2.4547,   1.8045, 682.0000])\n",
      "output:tensor([223355.7344])\n",
      "Batch Average Reconstruciton Loss:7440315904.0\n",
      "input:tensor([  8.0297,   8.4555,   6.9028,   8.4205, 682.0000])\n",
      "output:tensor([223020.5156])\n",
      "Batch Average Reconstruciton Loss:9895974912.0\n",
      "input:tensor([  3.4340,   2.2130,   2.5135,   2.1530, 682.0000])\n",
      "output:tensor([223339.9219])\n",
      "Batch Average Reconstruciton Loss:4294977536.0\n",
      "input:tensor([  4.0793,   2.2315,   3.2270,   2.2145, 682.0000])\n",
      "output:tensor([223323.6875])\n",
      "Batch Average Reconstruciton Loss:394154016.0\n",
      "input:tensor([  4.3080,   3.0110,   3.0718,   2.9750, 682.0000])\n",
      "output:tensor([223295.5781])\n",
      "Batch Average Reconstruciton Loss:48628612.0\n",
      "input:tensor([  3.2883,   2.0205,   2.3171,   1.9415, 682.0000])\n",
      "output:tensor([223350.9531])\n",
      "Batch Average Reconstruciton Loss:6134343168.0\n",
      "input:tensor([  3.8383,   2.3010,   2.9040,   2.2580, 682.0000])\n",
      "output:tensor([223327.8750])\n",
      "Batch Average Reconstruciton Loss:1233282688.0\n",
      "input:tensor([  4.3257,   3.0365,   2.9356,   2.9025, 682.0000])\n",
      "output:tensor([223298.3906])\n",
      "Batch Average Reconstruciton Loss:36368248.0\n",
      "input:tensor([  3.5920,   2.4200,   2.5834,   2.3860, 682.0000])\n",
      "output:tensor([223329.4688])\n",
      "Batch Average Reconstruciton Loss:2792016128.0\n",
      "input:tensor([  4.7747,   2.1520,   4.0845,   2.1340, 682.0000])\n",
      "output:tensor([223309.9688])\n",
      "Batch Average Reconstruciton Loss:241708240.0\n",
      "input:tensor([  4.3310,   3.0105,   2.0115,   3.0055, 682.0000])\n",
      "output:tensor([223305.9219])\n",
      "Batch Average Reconstruciton Loss:32948496.0\n",
      "input:tensor([  3.8403,   2.2780,   2.9027,   2.2430, 682.0000])\n",
      "output:tensor([223328.4844])\n",
      "Batch Average Reconstruciton Loss:1223776384.0\n",
      "input:tensor([  5.4293,   2.6425,   4.5165,   2.6085, 682.0000])\n",
      "output:tensor([223281.2656])\n",
      "Batch Average Reconstruciton Loss:1645946496.0\n",
      "input:tensor([  4.2623,   1.9435,   3.6765,   1.8675, 682.0000])\n",
      "output:tensor([223328.6875])\n",
      "Batch Average Reconstruciton Loss:88497528.0\n",
      "input:tensor([  3.8417,   2.2870,   2.8920,   2.2700, 682.0000])\n",
      "output:tensor([223327.8125])\n",
      "Batch Average Reconstruciton Loss:1217534592.0\n",
      "input:tensor([ 30.1117,   2.6340,  38.9781,   2.5650, 682.0000])\n",
      "output:tensor([222650.8438])\n",
      "Batch Average Reconstruciton Loss:35988684800.0\n",
      "input:tensor([  4.4203,   2.4060,   3.4836,   2.3710, 682.0000])\n",
      "output:tensor([223311.5312])\n",
      "Batch Average Reconstruciton Loss:1222061.125\n",
      "input:tensor([  3.1237,   1.6890,   2.4760,   1.6710, 682.0000])\n",
      "output:tensor([223361.2969])\n",
      "Batch Average Reconstruciton Loss:8876221440.0\n",
      "input:tensor([  4.0760,   3.1940,   2.8832,   3.1160, 682.0000])\n",
      "output:tensor([223294.5625])\n",
      "Batch Average Reconstruciton Loss:403264128.0\n",
      "input:tensor([  4.3653,   2.5300,   3.3426,   2.5030, 682.0000])\n",
      "output:tensor([223309.0156])\n",
      "Batch Average Reconstruciton Loss:15491973.0\n",
      "input:tensor([  3.6467,   2.5185,   2.6093,   2.4835, 682.0000])\n",
      "output:tensor([223325.1094])\n",
      "Batch Average Reconstruciton Loss:2372068864.0\n",
      "input:tensor([  4.1327,   2.8085,   2.9761,   2.7255, 682.0000])\n",
      "output:tensor([223306.8906])\n",
      "Batch Average Reconstruciton Loss:279963488.0\n",
      "input:tensor([  4.3123,   3.0570,   3.0650,   3.0230, 682.0000])\n",
      "output:tensor([223293.9062])\n",
      "Batch Average Reconstruciton Loss:45482800.0\n",
      "input:tensor([  3.4200,   2.1500,   2.5164,   2.1430, 682.0000])\n",
      "output:tensor([223340.9844])\n",
      "Batch Average Reconstruciton Loss:4451160064.0\n",
      "input:tensor([  4.4313,   2.9550,   3.2065,   2.8910, 682.0000])\n",
      "output:tensor([223295.5000])\n",
      "Batch Average Reconstruciton Loss:318660.25\n",
      "input:tensor([  4.2613,   2.3930,   3.3159,   2.3550, 682.0000])\n",
      "output:tensor([223315.5625])\n",
      "Batch Average Reconstruciton Loss:89783912.0\n",
      "input:tensor([  4.4037,   2.1650,   3.6628,   2.1050, 682.0000])\n",
      "output:tensor([223319.0312])\n",
      "Batch Average Reconstruciton Loss:3794582.25\n",
      "input:tensor([  3.6330,   2.5675,   2.5926,   2.4615, 682.0000])\n",
      "output:tensor([223325.4844])\n",
      "Batch Average Reconstruciton Loss:2472825856.0\n",
      "input:tensor([  3.8113,   1.7620,   3.2724,   1.7210, 682.0000])\n",
      "output:tensor([223343.4219])\n",
      "Batch Average Reconstruciton Loss:1364015360.0\n",
      "input:tensor([  7.7710,   5.1720,   4.0214,   5.0770, 682.0000])\n",
      "output:tensor([223172.8906])\n",
      "Batch Average Reconstruciton Loss:9123858432.0\n",
      "input:tensor([  3.7073,   2.0950,   2.8844,   2.0350, 682.0000])\n",
      "output:tensor([223337.2656])\n",
      "Batch Average Reconstruciton Loss:1957242624.0\n",
      "input:tensor([  3.7517,   2.1885,   2.8544,   2.1705, 682.0000])\n",
      "output:tensor([223332.7188])\n",
      "Batch Average Reconstruciton Loss:1687836032.0\n",
      "input:tensor([  3.3597,   2.0710,   2.4985,   2.0530, 682.0000])\n",
      "output:tensor([223344.9062])\n",
      "Batch Average Reconstruciton Loss:5172787712.0\n",
      "input:tensor([  8.0753,   3.7980,   6.8339,   3.7640, 682.0000])\n",
      "output:tensor([223187.0625])\n",
      "Batch Average Reconstruciton Loss:10068930560.0\n",
      "input:tensor([ 77.2845,  76.9630, 120.7986,  94.1152, 802.0000])\n",
      "output:tensor([257507.8594])\n",
      "Batch Average Reconstruciton Loss:60511993856.0\n",
      "input:tensor([  4.5090,   2.8410,   3.3381,   2.7380, 682.0000])\n",
      "output:tensor([223298.3125])\n",
      "Batch Average Reconstruciton Loss:10852495.0\n",
      "input:tensor([  4.1557,   2.5890,   3.0822,   2.5540, 682.0000])\n",
      "output:tensor([223312.1250])\n",
      "Batch Average Reconstruciton Loss:237094560.0\n",
      "input:tensor([  3.5820,   2.3195,   2.6023,   2.2845, 682.0000])\n",
      "output:tensor([223333.])\n",
      "Batch Average Reconstruciton Loss:2873710336.0\n",
      "input:tensor([  5.3720,   5.0915,   4.1567,   5.0865, 682.0000])\n",
      "output:tensor([223197.5469])\n",
      "Batch Average Reconstruciton Loss:1485065472.0\n",
      "input:tensor([  3.5640,   2.3685,   2.5739,   2.3345, 682.0000])\n",
      "output:tensor([223331.6875])\n",
      "Batch Average Reconstruciton Loss:3025804544.0\n",
      "input:tensor([  3.6017,   2.4775,   2.5871,   2.4355, 682.0000])\n",
      "output:tensor([223327.4844])\n",
      "Batch Average Reconstruciton Loss:2714463744.0\n",
      "input:tensor([ 14.6417,   2.5160,  17.1982,   2.4060, 682.0000])\n",
      "output:tensor([223053.8750])\n",
      "Batch Average Reconstruciton Loss:24118671360.0\n",
      "input:tensor([ 16.8213,   1.8010,  21.2211,   1.7060, 682.0000])\n",
      "output:tensor([223012.7812])\n",
      "Batch Average Reconstruciton Loss:26909048832.0\n",
      "input:tensor([  4.6970,   3.1095,   3.4096,   3.0655, 682.0000])\n",
      "output:tensor([223284.5000])\n",
      "Batch Average Reconstruciton Loss:146059312.0\n",
      "input:tensor([ 16.8643,  12.7540,   9.4350,  12.7130, 682.0000])\n",
      "output:tensor([222746.1562])\n",
      "Batch Average Reconstruciton Loss:26871128064.0\n",
      "input:tensor([  4.1863,   3.1740,   2.9560,   3.1400, 682.0000])\n",
      "output:tensor([223292.2344])\n",
      "Batch Average Reconstruciton Loss:186862496.0\n",
      "input:tensor([  4.9373,   3.4520,   3.5247,   3.3680, 682.0000])\n",
      "output:tensor([223269.4844])\n",
      "Batch Average Reconstruciton Loss:499588864.0\n",
      "input:tensor([  4.1630,   2.7460,   3.0085,   2.7080, 682.0000])\n",
      "output:tensor([223307.3125])\n",
      "Batch Average Reconstruciton Loss:224480928.0\n",
      "input:tensor([  3.1450,   1.7385,   2.4608,   1.7035, 682.0000])\n",
      "output:tensor([223359.8906])\n",
      "Batch Average Reconstruciton Loss:8475247616.0\n",
      "input:tensor([  4.4917,   3.9775,   3.2751,   3.8545, 682.0000])\n",
      "output:tensor([223259.1250])\n",
      "Batch Average Reconstruciton Loss:5789437.5\n",
      "input:tensor([  4.1243,   2.2275,   3.2771,   2.1205, 682.0000])\n",
      "output:tensor([223325.0781])\n",
      "Batch Average Reconstruciton Loss:295802912.0\n",
      "input:tensor([  3.5633,   2.4195,   2.5654,   2.3855, 682.0000])\n",
      "output:tensor([223330.])\n",
      "Batch Average Reconstruciton Loss:3031713792.0\n",
      "input:tensor([  4.3773,   2.5175,   3.3543,   2.4825, 682.0000])\n",
      "output:tensor([223309.4062])\n",
      "Batch Average Reconstruciton Loss:10973277.0\n",
      "input:tensor([  3.0187,   2.1200,   2.1519,   2.0600, 682.0000])\n",
      "output:tensor([223351.5469])\n",
      "Batch Average Reconstruciton Loss:11081868288.0\n",
      "input:tensor([  4.0090,   2.4675,   2.9896,   2.4085, 682.0000])\n",
      "output:tensor([223319.5938])\n",
      "Batch Average Reconstruciton Loss:581938752.0\n",
      "input:tensor([  4.3537,   3.0505,   3.1125,   2.9825, 682.0000])\n",
      "output:tensor([223294.0469])\n",
      "Batch Average Reconstruciton Loss:20793172.0\n",
      "input:tensor([  3.5470,   2.3565,   2.5609,   2.3225, 682.0000])\n",
      "output:tensor([223332.4531])\n",
      "Batch Average Reconstruciton Loss:3174257152.0\n",
      "input:tensor([  6.2717,   5.2740,   4.5267,   5.2310, 682.0000])\n",
      "output:tensor([223178.4844])\n",
      "Batch Average Reconstruciton Loss:4225842944.0\n",
      "input:tensor([  6.8887,   4.8650,   4.8959,   4.8580, 682.0000])\n",
      "output:tensor([223181.6562])\n",
      "Batch Average Reconstruciton Loss:6268942848.0\n",
      "input:tensor([  3.0927,   1.8410,   2.3583,   1.8000, 682.0000])\n",
      "output:tensor([223358.0312])\n",
      "Batch Average Reconstruciton Loss:9486948352.0\n",
      "input:tensor([  3.7523,   2.2605,   2.8333,   2.1935, 682.0000])\n",
      "output:tensor([223331.6094])\n",
      "Batch Average Reconstruciton Loss:1684067456.0\n",
      "input:tensor([  4.3303,   2.0360,   3.6723,   2.0010, 682.0000])\n",
      "output:tensor([223323.6875])\n",
      "Batch Average Reconstruciton Loss:33158162.0\n",
      "input:tensor([  3.4873,   1.7495,   2.8666,   1.7155, 682.0000])\n",
      "output:tensor([223351.5000])\n",
      "Batch Average Reconstruciton Loss:3734004224.0\n",
      "input:tensor([  4.0037,   2.4855,   2.9619,   2.4515, 682.0000])\n",
      "output:tensor([223318.6875])\n",
      "Batch Average Reconstruciton Loss:598013376.0\n",
      "input:tensor([  3.8243,   2.7670,   2.7096,   2.7630, 682.0000])\n",
      "output:tensor([223312.5000])\n",
      "Batch Average Reconstruciton Loss:1301730304.0\n",
      "input:tensor([ 37.8627,  28.9635,  26.7819,  28.9295, 682.0000])\n",
      "output:tensor([221758.0938])\n",
      "Batch Average Reconstruciton Loss:38242967552.0\n",
      "input:tensor([  3.6007,   2.2060,   2.7038,   2.1460, 682.0000])\n",
      "output:tensor([223336.3750])\n",
      "Batch Average Reconstruciton Loss:2721565440.0\n",
      "input:tensor([  6.1417,   2.7900,   5.2800,   2.7720, 682.0000])\n",
      "output:tensor([223259.8594])\n",
      "Batch Average Reconstruciton Loss:3811810304.0\n",
      "input:tensor([  4.0527,   2.6505,   2.9600,   2.4955, 682.0000])\n",
      "output:tensor([223315.3438])\n",
      "Batch Average Reconstruciton Loss:460602688.0\n",
      "input:tensor([  4.9690,   2.9595,   3.7622,   2.8935, 682.0000])\n",
      "output:tensor([223283.7500])\n",
      "Batch Average Reconstruciton Loss:559121472.0\n",
      "input:tensor([  3.5940,   2.4325,   2.5835,   2.3735, 682.0000])\n",
      "output:tensor([223329.6250])\n",
      "Batch Average Reconstruciton Loss:2775854080.0\n",
      "input:tensor([  8.1820,   1.8325,   9.1803,   1.7655, 682.0000])\n",
      "output:tensor([223231.7969])\n",
      "Batch Average Reconstruciton Loss:10401918976.0\n",
      "input:tensor([  5.8173,   5.7355,   4.6249,   5.6975, 682.0000])\n",
      "output:tensor([223165.6406])\n",
      "Batch Average Reconstruciton Loss:2771036928.0\n",
      "input:tensor([  4.0697,   2.6530,   2.9614,   2.6430, 682.0000])\n",
      "output:tensor([223311.4062])\n",
      "Batch Average Reconstruciton Loss:417940512.0\n",
      "input:tensor([ 16.4783,  13.0410,   8.6331,  12.9330, 682.0000])\n",
      "output:tensor([222750.2969])\n",
      "Batch Average Reconstruciton Loss:26422599680.0\n",
      "input:tensor([  4.5420,   2.8775,   2.4852,   2.7765, 682.0000])\n",
      "output:tensor([223305.7656])\n",
      "Batch Average Reconstruciton Loss:24007704.0\n",
      "input:tensor([  4.2540,   3.0525,   3.0225,   2.9905, 682.0000])\n",
      "output:tensor([223295.8438])\n",
      "Batch Average Reconstruciton Loss:97933912.0\n",
      "input:tensor([  5.5890,   2.9075,   4.5202,   2.8405, 682.0000])\n",
      "output:tensor([223270.9062])\n",
      "Batch Average Reconstruciton Loss:2095708288.0\n",
      "input:tensor([  3.1467,   1.7595,   2.4484,   1.7255, 682.0000])\n",
      "output:tensor([223359.2188])\n",
      "Batch Average Reconstruciton Loss:8444651008.0\n",
      "input:tensor([  4.1510,   2.7730,   2.9942,   2.7380, 682.0000])\n",
      "output:tensor([223306.5469])\n",
      "Batch Average Reconstruciton Loss:245625792.0\n",
      "input:tensor([  3.1703,   1.8330,   2.4418,   1.7640, 682.0000])\n",
      "output:tensor([223357.3125])\n",
      "Batch Average Reconstruciton Loss:8018072064.0\n",
      "input:tensor([  4.0287,   3.0705,   2.8448,   3.0265, 682.0000])\n",
      "output:tensor([223299.0469])\n",
      "Batch Average Reconstruciton Loss:526057952.0\n",
      "input:tensor([  4.2830,   2.3795,   3.3530,   2.3205, 682.0000])\n",
      "output:tensor([223315.9531])\n",
      "Batch Average Reconstruciton Loss:68840984.0\n",
      "input:tensor([ 31.3603,  23.8110,  22.1734,  23.7960, 682.0000])\n",
      "output:tensor([222060.0938])\n",
      "Batch Average Reconstruciton Loss:36262858752.0\n",
      "input:tensor([  4.2150,   3.2555,   2.9793,   3.1515, 682.0000])\n",
      "output:tensor([223290.5156])\n",
      "Batch Average Reconstruciton Loss:145431168.0\n",
      "input:tensor([  4.7207,   3.1300,   3.4164,   3.0970, 682.0000])\n",
      "output:tensor([223283.1719])\n",
      "Batch Average Reconstruciton Loss:172742960.0\n",
      "input:tensor([  3.8217,   2.7855,   2.6149,   2.5995, 682.0000])\n",
      "output:tensor([223317.4688])\n",
      "Batch Average Reconstruciton Loss:1314463488.0\n",
      "input:tensor([  3.7403,   2.2685,   2.8090,   2.2315, 682.0000])\n",
      "output:tensor([223330.9531])\n",
      "Batch Average Reconstruciton Loss:1754440960.0\n",
      "input:tensor([  3.0833,   2.1525,   2.0566,   2.0585, 682.0000])\n",
      "output:tensor([223351.5781])\n",
      "Batch Average Reconstruciton Loss:9678313472.0\n",
      "input:tensor([  4.6093,   3.3020,   3.2731,   3.2330, 682.0000])\n",
      "output:tensor([223280.6406])\n",
      "Batch Average Reconstruciton Loss:65054560.0\n",
      "input:tensor([  3.8233,   2.8315,   2.5831,   2.7095, 682.0000])\n",
      "output:tensor([223314.5000])\n",
      "Batch Average Reconstruciton Loss:1306424832.0\n",
      "input:tensor([  3.5867,   1.9350,   2.8555,   1.8550, 682.0000])\n",
      "output:tensor([223345.0781])\n",
      "Batch Average Reconstruciton Loss:2833956864.0\n",
      "input:tensor([  4.7543,   3.1905,   3.4328,   3.0635, 682.0000])\n",
      "output:tensor([223282.8438])\n",
      "Batch Average Reconstruciton Loss:214061584.0\n",
      "input:tensor([  4.0403,   2.0965,   3.2820,   2.0555, 682.0000])\n",
      "output:tensor([223328.9375])\n",
      "Batch Average Reconstruciton Loss:492620800.0\n",
      "input:tensor([  4.5440,   2.9510,   3.3221,   2.8480, 682.0000])\n",
      "output:tensor([223294.1875])\n",
      "Batch Average Reconstruciton Loss:24842126.0\n",
      "input:tensor([  4.1350,   2.7445,   2.9868,   2.7275, 682.0000])\n",
      "output:tensor([223307.3594])\n",
      "Batch Average Reconstruciton Loss:275415296.0\n",
      "input:tensor([ 20.2463,   4.2100,  22.9906,   4.1500, 682.0000])\n",
      "output:tensor([222870.5312])\n",
      "Batch Average Reconstruciton Loss:30232004608.0\n",
      "input:tensor([  4.0823,   1.7575,   3.5166,   1.6525, 682.0000])\n",
      "output:tensor([223339.6875])\n",
      "Batch Average Reconstruciton Loss:386449248.0\n",
      "input:tensor([  3.7070,   2.5845,   2.6419,   2.5665, 682.0000])\n",
      "output:tensor([223321.3125])\n",
      "Batch Average Reconstruciton Loss:1960779264.0\n",
      "input:tensor([  5.3137,   4.1080,   3.7575,   4.1040, 682.0000])\n",
      "output:tensor([223237.5625])\n",
      "Batch Average Reconstruciton Loss:1335870464.0\n",
      "input:tensor([  5.3457,   2.5360,   4.5608,   2.4280, 682.0000])\n",
      "output:tensor([223287.3594])\n",
      "Batch Average Reconstruciton Loss:1422523776.0\n",
      "input:tensor([  5.5790,   4.4425,   3.9619,   4.2815, 682.0000])\n",
      "output:tensor([223224.5469])\n",
      "Batch Average Reconstruciton Loss:2062481024.0\n",
      "input:tensor([  5.2677,   4.4460,   1.2053,   4.4060, 682.0000])\n",
      "output:tensor([223254.2500])\n",
      "Batch Average Reconstruciton Loss:1220471680.0\n",
      "input:tensor([  3.6217,   1.9720,   2.8511,   1.9550, 682.0000])\n",
      "output:tensor([223341.8281])\n",
      "Batch Average Reconstruciton Loss:2556836608.0\n",
      "input:tensor([  3.8893,   2.4220,   2.8932,   2.3790, 682.0000])\n",
      "output:tensor([223323.1406])\n",
      "Batch Average Reconstruciton Loss:1007037824.0\n",
      "input:tensor([  3.1663,   1.8905,   2.4208,   1.7895, 682.0000])\n",
      "output:tensor([223356.3125])\n",
      "Batch Average Reconstruciton Loss:8089147392.0\n",
      "input:tensor([  3.9320,   2.6790,   2.8218,   2.6370, 682.0000])\n",
      "output:tensor([223314.2500])\n",
      "Batch Average Reconstruciton Loss:839536128.0\n",
      "input:tensor([  3.8030,   2.7315,   2.7012,   2.6565, 682.0000])\n",
      "output:tensor([223315.8750])\n",
      "Batch Average Reconstruciton Loss:1408585344.0\n",
      "input:tensor([ 21.2090,   2.7680,  26.2452,   2.7090, 682.0000])\n",
      "output:tensor([222876.8750])\n",
      "Batch Average Reconstruciton Loss:31012575232.0\n",
      "input:tensor([  3.8080,   2.2945,   2.8818,   2.1475, 682.0000])\n",
      "output:tensor([223331.2812])\n",
      "Batch Average Reconstruciton Loss:1381811072.0\n",
      "input:tensor([  3.4680,   2.2335,   2.5472,   2.1655, 682.0000])\n",
      "output:tensor([223338.6875])\n",
      "Batch Average Reconstruciton Loss:3931956224.0\n",
      "input:tensor([  3.9420,   2.9820,   2.7837,   2.8980, 682.0000])\n",
      "output:tensor([223304.7812])\n",
      "Batch Average Reconstruciton Loss:803394752.0\n",
      "input:tensor([  5.3377,   3.5530,   3.8597,   3.4930, 682.0000])\n",
      "output:tensor([223257.4531])\n",
      "Batch Average Reconstruciton Loss:1399392384.0\n",
      "input:tensor([  5.0003,   1.9010,   4.6877,   1.8670, 682.0000])\n",
      "output:tensor([223310.5000])\n",
      "Batch Average Reconstruciton Loss:621180864.0\n",
      "input:tensor([  3.8370,   3.1450,   2.7321,   3.0710, 682.0000])\n",
      "output:tensor([223300.3906])\n",
      "Batch Average Reconstruciton Loss:1241477760.0\n",
      "input:tensor([  5.0370,   4.1580,   2.1263,   4.0800, 682.0000])\n",
      "output:tensor([223258.0469])\n",
      "Batch Average Reconstruciton Loss:692481664.0\n",
      "input:tensor([  3.5293,   2.3670,   2.5399,   2.3500, 682.0000])\n",
      "output:tensor([223332.0469])\n",
      "Batch Average Reconstruciton Loss:3334017792.0\n",
      "input:tensor([  3.7427,   2.6295,   2.6702,   2.5695, 682.0000])\n",
      "output:tensor([223320.1250])\n",
      "Batch Average Reconstruciton Loss:1741549440.0\n",
      "input:tensor([  3.9650,   2.5050,   2.9220,   2.4660, 682.0000])\n",
      "output:tensor([223318.9375])\n",
      "Batch Average Reconstruciton Loss:722000256.0\n",
      "input:tensor([  3.9307,   2.4700,   2.9173,   2.4050, 682.0000])\n",
      "output:tensor([223321.2812])\n",
      "Batch Average Reconstruciton Loss:844060480.0\n",
      "input:tensor([  3.3707,   2.1040,   2.4947,   2.0700, 682.0000])\n",
      "output:tensor([223344.0625])\n",
      "Batch Average Reconstruciton Loss:5035312640.0\n",
      "input:tensor([ 12.3517,   2.4795,  14.1515,   2.4445, 682.0000])\n",
      "output:tensor([223110.3125])\n",
      "Batch Average Reconstruciton Loss:20391071744.0\n",
      "input:tensor([  5.3603,   4.4645,   1.3157,   4.4495, 682.0000])\n",
      "output:tensor([223250.7656])\n",
      "Batch Average Reconstruciton Loss:1458305408.0\n",
      "input:tensor([  3.8203,   2.2900,   2.9001,   2.1110, 682.0000])\n",
      "output:tensor([223331.9062])\n",
      "Batch Average Reconstruciton Loss:1319948416.0\n",
      "input:tensor([  3.9150,   2.4250,   2.9159,   2.3900, 682.0000])\n",
      "output:tensor([223322.3125])\n",
      "Batch Average Reconstruciton Loss:903705024.0\n",
      "input:tensor([  4.0373,   2.1250,   3.2603,   2.0810, 682.0000])\n",
      "output:tensor([223328.2812])\n",
      "Batch Average Reconstruciton Loss:500807040.0\n",
      "input:tensor([  4.1073,   2.2085,   3.2715,   2.1385, 682.0000])\n",
      "output:tensor([223325.0625])\n",
      "Batch Average Reconstruciton Loss:331019360.0\n",
      "input:tensor([  4.3277,   2.9315,   2.1221,   2.9125, 682.0000])\n",
      "output:tensor([223307.9375])\n",
      "Batch Average Reconstruciton Loss:34987964.0\n",
      "input:tensor([  6.7013,   2.3910,   6.4650,   2.3730, 682.0000])\n",
      "output:tensor([223255.4531])\n",
      "Batch Average Reconstruciton Loss:5658868736.0\n",
      "input:tensor([  4.7790,   2.3295,   3.9753,   2.2945, 682.0000])\n",
      "output:tensor([223305.1875])\n",
      "Batch Average Reconstruciton Loss:247438800.0\n",
      "input:tensor([  3.9340,   3.1005,   2.7861,   3.0235, 682.0000])\n",
      "output:tensor([223300.4375])\n",
      "Batch Average Reconstruciton Loss:832932096.0\n",
      "input:tensor([  3.4413,   2.1450,   2.5441,   2.1110, 682.0000])\n",
      "output:tensor([223341.3125])\n",
      "Batch Average Reconstruciton Loss:4214436096.0\n",
      "input:tensor([  3.7930,   2.2360,   2.8888,   2.1560, 682.0000])\n",
      "output:tensor([223331.7812])\n",
      "Batch Average Reconstruciton Loss:1459409536.0\n",
      "input:tensor([ 16.3780,   2.5515,  19.7226,   2.5125, 682.0000])\n",
      "output:tensor([223005.3281])\n",
      "Batch Average Reconstruciton Loss:26385561600.0\n",
      "input:tensor([  3.0220,   2.0315,   2.1814,   1.9925, 682.0000])\n",
      "output:tensor([223353.8281])\n",
      "Batch Average Reconstruciton Loss:11005094912.0\n",
      "input:tensor([  3.8570,   2.3885,   2.8660,   2.3485, 682.0000])\n",
      "output:tensor([223324.8906])\n",
      "Batch Average Reconstruciton Loss:1147184256.0\n",
      "input:tensor([  3.2930,   1.9930,   2.4730,   1.9540, 682.0000])\n",
      "output:tensor([223349.1875])\n",
      "Batch Average Reconstruciton Loss:6067757568.0\n",
      "input:tensor([  3.1980,   1.7480,   2.5263,   1.7130, 682.0000])\n",
      "output:tensor([223358.2812])\n",
      "Batch Average Reconstruciton Loss:7540442112.0\n",
      "input:tensor([  5.1870,   4.8590,   3.9780,   4.8420, 682.0000])\n",
      "output:tensor([223210.0469])\n",
      "Batch Average Reconstruciton Loss:1021636352.0\n",
      "input:tensor([  4.8510,   2.8130,   3.7018,   2.7780, 682.0000])\n",
      "output:tensor([223290.0938])\n",
      "Batch Average Reconstruciton Loss:353293152.0\n",
      "input:tensor([  3.7450,   2.6720,   2.6606,   2.6320, 682.0000])\n",
      "output:tensor([223318.1562])\n",
      "Batch Average Reconstruciton Loss:1727968768.0\n",
      "input:tensor([  4.9833,   3.5020,   3.5510,   3.4680, 682.0000])\n",
      "output:tensor([223265.6875])\n",
      "Batch Average Reconstruciton Loss:585721664.0\n",
      "input:tensor([ 33.8530,   1.7535,  45.4485,   1.7195, 682.0000])\n",
      "output:tensor([222572.3125])\n",
      "Batch Average Reconstruciton Loss:37353025536.0\n",
      "input:tensor([  3.9103,   3.1940,   2.7848,   3.1370, 682.0000])\n",
      "output:tensor([223296.8438])\n",
      "Batch Average Reconstruciton Loss:923561600.0\n",
      "input:tensor([  4.6870,   3.1400,   3.3789,   3.1040, 682.0000])\n",
      "output:tensor([223283.6250])\n",
      "Batch Average Reconstruciton Loss:135364496.0\n",
      "input:tensor([  3.9707,   3.1590,   2.8122,   3.0900, 682.0000])\n",
      "output:tensor([223297.4688])\n",
      "Batch Average Reconstruciton Loss:704081344.0\n",
      "input:tensor([  5.4337,   4.0545,   2.0516,   4.0495, 682.0000])\n",
      "output:tensor([223256.5000])\n",
      "Batch Average Reconstruciton Loss:1655798144.0\n",
      "input:tensor([  4.5933,   3.5205,   3.2452,   3.4105, 682.0000])\n",
      "output:tensor([223274.3281])\n",
      "Batch Average Reconstruciton Loss:53426276.0\n",
      "input:tensor([  5.1370,   2.2750,   4.5138,   2.1940, 682.0000])\n",
      "output:tensor([223298.7188])\n",
      "Batch Average Reconstruciton Loss:911419136.0\n",
      "input:tensor([  4.1343,   2.2340,   3.2706,   2.1990, 682.0000])\n",
      "output:tensor([223323.])\n",
      "Batch Average Reconstruciton Loss:276191168.0\n",
      "input:tensor([  3.8190,   2.7930,   2.7040,   2.7870, 682.0000])\n",
      "output:tensor([223311.7188])\n",
      "Batch Average Reconstruciton Loss:1328039808.0\n",
      "input:tensor([  3.9260,   2.9820,   2.7723,   2.9400, 682.0000])\n",
      "output:tensor([223304.0312])\n",
      "Batch Average Reconstruciton Loss:862595072.0\n",
      "input:tensor([  3.4780,   1.7640,   2.8694,   1.7250, 682.0000])\n",
      "output:tensor([223351.1562])\n",
      "Batch Average Reconstruciton Loss:3827877632.0\n",
      "input:tensor([  4.7087,   2.1425,   4.0661,   2.0785, 682.0000])\n",
      "output:tensor([223312.3594])\n",
      "Batch Average Reconstruciton Loss:159702848.0\n",
      "input:tensor([  4.8477,   2.2705,   4.1148,   2.2345, 682.0000])\n",
      "output:tensor([223305.0938])\n",
      "Batch Average Reconstruciton Loss:348572416.0\n",
      "input:tensor([  3.2703,   2.0235,   2.4418,   1.9635, 682.0000])\n",
      "output:tensor([223349.2188])\n",
      "Batch Average Reconstruciton Loss:6397405184.0\n",
      "input:tensor([ 14.2937,  11.0665,   6.9663,  11.0055, 682.0000])\n",
      "output:tensor([222860.7188])\n",
      "Batch Average Reconstruciton Loss:23549884416.0\n",
      "input:tensor([  4.3207,   2.4070,   3.3794,   2.3900, 682.0000])\n",
      "output:tensor([223313.2500])\n",
      "Batch Average Reconstruciton Loss:39447820.0\n",
      "input:tensor([ 27.9640,   3.4160,  34.7260,   3.3820, 682.0000])\n",
      "output:tensor([222690.4375])\n",
      "Batch Average Reconstruciton Loss:35049996288.0\n",
      "input:tensor([  4.1933,   2.3070,   3.2777,   2.2470, 682.0000])\n",
      "output:tensor([223320.3125])\n",
      "Batch Average Reconstruciton Loss:175448240.0\n",
      "input:tensor([  3.9453,   2.4875,   2.9224,   2.3765, 682.0000])\n",
      "output:tensor([223321.6094])\n",
      "Batch Average Reconstruciton Loss:790418944.0\n",
      "input:tensor([  6.1390,   3.7805,   4.5543,   3.7635, 682.0000])\n",
      "output:tensor([223232.2812])\n",
      "Batch Average Reconstruciton Loss:3799770880.0\n",
      "input:tensor([  3.4143,   2.1835,   2.5118,   2.1655, 682.0000])\n",
      "output:tensor([223340.1719])\n",
      "Batch Average Reconstruciton Loss:4515816960.0\n",
      "input:tensor([  3.4837,   1.7340,   2.8819,   1.7000, 682.0000])\n",
      "output:tensor([223351.9062])\n",
      "Batch Average Reconstruciton Loss:3770585600.0\n",
      "input:tensor([  4.4880,   2.3480,   3.6616,   2.2450, 682.0000])\n",
      "output:tensor([223312.6875])\n",
      "Batch Average Reconstruciton Loss:5192416.5\n",
      "input:tensor([  3.9247,   2.3775,   2.9353,   2.3605, 682.0000])\n",
      "output:tensor([223323.2500])\n",
      "Batch Average Reconstruciton Loss:866522240.0\n",
      "input:tensor([ 13.4410,   2.0880,  16.2110,   2.0090, 682.0000])\n",
      "output:tensor([223091.7344])\n",
      "Batch Average Reconstruciton Loss:22286827520.0\n",
      "input:tensor([  3.9903,   2.3765,   3.0233,   2.2955, 682.0000])\n",
      "output:tensor([223323.2344])\n",
      "Batch Average Reconstruciton Loss:638965440.0\n",
      "input:tensor([  5.8157,   3.8685,   4.1965,   3.8255, 682.0000])\n",
      "output:tensor([223237.0625])\n",
      "Batch Average Reconstruciton Loss:2773398272.0\n",
      "input:tensor([  3.7373,   2.1355,   2.8678,   2.1165, 682.0000])\n",
      "output:tensor([223334.6562])\n",
      "Batch Average Reconstruciton Loss:1772017920.0\n",
      "input:tensor([  5.4367,   4.6420,   3.9251,   4.5970, 682.0000])\n",
      "output:tensor([223216.3906])\n",
      "Batch Average Reconstruciton Loss:1660675840.0\n",
      "input:tensor([  3.2907,   1.9880,   2.4753,   1.9530, 682.0000])\n",
      "output:tensor([223349.2656])\n",
      "Batch Average Reconstruciton Loss:6101130752.0\n",
      "input:tensor([  3.2033,   1.8635,   2.4547,   1.7895, 682.0000])\n",
      "output:tensor([223355.8594])\n",
      "Batch Average Reconstruciton Loss:7451339264.0\n",
      "input:tensor([  4.4383,   3.2370,   2.0297,   3.1100, 682.0000])\n",
      "output:tensor([223299.5625])\n",
      "Batch Average Reconstruciton Loss:43030.31640625\n",
      "input:tensor([  5.5300,   4.4570,   3.9304,   4.3820, 682.0000])\n",
      "output:tensor([223222.7188])\n",
      "Batch Average Reconstruciton Loss:1921745536.0\n",
      "input:tensor([  3.8807,   2.3815,   2.8810,   2.3165, 682.0000])\n",
      "output:tensor([223325.3594])\n",
      "Batch Average Reconstruciton Loss:1043331392.0\n",
      "input:tensor([  5.0613,   3.1840,   3.5550,   3.0930, 682.0000])\n",
      "output:tensor([223277.5781])\n",
      "Batch Average Reconstruciton Loss:744284480.0\n",
      "input:tensor([  4.5247,   2.8075,   3.3579,   2.7885, 682.0000])\n",
      "output:tensor([223297.0469])\n",
      "Batch Average Reconstruciton Loss:16435296.0\n",
      "input:tensor([  3.4167,   2.1725,   2.5187,   2.1385, 682.0000])\n",
      "output:tensor([223340.8594])\n",
      "Batch Average Reconstruciton Loss:4489018880.0\n",
      "input:tensor([  5.1873,   3.2630,   3.8235,   3.2280, 682.0000])\n",
      "output:tensor([223269.1562])\n",
      "Batch Average Reconstruciton Loss:1026187136.0\n",
      "input:tensor([  3.5133,   2.3265,   2.5435,   2.2485, 682.0000])\n",
      "output:tensor([223335.1719])\n",
      "Batch Average Reconstruciton Loss:3483104000.0\n",
      "input:tensor([  3.7990,   2.2115,   2.9177,   2.1315, 682.0000])\n",
      "output:tensor([223332.2812])\n",
      "Batch Average Reconstruciton Loss:1427987328.0\n",
      "input:tensor([  4.4870,   3.1595,   3.1965,   3.1005, 682.0000])\n",
      "output:tensor([223287.6094])\n",
      "Batch Average Reconstruciton Loss:4860302.5\n",
      "input:tensor([  3.7457,   2.1010,   2.9122,   2.0660, 682.0000])\n",
      "output:tensor([223335.7188])\n",
      "Batch Average Reconstruciton Loss:1722522368.0\n",
      "input:tensor([  5.6307,   3.6195,   3.1295,   3.6005, 682.0000])\n",
      "output:tensor([223258.7344])\n",
      "Batch Average Reconstruciton Loss:2216595456.0\n",
      "input:tensor([  3.1767,   1.8000,   2.4705,   1.7820, 682.0000])\n",
      "output:tensor([223356.8281])\n",
      "Batch Average Reconstruciton Loss:7906797056.0\n",
      "input:tensor([  4.3593,   3.1380,   3.0931,   3.1210, 682.0000])\n",
      "output:tensor([223289.7812])\n",
      "Batch Average Reconstruciton Loss:18217692.0\n",
      "input:tensor([  4.4000,   3.4820,   3.1127,   3.4180, 682.0000])\n",
      "output:tensor([223278.0156])\n",
      "Batch Average Reconstruciton Loss:4739261.0\n",
      "input:tensor([  3.6187,   2.4750,   2.4311,   2.3940, 682.0000])\n",
      "output:tensor([223330.0312])\n",
      "Batch Average Reconstruciton Loss:2581043200.0\n",
      "input:tensor([ 24.0470,   6.5590,  25.3851,   6.5250, 682.0000])\n",
      "output:tensor([222719.9375])\n",
      "Batch Average Reconstruciton Loss:32930248704.0\n",
      "input:tensor([  3.6880,   2.1855,   2.7940,   2.1195, 682.0000])\n",
      "output:tensor([223335.3594])\n",
      "Batch Average Reconstruciton Loss:2083433216.0\n",
      "input:tensor([  4.8580,   4.4125,   3.6081,   4.2865, 682.0000])\n",
      "output:tensor([223236.1875])\n",
      "Batch Average Reconstruciton Loss:362414496.0\n",
      "input:tensor([ 79.3190,  79.1200, 118.4299,  93.1002, 802.0000])\n",
      "output:tensor([257514.2656])\n",
      "Batch Average Reconstruciton Loss:60660371456.0\n",
      "input:tensor([  3.9600,   3.0240,   2.7967,   2.9450, 682.0000])\n",
      "output:tensor([223302.8281])\n",
      "Batch Average Reconstruciton Loss:739958144.0\n",
      "input:tensor([  3.5680,   1.8500,   2.8986,   1.8150, 682.0000])\n",
      "output:tensor([223346.7188])\n",
      "Batch Average Reconstruciton Loss:2989933056.0\n",
      "input:tensor([  5.5760,   4.4290,   3.9537,   4.3950, 682.0000])\n",
      "output:tensor([223221.9531])\n",
      "Batch Average Reconstruciton Loss:2053626240.0\n",
      "input:tensor([  3.8423,   1.8425,   3.2278,   1.8085, 682.0000])\n",
      "output:tensor([223340.5312])\n",
      "Batch Average Reconstruciton Loss:1213509888.0\n",
      "input:tensor([  3.5987,   1.8975,   2.8812,   1.8625, 682.0000])\n",
      "output:tensor([223344.9062])\n",
      "Batch Average Reconstruciton Loss:2736659712.0\n",
      "input:tensor([  3.6850,   2.0740,   2.8679,   2.0570, 682.0000])\n",
      "output:tensor([223337.3438])\n",
      "Batch Average Reconstruciton Loss:2103291520.0\n",
      "input:tensor([  4.6723,   3.0475,   3.4028,   3.0305, 682.0000])\n",
      "output:tensor([223286.3750])\n",
      "Batch Average Reconstruciton Loss:120393016.0\n",
      "input:tensor([  3.4907,   1.9770,   2.7404,   1.8790, 682.0000])\n",
      "output:tensor([223346.2812])\n",
      "Batch Average Reconstruciton Loss:3701471488.0\n",
      "input:tensor([  3.5780,   2.3800,   1.7599,   2.2810, 682.0000])\n",
      "output:tensor([223341.5000])\n",
      "Batch Average Reconstruciton Loss:2906126336.0\n",
      "input:tensor([  4.0543,   2.6460,   2.9519,   2.5760, 682.0000])\n",
      "output:tensor([223313.4375])\n",
      "Batch Average Reconstruciton Loss:456359072.0\n",
      "input:tensor([  4.2133,   2.3405,   3.3031,   2.3225, 682.0000])\n",
      "output:tensor([223317.5938])\n",
      "Batch Average Reconstruciton Loss:147025472.0\n",
      "input:tensor([ 22.9860,  17.0540,  16.2528,  16.9930, 682.0000])\n",
      "output:tensor([222454.9844])\n",
      "Batch Average Reconstruciton Loss:32147767296.0\n",
      "input:tensor([  4.2663,   2.9470,   3.0491,   2.9070, 682.0000])\n",
      "output:tensor([223298.6406])\n",
      "Batch Average Reconstruciton Loss:84996584.0\n",
      "input:tensor([  5.2237,   3.9385,   3.6908,   3.8595, 682.0000])\n",
      "output:tensor([223247.1562])\n",
      "Batch Average Reconstruciton Loss:1111699328.0\n",
      "input:tensor([  3.9960,   1.6950,   3.5637,   1.6580, 682.0000])\n",
      "output:tensor([223340.6094])\n",
      "Batch Average Reconstruciton Loss:620378112.0\n",
      "input:tensor([  4.1730,   2.7415,   3.0367,   2.6715, 682.0000])\n",
      "output:tensor([223307.8438])\n",
      "Batch Average Reconstruciton Loss:207681424.0\n",
      "input:tensor([  3.9343,   1.9270,   3.2901,   1.8930, 682.0000])\n",
      "output:tensor([223335.8594])\n",
      "Batch Average Reconstruciton Loss:829620928.0\n",
      "input:tensor([  4.0680,   2.4635,   3.0450,   2.4295, 682.0000])\n",
      "output:tensor([223317.9062])\n",
      "Batch Average Reconstruciton Loss:421731136.0\n",
      "input:tensor([  4.1533,   2.8010,   2.9911,   2.7300, 682.0000])\n",
      "output:tensor([223306.4375])\n",
      "Batch Average Reconstruciton Loss:241415856.0\n",
      "input:tensor([  7.4660,   8.2060,   6.7197,   8.1710, 682.0000])\n",
      "output:tensor([223037.3438])\n",
      "Batch Average Reconstruciton Loss:8130330112.0\n",
      "input:tensor([  3.6680,   2.6100,   2.6023,   2.5740, 682.0000])\n",
      "output:tensor([223321.7188])\n",
      "Batch Average Reconstruciton Loss:2220792064.0\n",
      "input:tensor([  4.5437,   2.4160,   3.6448,   2.3730, 682.0000])\n",
      "output:tensor([223308.3438])\n",
      "Batch Average Reconstruciton Loss:24823750.0\n",
      "input:tensor([  4.0677,   2.6160,   2.9863,   2.5980, 682.0000])\n",
      "output:tensor([223312.6719])\n",
      "Batch Average Reconstruciton Loss:422768224.0\n",
      "input:tensor([  4.3573,   3.0575,   3.1110,   3.0145, 682.0000])\n",
      "output:tensor([223293.1250])\n",
      "Batch Average Reconstruciton Loss:19087068.0\n",
      "input:tensor([  9.8007,   3.9280,   8.9468,   3.8910, 682.0000])\n",
      "output:tensor([223141.5469])\n",
      "Batch Average Reconstruciton Loss:14865351680.0\n",
      "input:tensor([ 19.4853,   2.2150,  24.5472,   2.1970, 682.0000])\n",
      "output:tensor([222932.1094])\n",
      "Batch Average Reconstruciton Loss:29591605248.0\n",
      "input:tensor([ 25.4133,   2.0840,  33.0965,   2.0230, 682.0000])\n",
      "output:tensor([222783.2344])\n",
      "Batch Average Reconstruciton Loss:33763414016.0\n",
      "input:tensor([  4.5707,   2.7620,   3.4250,   2.7280, 682.0000])\n",
      "output:tensor([223297.8281])\n",
      "Batch Average Reconstruciton Loss:39210492.0\n",
      "input:tensor([ 26.4253,   2.2770,  34.2107,   2.2410, 682.0000])\n",
      "output:tensor([222753.0156])\n",
      "Batch Average Reconstruciton Loss:34303860736.0\n",
      "input:tensor([  3.7057,   2.0725,   2.8756,   2.0375, 682.0000])\n",
      "output:tensor([223337.5469])\n",
      "Batch Average Reconstruciton Loss:1967849856.0\n",
      "input:tensor([  4.8103,   3.2465,   2.4714,   3.2425, 682.0000])\n",
      "output:tensor([223287.4688])\n",
      "Batch Average Reconstruciton Loss:291196096.0\n",
      "input:tensor([  3.7547,   2.6975,   2.6624,   2.6365, 682.0000])\n",
      "output:tensor([223317.6406])\n",
      "Batch Average Reconstruciton Loss:1671776128.0\n",
      "input:tensor([  3.9910,   3.0315,   2.8179,   3.0135, 682.0000])\n",
      "output:tensor([223300.4688])\n",
      "Batch Average Reconstruciton Loss:637993408.0\n",
      "input:tensor([  3.7233,   2.1965,   2.8473,   2.1625, 682.0000])\n",
      "output:tensor([223333.2188])\n",
      "Batch Average Reconstruciton Loss:1857160192.0\n",
      "input:tensor([  3.1287,   1.7430,   2.4399,   1.7380, 682.0000])\n",
      "output:tensor([223359.3750])\n",
      "Batch Average Reconstruciton Loss:8781306880.0\n",
      "input:tensor([  3.8920,   2.4250,   2.8779,   2.3650, 682.0000])\n",
      "output:tensor([223323.5781])\n",
      "Batch Average Reconstruciton Loss:995934016.0\n",
      "input:tensor([  7.1850,   2.3705,   7.1099,   2.3325, 682.0000])\n",
      "output:tensor([223244.6562])\n",
      "Batch Average Reconstruciton Loss:7255574016.0\n",
      "input:tensor([  5.0100,   3.1770,   3.6845,   3.1090, 682.0000])\n",
      "output:tensor([223276.4219])\n",
      "Batch Average Reconstruciton Loss:638695296.0\n",
      "input:tensor([  3.7433,   2.1695,   2.8617,   2.1275, 682.0000])\n",
      "output:tensor([223334.0156])\n",
      "Batch Average Reconstruciton Loss:1736387584.0\n",
      "input:tensor([  3.7917,   2.1645,   2.9106,   2.1465, 682.0000])\n",
      "output:tensor([223332.5469])\n",
      "Batch Average Reconstruciton Loss:1466388608.0\n",
      "input:tensor([  3.6740,   2.5430,   2.6180,   2.5260, 682.0000])\n",
      "output:tensor([223323.4219])\n",
      "Batch Average Reconstruciton Loss:2179169792.0\n",
      "input:tensor([  5.2463,   3.7275,   3.7247,   3.6205, 682.0000])\n",
      "output:tensor([223254.7812])\n",
      "Batch Average Reconstruciton Loss:1167642240.0\n",
      "input:tensor([  3.7463,   2.2105,   2.8545,   2.1445, 682.0000])\n",
      "output:tensor([223333.2031])\n",
      "Batch Average Reconstruciton Loss:1718831872.0\n",
      "input:tensor([  3.4357,   2.2180,   2.5226,   2.1350, 682.0000])\n",
      "output:tensor([223340.2188])\n",
      "Batch Average Reconstruciton Loss:4276608256.0\n",
      "input:tensor([  4.1750,   2.8850,   2.9808,   2.8680, 682.0000])\n",
      "output:tensor([223301.9844])\n",
      "Batch Average Reconstruciton Loss:204576256.0\n",
      "input:tensor([  4.4990,   2.7955,   3.3370,   2.7355, 682.0000])\n",
      "output:tensor([223299.])\n",
      "Batch Average Reconstruciton Loss:7873636.0\n",
      "input:tensor([ 37.1483,  27.6735,  26.2656,  27.6125, 682.0000])\n",
      "output:tensor([221817.9688])\n",
      "Batch Average Reconstruciton Loss:38069460992.0\n",
      "input:tensor([  4.1290,   2.2510,   3.2455,   2.2160, 682.0000])\n",
      "output:tensor([223322.7344])\n",
      "Batch Average Reconstruciton Loss:286600032.0\n",
      "input:tensor([  4.5663,   2.7350,   3.4277,   2.7190, 682.0000])\n",
      "output:tensor([223298.3594])\n",
      "Batch Average Reconstruciton Loss:36679488.0\n",
      "input:tensor([  4.1067,   2.7630,   2.9721,   2.6960, 682.0000])\n",
      "output:tensor([223308.4219])\n",
      "Batch Average Reconstruciton Loss:333047104.0\n",
      "input:tensor([  4.3157,   2.5375,   3.2817,   2.5195, 682.0000])\n",
      "output:tensor([223309.7031])\n",
      "Batch Average Reconstruciton Loss:42906388.0\n",
      "input:tensor([  3.8257,   2.8210,   2.5368,   2.7270, 682.0000])\n",
      "output:tensor([223314.6719])\n",
      "Batch Average Reconstruciton Loss:1295015808.0\n",
      "input:tensor([  3.6957,   2.0880,   2.8649,   2.0470, 682.0000])\n",
      "output:tensor([223337.3594])\n",
      "Batch Average Reconstruciton Loss:2032624768.0\n",
      "input:tensor([  5.0427,   3.7145,   3.5677,   3.6705, 682.0000])\n",
      "output:tensor([223257.5156])\n",
      "Batch Average Reconstruciton Loss:704186688.0\n",
      "input:tensor([  4.2703,   2.4135,   3.2965,   2.3965, 682.0000])\n",
      "output:tensor([223314.4062])\n",
      "Batch Average Reconstruciton Loss:80740896.0\n",
      "input:tensor([  4.4600,   2.7300,   3.3395,   2.6510, 682.0000])\n",
      "output:tensor([223302.2031])\n",
      "Batch Average Reconstruciton Loss:774757.5625\n",
      "input:tensor([  4.2250,   2.8910,   3.0232,   2.8120, 682.0000])\n",
      "output:tensor([223302.3438])\n",
      "Batch Average Reconstruciton Loss:132035184.0\n",
      "input:tensor([  3.6197,   2.4735,   2.5969,   2.4565, 682.0000])\n",
      "output:tensor([223326.7031])\n",
      "Batch Average Reconstruciton Loss:2573664512.0\n",
      "input:tensor([  3.7023,   2.6170,   2.6344,   2.5570, 682.0000])\n",
      "output:tensor([223321.3438])\n",
      "Batch Average Reconstruciton Loss:1990735232.0\n",
      "input:tensor([  5.8367,   5.2170,   4.3420,   5.1980, 682.0000])\n",
      "output:tensor([223186.5000])\n",
      "Batch Average Reconstruciton Loss:2833060352.0\n",
      "input:tensor([  3.6233,   2.2520,   2.6869,   2.2180, 682.0000])\n",
      "output:tensor([223334.])\n",
      "Batch Average Reconstruciton Loss:2544899840.0\n",
      "input:tensor([  3.5310,   1.7610,   2.9152,   1.7260, 682.0000])\n",
      "output:tensor([223350.1094])\n",
      "Batch Average Reconstruciton Loss:3316595456.0\n",
      "input:tensor([  4.4213,   2.1900,   3.6472,   2.1560, 682.0000])\n",
      "output:tensor([223317.4688])\n",
      "Batch Average Reconstruciton Loss:1101515.875\n",
      "input:tensor([  3.9293,   2.4460,   2.9286,   2.3380, 682.0000])\n",
      "output:tensor([223323.1094])\n",
      "Batch Average Reconstruciton Loss:848958400.0\n",
      "input:tensor([  4.1360,   2.7655,   2.9853,   2.7265, 682.0000])\n",
      "output:tensor([223307.1406])\n",
      "Batch Average Reconstruciton Loss:273500800.0\n",
      "input:tensor([  4.6093,   2.5285,   3.6441,   2.4215, 682.0000])\n",
      "output:tensor([223305.2500])\n",
      "Batch Average Reconstruciton Loss:65452144.0\n",
      "input:tensor([ 16.4207,   2.8715,  19.2442,   2.8545, 682.0000])\n",
      "output:tensor([222998.0312])\n",
      "Batch Average Reconstruciton Loss:26434217984.0\n",
      "input:tensor([ 16.7427,   2.5635,  20.1813,   2.5465, 682.0000])\n",
      "output:tensor([222995.5938])\n",
      "Batch Average Reconstruciton Loss:26812618752.0\n",
      "input:tensor([  4.5880,   3.3910,   1.7569,   3.2890, 682.0000])\n",
      "output:tensor([223294.7812])\n",
      "Batch Average Reconstruciton Loss:50109144.0\n",
      "input:tensor([  3.8710,   2.3760,   2.9004,   2.3130, 682.0000])\n",
      "output:tensor([223325.4062])\n",
      "Batch Average Reconstruciton Loss:1085016832.0\n",
      "input:tensor([  3.7573,   2.5495,   2.7006,   2.4905, 682.0000])\n",
      "output:tensor([223322.4531])\n",
      "Batch Average Reconstruciton Loss:1656046208.0\n",
      "input:tensor([  3.9640,   2.4945,   2.9361,   2.4605, 682.0000])\n",
      "output:tensor([223319.0625])\n",
      "Batch Average Reconstruciton Loss:725383104.0\n",
      "input:tensor([  4.4247,   3.1760,   3.1368,   3.1570, 682.0000])\n",
      "output:tensor([223287.3125])\n",
      "Batch Average Reconstruciton Loss:829351.75\n",
      "input:tensor([  3.6570,   2.4645,   2.6306,   2.4275, 682.0000])\n",
      "output:tensor([223326.7656])\n",
      "Batch Average Reconstruciton Loss:2297690880.0\n",
      "input:tensor([  3.7127,   2.0165,   2.9343,   1.9825, 682.0000])\n",
      "output:tensor([223338.8438])\n",
      "Batch Average Reconstruciton Loss:1923187072.0\n",
      "input:tensor([  3.6983,   2.1050,   2.8654,   2.0310, 682.0000])\n",
      "output:tensor([223337.5625])\n",
      "Batch Average Reconstruciton Loss:2015241216.0\n",
      "input:tensor([  4.6047,   3.3795,   2.0793,   3.3465, 682.0000])\n",
      "output:tensor([223289.8281])\n",
      "Batch Average Reconstruciton Loss:61714036.0\n",
      "input:tensor([  3.8720,   3.3375,   2.8067,   3.3305, 682.0000])\n",
      "output:tensor([223290.6562])\n",
      "Batch Average Reconstruciton Loss:1082893312.0\n",
      "input:tensor([  4.3480,   3.0435,   3.0997,   2.9625, 682.0000])\n",
      "output:tensor([223294.8125])\n",
      "Batch Average Reconstruciton Loss:23582558.0\n",
      "input:tensor([ 37.6777,   2.3535,  50.0771,   2.2845, 682.0000])\n",
      "output:tensor([222461.5156])\n",
      "Batch Average Reconstruciton Loss:38467964928.0\n",
      "input:tensor([  3.8303,   2.8290,   2.7105,   2.7510, 682.0000])\n",
      "output:tensor([223312.0625])\n",
      "Batch Average Reconstruciton Loss:1272558464.0\n",
      "input:tensor([  3.4813,   2.2800,   2.5398,   2.2360, 682.0000])\n",
      "output:tensor([223336.3438])\n",
      "Batch Average Reconstruciton Loss:3795996160.0\n",
      "input:tensor([  4.4210,   2.6280,   3.3219,   2.6110, 682.0000])\n",
      "output:tensor([223304.8750])\n",
      "Batch Average Reconstruciton Loss:1164510.75\n",
      "input:tensor([  4.8190,   2.7620,   3.6997,   2.7320, 682.0000])\n",
      "output:tensor([223292.1406])\n",
      "Batch Average Reconstruciton Loss:304158496.0\n",
      "input:tensor([  3.5750,   2.3560,   2.5896,   2.3220, 682.0000])\n",
      "output:tensor([223331.8750])\n",
      "Batch Average Reconstruciton Loss:2932344320.0\n",
      "input:tensor([  3.4787,   1.7630,   2.8447,   1.7280, 682.0000])\n",
      "output:tensor([223351.3594])\n",
      "Batch Average Reconstruciton Loss:3821173504.0\n",
      "input:tensor([  3.4323,   2.1650,   2.5218,   2.1590, 682.0000])\n",
      "output:tensor([223340.2188])\n",
      "Batch Average Reconstruciton Loss:4313308160.0\n",
      "input:tensor([ 17.1110,   3.4005,  19.4498,   3.3035, 682.0000])\n",
      "output:tensor([222971.6250])\n",
      "Batch Average Reconstruciton Loss:27224215552.0\n",
      "input:tensor([  3.9197,   2.3925,   2.9230,   2.3575, 682.0000])\n",
      "output:tensor([223323.3438])\n",
      "Batch Average Reconstruciton Loss:885637120.0\n",
      "input:tensor([  3.9637,   2.5175,   2.9259,   2.4435, 682.0000])\n",
      "output:tensor([223319.3750])\n",
      "Batch Average Reconstruciton Loss:726497920.0\n",
      "input:tensor([  3.9757,   2.4960,   2.9311,   2.4620, 682.0000])\n",
      "output:tensor([223318.9688])\n",
      "Batch Average Reconstruciton Loss:686389248.0\n",
      "input:tensor([  3.9570,   2.4795,   2.9240,   2.4395, 682.0000])\n",
      "output:tensor([223319.9688])\n",
      "Batch Average Reconstruciton Loss:749392320.0\n",
      "input:tensor([  3.6197,   1.9535,   2.8980,   1.8935, 682.0000])\n",
      "output:tensor([223343.1250])\n",
      "Batch Average Reconstruciton Loss:2571998464.0\n",
      "input:tensor([  3.8977,   2.4465,   2.8771,   2.4055, 682.0000])\n",
      "output:tensor([223322.3125])\n",
      "Batch Average Reconstruciton Loss:972734208.0\n",
      "input:tensor([  4.5907,   2.9760,   2.3620,   2.9160, 682.0000])\n",
      "output:tensor([223302.0312])\n",
      "Batch Average Reconstruciton Loss:51998972.0\n",
      "input:tensor([  3.9467,   2.4485,   2.9256,   2.4145, 682.0000])\n",
      "output:tensor([223321.])\n",
      "Batch Average Reconstruciton Loss:785680896.0\n",
      "input:tensor([  4.2300,   1.8555,   3.7079,   1.8385, 682.0000])\n",
      "output:tensor([223330.3438])\n",
      "Batch Average Reconstruciton Loss:125096536.0\n",
      "input:tensor([  3.2733,   2.4395,   2.3123,   2.4355, 682.0000])\n",
      "output:tensor([223334.3125])\n",
      "Batch Average Reconstruciton Loss:6355387904.0\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "#model.load_state_dict(torch.load('../model/param_AE'))\n",
    "model.eval()\n",
    "validation_batch_size = 1\n",
    "permutation = np.random.permutation(len(validation_data))\n",
    "for i in range(0, len(validation_data), validation_batch_size):\n",
    "    batch_idc = permutation[i:i+validation_batch_size]\n",
    "    batch = validation_X[batch_idc,]\n",
    "    batch_y = validation_y[batch_idc,]\n",
    "    loss = 0\n",
    "    # compute reconstructions\n",
    "    outputs = model(batch)\n",
    "\n",
    "    print(f\"input:{batch[0].data}\\noutput:{outputs[0].data}\")\n",
    "    \n",
    "    # compute the epoch validation loss\n",
    "    loss = criterion(outputs, batch_y.view(len(outputs), 1)).item()\n",
    "    loss /= len(batch)\n",
    "    #i_loss = torch.sum(torch.square(batch[0]-outputs[0]))\n",
    "    print(f\"Batch Average Reconstruciton Loss:{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xxd/Documents/Course/MIE696/mie696/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "#model.load_state_dict(torch.load('../model/param_AE'))\n",
    "model.eval()\n",
    "model_name = \"VAE\"\n",
    "\n",
    "# Collapse\n",
    "if True:\n",
    "    loss_test = []\n",
    "    lcs_array = torch.tensor([[0 for _ in range(NUM_FEATURE)]])\n",
    "\n",
    "    y_scores = []\n",
    "    y_scores_lcs = []\n",
    "    kl_div_test = []\n",
    "    y_ground_truth = []\n",
    "    # Define KL Loss\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\", log_target=False)\n",
    "    l = len(test_data)\n",
    "    permutation = np.random.permutation(l)\n",
    "    for i in range(0, l, 1):\n",
    "        batch_idc = permutation[i:i+1]\n",
    "        batch = test_X[batch_idc,]\n",
    "        batch_y = test_y[batch_idc,]\n",
    "        loss = 0\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = model(batch)\n",
    "\n",
    "        #print(f\"input:{batch[0].data}\\noutput:{outputs[0].data}\")\n",
    "        \n",
    "        # compute the epoch test loss\n",
    "        loss = criterion(outputs, batch_y).item()\n",
    "        # append loss and class label\n",
    "        y_scores.append(loss)\n",
    "        y_ground_truth.append(0)\n",
    "        #i_loss = torch.sum(torch.square(batch[0]-outputs[0]))\n",
    "        loss_test.append(loss)\n",
    "        #print(f\"Reconstruciton Loss:{loss}\")\n",
    "    #________________________________________________________________________#\n",
    "\n",
    "    # anomaly detection test\n",
    "    loss_attack =[]\n",
    "    l = len(anomalous_data)\n",
    "    permutation = np.random.permutation(l)\n",
    "    for i in range(0, l, 1):\n",
    "        batch_idc = permutation[i:i+1]\n",
    "        batch = anomalous_X[batch_idc,]\n",
    "        batch_y = anomalous_y[batch_idc,]\n",
    "        loss = 0\n",
    "        # compute reconstructions\n",
    "        outputs = model(batch)\n",
    "        # compute the epoch test loss\n",
    "        loss = criterion(outputs, batch_y).item()\n",
    "        # append loss and class label\n",
    "        y_scores.append(loss)\n",
    "        y_ground_truth.append(1)\n",
    "        loss_attack.append(loss)\n",
    "        #print(f\"Reconstruciton Loss:{loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "if True:\n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    ax.set_xlabel('Instances', fontsize = 12)\n",
    "    ax.set_ylabel('MSE---Sum', fontsize = 12)\n",
    "    ax.set_yscale('log')\n",
    "    #ax.set_ylim(1e2, 1e9)\n",
    "    ax.set_title('Reconstruction Error: - ' + model_name, fontsize = 18)\n",
    "    ax.grid()\n",
    "    a = ax.scatter(np.arange(len(loss_test)), loss_test, marker=\".\")\n",
    "    b = ax.scatter(np.arange(len(loss_attack)), loss_attack, marker=\"x\", alpha=0.4)\n",
    "    a.set_label('Normal data')\n",
    "    b.set_label('Anomalous data')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convergence Rate\n",
    "if True:\n",
    "    fig = plt.figure(figsize = (5, 5))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Epoch', fontsize = 12)\n",
    "    ax.set_ylabel('Loss--L2 Distance', fontsize = 12)\n",
    "    ax.set_yscale('log')\n",
    "    #ax.set_ylim(1e5, 1e9)\n",
    "    ax.set_title('Convergence rate', fontsize = 18)\n",
    "    ax.grid()\n",
    "    a = ax.plot(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC & AUC\n",
    "from sklearn import metrics\n",
    "if True:\n",
    "    fig = plt.figure(figsize = (5,5))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "\n",
    "    fpr_MSE, tpr_MSE, _ = metrics.roc_curve(y_ground_truth,  y_scores)\n",
    "    auc_MSE = metrics.roc_auc_score(y_ground_truth,  y_scores)\n",
    "\n",
    "    ax.set_title(model_name+'(normalized data)\\n ROC Curve and AUC', fontsize = 18)\n",
    "    ax.plot(fpr_MSE,tpr_MSE, label=\"MSE auc=\"+str(auc_MSE))\n",
    "    ax.set_xlabel(\"False Positive Rate\", fontsize=15)\n",
    "    ax.set_ylabel(\"True Positive Rate\", fontsize=15)\n",
    "    ax.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "('__name__', '__main__')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m KLD1 \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mlog(std\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m mu\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m std\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m# KL divergence with N(0, 1)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39marray([[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m], [\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]])[:,\u001b[39m1\u001b[39m], return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m1\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mlocals\u001b[39m()\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(item)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCE\u001b[39m\u001b[39m\"\u001b[39m, nn\u001b[39m.\u001b[39mBCELoss(reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)(torch\u001b[39m.\u001b[39mtensor([\u001b[39m.2\u001b[39m,\u001b[39m.5\u001b[39m,\u001b[39m.9\u001b[39m,\u001b[39m.1\u001b[39m]), torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.0\u001b[39m,\u001b[39m1.0\u001b[39m,\u001b[39m1.0\u001b[39m,\u001b[39m1.0\u001b[39m])))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "# test block\n",
    "import itertools\n",
    "mu, std = torch.rand(4, 16), torch.exp(torch.rand(4, 16))**0.5\n",
    "KLD = torch.distributions.kl.kl_divergence(torch.distributions.normal.Normal(mu, std), torch.distributions.normal.Normal(torch.zeros_like(mu), torch.ones_like(std)))\n",
    "KLD1 = -0.5 * (1 + torch.log(std**2) - mu**2 - std**2) # KL divergence with N(0, 1)\n",
    "print(np.unique(np.array([[1,1], [2,1],[1,1]])[:,1], return_counts=True)[1])\n",
    "for item in locals().items():\n",
    "    print(item)\n",
    "print(\"CE\", nn.BCELoss(reduction='none')(torch.tensor([.2,.5,.9,.1]), torch.tensor([1.0,1.0,1.0,1.0])))\n",
    "a = np.random.rand(10, 2)\n",
    "print(np.concatenate((a, a, np.ones((10, 1))), axis=1))\n",
    "\n",
    "sd = torch.randint(0, 5, (3, 2, 1))\n",
    "print(sd)\n",
    "sigma = sd * sd.view(3, 1, 2)\n",
    "print(sigma)\n",
    "print(sigma.shape)\n",
    "print(torch.eye(3).expand(4, 3, 3))\n",
    "\n",
    "Sigma = torch.rand(2, 2) + torch.eye(2) * 1e-6\n",
    "Sigma = Sigma.T * Sigma\n",
    "print(Sigma.shape)\n",
    "Sigma2 = Sigma.expand(4, 2, 2)\n",
    "torch.mul(torch.rand(4, 2, 2), torch.rand(4, 2, 1)).shape\n",
    "\n",
    "p = torch.distributions.normal.Normal(torch.rand(16, 4), torch.randint(1, 3, (16, 4)))\n",
    "q = torch.distributions.normal.Normal(torch.rand(16, 4), torch.randint(1, 3, (16, 4)))\n",
    "\n",
    "torch.distributions.kl.kl_divergence(p, q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db51f3103e33fda5231e127d6bff8ab7a63db870768c02250aa2c81f3d18b2ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
